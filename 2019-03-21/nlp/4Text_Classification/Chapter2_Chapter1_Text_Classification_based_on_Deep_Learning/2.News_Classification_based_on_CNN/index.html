<!DOCTYPE html>
<html lang="en">







<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>NLP系列 | Pastor Dean</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="pastor">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/images/favicon-16x16-next.png">
	<link rel="apple-touch-icon" href="/images/favicon-16x16-next.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Pastor Dean">
	<meta property="og:type" content="article">
	<meta property="og:title" content="NLP系列 | Pastor Dean">
	<meta property="og:description" content>
	<meta property="og:url" content="https://mrpastor.github.io/2019-03-21/nlp/4Text_Classification/Chapter2_Chapter1_Text_Classification_based_on_Deep_Learning/2.News_Classification_based_on_CNN/">

	
	<meta property="article:published_time" content="2019-03-21T19:03:00+08:00"> 
	<meta property="article:author" content="pastor">
	<meta property="article:published_first" content="Pastor Dean, /2019-03-21/nlp/4Text_Classification/Chapter2_Chapter1_Text_Classification_based_on_Deep_Learning/2.News_Classification_based_on_CNN/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Pastor Dean">
                    <img src="/images/favicon-32x32-next.png" alt="Pastor Dean">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/ || home" title="home">home</a>
            </li>
            
            <li>
                <a href="/categories/ || th" title="categories">categories</a>
            </li>
            
            <li>
                <a href="/archives/ || archive" title="archives">archives</a>
            </li>
            
            <li>
                <a href="/tools/ || tools" title="tools">tools</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/mrpastor" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2019-03-21T11:19:18.000Z">
                    2019-03-21
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/NLP/">NLP</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">NLP系列</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h1 id="使用TensorFlow构建卷积神经网络完成新闻分类"><a href="#使用TensorFlow构建卷积神经网络完成新闻分类" class="headerlink" title="使用TensorFlow构建卷积神经网络完成新闻分类"></a>使用TensorFlow构建卷积神经网络完成新闻分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df_cnews =pd.read_csv(<span class="string">"./data/cnews.train.txt"</span>,sep=<span class="string">"\t"</span>,names=[<span class="string">'category'</span>,<span class="string">'cnews'</span>], encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">df_cnews = df_cnews.dropna()</span><br><span class="line"></span><br><span class="line">ty = df_cnews[df_cnews.category==<span class="string">'体育'</span>].cnews.values.tolist()</span><br><span class="line">jj = df_cnews[df_cnews.category==<span class="string">'家居'</span>].cnews.values.tolist()</span><br><span class="line">ss = df_cnews[df_cnews.category==<span class="string">'时尚'</span>].cnews.values.tolist()</span><br><span class="line">fc = df_cnews[df_cnews.category==<span class="string">'房产'</span>].cnews.values.tolist()</span><br><span class="line">jy = df_cnews[df_cnews.category==<span class="string">'教育'</span>].cnews.values.tolist()</span><br><span class="line">sz = df_cnews[df_cnews.category==<span class="string">'时政'</span>].cnews.values.tolist()</span><br><span class="line">yl = df_cnews[df_cnews.category==<span class="string">'娱乐'</span>].cnews.values.tolist()</span><br><span class="line">yx = df_cnews[df_cnews.category==<span class="string">'游戏'</span>].cnews.values.tolist()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 停用词</span></span><br><span class="line">stopwords=pd.read_csv(<span class="string">"./data/stopwords.txt"</span>,index_col=<span class="keyword">False</span>,quoting=<span class="number">3</span>,sep=<span class="string">"\t"</span>,names=[<span class="string">'stopword'</span>], encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">stopwords=stopwords[<span class="string">'stopword'</span>].values</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_text</span><span class="params">(content_lines, sentences, category)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> content_lines:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            segs=jieba.lcut(line)</span><br><span class="line">            segs = filter(<span class="keyword">lambda</span> x:len(x)&gt;<span class="number">1</span>, segs)</span><br><span class="line">            segs = filter(<span class="keyword">lambda</span> x:x <span class="keyword">not</span> <span class="keyword">in</span> stopwords, segs)</span><br><span class="line">            sentences.append((<span class="string">" "</span>.join(segs), category))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(line)</span><br><span class="line">            <span class="keyword">continue</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#生成训练数据</span></span><br><span class="line">sentences = []</span><br><span class="line"></span><br><span class="line">preprocess_text(ty, sentences, <span class="string">'ty'</span>)</span><br><span class="line">preprocess_text(jj, sentences, <span class="string">'jj'</span>)</span><br><span class="line">preprocess_text(ss, sentences, <span class="string">'ss'</span>)</span><br><span class="line">preprocess_text(fc, sentences, <span class="string">'fc'</span>)</span><br><span class="line">preprocess_text(jy, sentences, <span class="string">'jy'</span>)</span><br><span class="line">preprocess_text(sz, sentences, <span class="string">'sz'</span>)</span><br><span class="line">preprocess_text(yl, sentences, <span class="string">'yl'</span>)</span><br><span class="line">preprocess_text(yx, sentences, <span class="string">'yx'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 2.004 seconds.
Prefix dict has been built succesfully.
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x, y = zip(*sentences)</span><br><span class="line">train_data, test_data, train_target, test_target = train_test_split(x, y, random_state=<span class="number">1234</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">基于卷积神经网络的中文文本分类</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">learn = tf.contrib.learn</span><br><span class="line"></span><br><span class="line">FLAGS = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#文档最长长度</span></span><br><span class="line">MAX_DOCUMENT_LENGTH = <span class="number">100</span></span><br><span class="line"><span class="comment">#最小词频数</span></span><br><span class="line">MIN_WORD_FREQUENCE = <span class="number">2</span></span><br><span class="line"><span class="comment">#词嵌入的维度</span></span><br><span class="line">EMBEDDING_SIZE = <span class="number">20</span></span><br><span class="line"><span class="comment">#filter个数</span></span><br><span class="line">N_FILTERS = <span class="number">10</span></span><br><span class="line"><span class="comment">#感知野大小</span></span><br><span class="line">WINDOW_SIZE = <span class="number">20</span></span><br><span class="line"><span class="comment">#filter的形状</span></span><br><span class="line">FILTER_SHAPE1 = [WINDOW_SIZE, EMBEDDING_SIZE]</span><br><span class="line">FILTER_SHAPE2 = [WINDOW_SIZE, N_FILTERS]</span><br><span class="line"><span class="comment">#池化</span></span><br><span class="line">POOLING_WINDOW = <span class="number">4</span></span><br><span class="line">POOLING_STRIDE = <span class="number">2</span></span><br><span class="line">n_words = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cnn_model</span><span class="params">(features, target)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    2层的卷积神经网络，用于短文本分类</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 先把词转成词嵌入</span></span><br><span class="line">    <span class="comment"># 我们得到一个形状为[n_words, EMBEDDING_SIZE]的词表映射矩阵</span></span><br><span class="line">    <span class="comment"># 接着我们可以把一批文本映射成[batch_size, sequence_length, EMBEDDING_SIZE]的矩阵形式</span></span><br><span class="line">    target = tf.one_hot(target, <span class="number">15</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    word_vectors = tf.contrib.layers.embed_sequence(</span><br><span class="line">            features, vocab_size=n_words, embed_dim=EMBEDDING_SIZE, scope=<span class="string">'words'</span>)</span><br><span class="line">    word_vectors = tf.expand_dims(word_vectors, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'CNN_Layer1'</span>):</span><br><span class="line">        <span class="comment"># 添加卷积层做滤波</span></span><br><span class="line">        conv1 = tf.contrib.layers.convolution2d(</span><br><span class="line">                word_vectors, N_FILTERS, FILTER_SHAPE1, padding=<span class="string">'VALID'</span>)</span><br><span class="line">        <span class="comment"># 添加RELU非线性</span></span><br><span class="line">        conv1 = tf.nn.relu(conv1)</span><br><span class="line">        <span class="comment"># 最大池化</span></span><br><span class="line">        pool1 = tf.nn.max_pool(</span><br><span class="line">                conv1,</span><br><span class="line">                ksize=[<span class="number">1</span>, POOLING_WINDOW, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                strides=[<span class="number">1</span>, POOLING_STRIDE, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                padding=<span class="string">'SAME'</span>)</span><br><span class="line">        <span class="comment"># 对矩阵进行转置，以满足形状</span></span><br><span class="line">        pool1 = tf.transpose(pool1, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'CNN_Layer2'</span>):</span><br><span class="line">        <span class="comment"># 第2个卷积层</span></span><br><span class="line">        conv2 = tf.contrib.layers.convolution2d(</span><br><span class="line">                pool1, N_FILTERS, FILTER_SHAPE2, padding=<span class="string">'VALID'</span>)</span><br><span class="line">        <span class="comment"># 抽取特征</span></span><br><span class="line">        pool2 = tf.squeeze(tf.reduce_max(conv2, <span class="number">1</span>), squeeze_dims=[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 全连接层</span></span><br><span class="line">    logits = tf.contrib.layers.fully_connected(pool2, <span class="number">15</span>, activation_fn=<span class="keyword">None</span>)</span><br><span class="line">    loss = tf.losses.softmax_cross_entropy(target, logits)</span><br><span class="line"></span><br><span class="line">    train_op = tf.contrib.layers.optimize_loss(</span><br><span class="line">            loss,</span><br><span class="line">            tf.contrib.framework.get_global_step(),</span><br><span class="line">            optimizer=<span class="string">'Adam'</span>,</span><br><span class="line">            learning_rate=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (&#123;</span><br><span class="line">            <span class="string">'class'</span>: tf.argmax(logits, <span class="number">1</span>),</span><br><span class="line">            <span class="string">'prob'</span>: tf.nn.softmax(logits)</span><br><span class="line">    &#125;, loss, train_op)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">global</span> n_words</span><br><span class="line"><span class="comment"># 处理词汇</span></span><br><span class="line">vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH, min_frequency=MIN_WORD_FREQUENCE)</span><br><span class="line">x_train = np.array(list(vocab_processor.fit_transform(train_data)))</span><br><span class="line">x_test = np.array(list(vocab_processor.transform(test_data)))</span><br><span class="line">n_words = len(vocab_processor.vocabulary_)</span><br><span class="line">print(<span class="string">'Total words: %d'</span> % n_words)</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From &lt;ipython-input-6-101cbea574b0&gt;:3: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
Total words: 48058
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cate_dic = &#123;<span class="string">'ty'</span>:<span class="number">1</span>, <span class="string">'jj'</span>:<span class="number">2</span>, <span class="string">'ss'</span>:<span class="number">3</span>, <span class="string">'fc'</span>:<span class="number">4</span>, <span class="string">'jy'</span>:<span class="number">5</span>,<span class="string">'sz'</span>:<span class="number">6</span>,<span class="string">'yl'</span>:<span class="number">7</span>,<span class="string">'yx'</span>:<span class="number">8</span>&#125;</span><br><span class="line">train_target = map(<span class="keyword">lambda</span> x:cate_dic[x], train_target)</span><br><span class="line">test_target = map(<span class="keyword">lambda</span> x:cate_dic[x], test_target)</span><br><span class="line">y_train = pandas.Series(train_target)</span><br><span class="line">y_test = pandas.Series(test_target)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line">classifier = learn.SKCompat(learn.Estimator(model_fn=cnn_model))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练和预测</span></span><br><span class="line">classifier.fit(x_train, y_train, steps=<span class="number">1000</span>)</span><br><span class="line">y_predicted = classifier.predict(x_test)[<span class="string">'class'</span>]</span><br><span class="line">score = metrics.accuracy_score(y_test, y_predicted)</span><br><span class="line">print(<span class="string">'Accuracy: &#123;0:f&#125;'</span>.format(score))</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.
Instructions for updating:
Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:428: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp568rmfet
INFO:tensorflow:Using config: {&apos;_train_distribute&apos;: None, &apos;_is_chief&apos;: True, &apos;_log_step_count_steps&apos;: 100, &apos;_device_fn&apos;: None, &apos;_save_summary_steps&apos;: 100, &apos;_protocol&apos;: None, &apos;_environment&apos;: &apos;local&apos;, &apos;_task_id&apos;: 0, &apos;_save_checkpoints_steps&apos;: None, &apos;_task_type&apos;: None, &apos;_save_checkpoints_secs&apos;: 600, &apos;_keep_checkpoint_max&apos;: 5, &apos;_session_config&apos;: None, &apos;_model_dir&apos;: &apos;/tmp/tmp568rmfet&apos;, &apos;_cluster_spec&apos;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f469eaa6278&gt;, &apos;_tf_config&apos;: gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, &apos;_evaluation_master&apos;: &apos;&apos;, &apos;_num_worker_replicas&apos;: 0, &apos;_eval_distribute&apos;: None, &apos;_master&apos;: &apos;&apos;, &apos;_tf_random_seed&apos;: None, &apos;_num_ps_replicas&apos;: 0, &apos;_keep_checkpoint_every_n_hours&apos;: 10000}
WARNING:tensorflow:From &lt;ipython-input-8-49860c40bfe1&gt;:2: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to the Estimator interface.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.
Instructions for updating:
Please access pandas data directly.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.
Instructions for updating:
Please access pandas data directly.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.
Instructions for updating:
Please convert numpy dtypes explicitly.
WARNING:tensorflow:From &lt;ipython-input-5-c2c13d88f68c&gt;:70: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From &lt;ipython-input-5-c2c13d88f68c&gt;:78: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_global_step
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1241: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.
Instructions for updating:
When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp568rmfet/model.ckpt.
INFO:tensorflow:loss = 2.7079399, step = 0
INFO:tensorflow:global_step/sec: 98.5193
INFO:tensorflow:loss = 0.050897215, step = 100 (1.020 sec)
INFO:tensorflow:global_step/sec: 119.128
INFO:tensorflow:loss = 0.0014143699, step = 200 (0.837 sec)
INFO:tensorflow:global_step/sec: 108.514
INFO:tensorflow:loss = 0.000132761, step = 300 (0.924 sec)
INFO:tensorflow:global_step/sec: 117.55
INFO:tensorflow:loss = 0.0002916466, step = 400 (0.848 sec)
INFO:tensorflow:global_step/sec: 119.855
INFO:tensorflow:loss = 3.9822407e-05, step = 500 (0.834 sec)
INFO:tensorflow:global_step/sec: 119.059
INFO:tensorflow:loss = 3.786313e-05, step = 600 (0.840 sec)
INFO:tensorflow:global_step/sec: 110.227
INFO:tensorflow:loss = 0.0004890824, step = 700 (0.909 sec)
INFO:tensorflow:global_step/sec: 115.1
INFO:tensorflow:loss = 3.7943282e-05, step = 800 (0.868 sec)
INFO:tensorflow:global_step/sec: 117.432
INFO:tensorflow:loss = 1.45628455e-05, step = 900 (0.850 sec)
INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp568rmfet/model.ckpt.
INFO:tensorflow:Loss for final step: 1.8430579e-05.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmp568rmfet/model.ckpt-1000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
Accuracy: 0.933500
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">使用RNN完成文本分类</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.layers.python.layers <span class="keyword">import</span> encoders</span><br><span class="line"></span><br><span class="line">learn = tf.contrib.learn</span><br><span class="line"></span><br><span class="line">FLAGS = <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 词袋模型</span></span><br><span class="line"></span><br><span class="line">MAX_DOCUMENT_LENGTH = <span class="number">15</span></span><br><span class="line">MIN_WORD_FREQUENCE = <span class="number">1</span></span><br><span class="line">EMBEDDING_SIZE = <span class="number">50</span></span><br><span class="line"><span class="keyword">global</span> n_words</span><br><span class="line"><span class="comment"># 处理词汇</span></span><br><span class="line">vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH, min_frequency=MIN_WORD_FREQUENCE)</span><br><span class="line">x_train = np.array(list(vocab_processor.fit_transform(train_data)))</span><br><span class="line">x_test = np.array(list(vocab_processor.transform(test_data)))</span><br><span class="line">n_words = len(vocab_processor.vocabulary_)</span><br><span class="line">print(<span class="string">'Total words: %d'</span> % n_words)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bag_of_words_model</span><span class="params">(features, target)</span>:</span></span><br><span class="line">    <span class="string">"""先转成词袋模型"""</span></span><br><span class="line">    target = tf.one_hot(target, <span class="number">15</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    features = encoders.bow_encoder(</span><br><span class="line">            features, vocab_size=n_words, embed_dim=EMBEDDING_SIZE)</span><br><span class="line">    logits = tf.contrib.layers.fully_connected(features, <span class="number">15</span>, activation_fn=<span class="keyword">None</span>)</span><br><span class="line">    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)</span><br><span class="line">    train_op = tf.contrib.layers.optimize_loss(</span><br><span class="line">            loss,</span><br><span class="line">            tf.contrib.framework.get_global_step(),</span><br><span class="line">            optimizer=<span class="string">'Adam'</span>,</span><br><span class="line">            learning_rate=<span class="number">0.01</span>)</span><br><span class="line">    <span class="keyword">return</span> (&#123;</span><br><span class="line">            <span class="string">'class'</span>: tf.argmax(logits, <span class="number">1</span>),</span><br><span class="line">            <span class="string">'prob'</span>: tf.nn.softmax(logits)</span><br><span class="line">    &#125;, loss, train_op)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_fn = bag_of_words_model</span><br><span class="line">classifier = learn.SKCompat(learn.Estimator(model_fn=model_fn))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and predict</span></span><br><span class="line">classifier.fit(x_train, y_train, steps=<span class="number">1000</span>)</span><br><span class="line">y_predicted = classifier.predict(x_test)[<span class="string">'class'</span>]</span><br><span class="line">score = metrics.accuracy_score(y_test, y_predicted)</span><br><span class="line">print(<span class="string">'Accuracy: &#123;0:f&#125;'</span>.format(score))</span><br></pre></td></tr></table></figure>
<pre><code>Total words: 65350
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_xsdnfqs
INFO:tensorflow:Using config: {&apos;_train_distribute&apos;: None, &apos;_is_chief&apos;: True, &apos;_log_step_count_steps&apos;: 100, &apos;_device_fn&apos;: None, &apos;_save_summary_steps&apos;: 100, &apos;_protocol&apos;: None, &apos;_environment&apos;: &apos;local&apos;, &apos;_task_id&apos;: 0, &apos;_save_checkpoints_steps&apos;: None, &apos;_task_type&apos;: None, &apos;_save_checkpoints_secs&apos;: 600, &apos;_keep_checkpoint_max&apos;: 5, &apos;_session_config&apos;: None, &apos;_model_dir&apos;: &apos;/tmp/tmp_xsdnfqs&apos;, &apos;_cluster_spec&apos;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f469e6b8cf8&gt;, &apos;_tf_config&apos;: gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, &apos;_evaluation_master&apos;: &apos;&apos;, &apos;_num_worker_replicas&apos;: 0, &apos;_eval_distribute&apos;: None, &apos;_master&apos;: &apos;&apos;, &apos;_tf_random_seed&apos;: None, &apos;_num_ps_replicas&apos;: 0, &apos;_keep_checkpoint_every_n_hours&apos;: 10000}
WARNING:tensorflow:From &lt;ipython-input-10-a6718fa18db5&gt;:20: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:399: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.compute_weighted_loss instead.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:147: add_arg_scope.&lt;locals&gt;.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.add_loss instead.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_xsdnfqs/model.ckpt.
INFO:tensorflow:loss = 2.7085168, step = 0
INFO:tensorflow:global_step/sec: 91.6219
INFO:tensorflow:loss = 0.044218887, step = 100 (1.094 sec)
INFO:tensorflow:global_step/sec: 102.446
INFO:tensorflow:loss = 0.0072543425, step = 200 (0.975 sec)
INFO:tensorflow:global_step/sec: 103.751
INFO:tensorflow:loss = 0.002886944, step = 300 (0.964 sec)
INFO:tensorflow:global_step/sec: 103.69
INFO:tensorflow:loss = 0.0020158489, step = 400 (0.965 sec)
INFO:tensorflow:global_step/sec: 102.387
INFO:tensorflow:loss = 0.0011120392, step = 500 (0.976 sec)
INFO:tensorflow:global_step/sec: 102.986
INFO:tensorflow:loss = 0.0008669663, step = 600 (0.971 sec)
INFO:tensorflow:global_step/sec: 102.535
INFO:tensorflow:loss = 0.000653078, step = 700 (0.975 sec)
INFO:tensorflow:global_step/sec: 102.798
INFO:tensorflow:loss = 0.0005366546, step = 800 (0.973 sec)
INFO:tensorflow:global_step/sec: 103.618
INFO:tensorflow:loss = 0.0005024085, step = 900 (0.965 sec)
INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_xsdnfqs/model.ckpt.
INFO:tensorflow:Loss for final step: 0.00040020357.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmp_xsdnfqs/model.ckpt-1000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
Accuracy: 0.957000
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRU分类器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_model</span><span class="params">(features, target)</span>:</span></span><br><span class="line">    <span class="string">"""用RNN模型(这里用的是GRU)完成文本分类"""</span></span><br><span class="line">    <span class="comment"># Convert indexes of words into embeddings.</span></span><br><span class="line">    <span class="comment"># This creates embeddings matrix of [n_words, EMBEDDING_SIZE] and then</span></span><br><span class="line">    <span class="comment"># maps word indexes of the sequence into [batch_size, sequence_length,</span></span><br><span class="line">    <span class="comment"># EMBEDDING_SIZE].</span></span><br><span class="line">    word_vectors = tf.contrib.layers.embed_sequence(</span><br><span class="line">            features, vocab_size=n_words, embed_dim=EMBEDDING_SIZE, scope=<span class="string">'words'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Split into list of embedding per word, while removing doc length dim.</span></span><br><span class="line">    <span class="comment"># word_list results to be a list of tensors [batch_size, EMBEDDING_SIZE].</span></span><br><span class="line">    word_list = tf.unstack(word_vectors, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a Gated Recurrent Unit cell with hidden size of EMBEDDING_SIZE.</span></span><br><span class="line">    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create an unrolled Recurrent Neural Networks to length of</span></span><br><span class="line">    <span class="comment"># MAX_DOCUMENT_LENGTH and passes word_list as inputs for each unit.</span></span><br><span class="line">    _, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Given encoding of RNN, take encoding of last step (e.g hidden size of the</span></span><br><span class="line">    <span class="comment"># neural network of last step) and pass it as features for logistic</span></span><br><span class="line">    <span class="comment"># regression over output classes.</span></span><br><span class="line">    target = tf.one_hot(target, <span class="number">15</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    logits = tf.contrib.layers.fully_connected(encoding, <span class="number">15</span>, activation_fn=<span class="keyword">None</span>)</span><br><span class="line">    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a training op.</span></span><br><span class="line">    train_op = tf.contrib.layers.optimize_loss(</span><br><span class="line">            loss,</span><br><span class="line">            tf.contrib.framework.get_global_step(),</span><br><span class="line">            optimizer=<span class="string">'Adam'</span>,</span><br><span class="line">            learning_rate=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (&#123;</span><br><span class="line">            <span class="string">'class'</span>: tf.argmax(logits, <span class="number">1</span>),</span><br><span class="line">            <span class="string">'prob'</span>: tf.nn.softmax(logits)</span><br><span class="line">    &#125;, loss, train_op)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model_fn = rnn_model</span><br><span class="line">classifier = learn.SKCompat(learn.Estimator(model_fn=model_fn))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train and predict</span></span><br><span class="line">classifier.fit(x_train, y_train, steps=<span class="number">1000</span>)</span><br><span class="line">y_predicted = classifier.predict(x_test)[<span class="string">'class'</span>]</span><br><span class="line">score = metrics.accuracy_score(y_test, y_predicted)</span><br><span class="line">print(<span class="string">'Accuracy: &#123;0:f&#125;'</span>.format(score))</span><br></pre></td></tr></table></figure>
<pre><code>INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: C:\Users\vip\AppData\Local\Temp\tmp1fdgvpeq
INFO:tensorflow:Using config: {&apos;_task_type&apos;: None, &apos;_task_id&apos;: 0, &apos;_cluster_spec&apos;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020B6B1DE5C0&gt;, &apos;_master&apos;: &apos;&apos;, &apos;_num_ps_replicas&apos;: 0, &apos;_num_worker_replicas&apos;: 0, &apos;_environment&apos;: &apos;local&apos;, &apos;_is_chief&apos;: True, &apos;_evaluation_master&apos;: &apos;&apos;, &apos;_train_distribute&apos;: None, &apos;_eval_distribute&apos;: None, &apos;_device_fn&apos;: None, &apos;_tf_config&apos;: gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, &apos;_tf_random_seed&apos;: None, &apos;_save_summary_steps&apos;: 100, &apos;_save_checkpoints_secs&apos;: 600, &apos;_log_step_count_steps&apos;: 100, &apos;_protocol&apos;: None, &apos;_session_config&apos;: None, &apos;_save_checkpoints_steps&apos;: None, &apos;_keep_checkpoint_max&apos;: 5, &apos;_keep_checkpoint_every_n_hours&apos;: 10000, &apos;_model_dir&apos;: &apos;C:\\Users\\vip\\AppData\\Local\\Temp\\tmp1fdgvpeq&apos;}
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into C:\Users\vip\AppData\Local\Temp\tmp1fdgvpeq\model.ckpt.
INFO:tensorflow:loss = 2.7080488, step = 1
INFO:tensorflow:global_step/sec: 23.1885
INFO:tensorflow:loss = 0.051642288, step = 101 (4.314 sec)
INFO:tensorflow:global_step/sec: 26.0637
INFO:tensorflow:loss = 0.00094055594, step = 201 (3.837 sec)
INFO:tensorflow:global_step/sec: 25.6373
INFO:tensorflow:loss = 0.00044845277, step = 301 (3.901 sec)
INFO:tensorflow:global_step/sec: 26.2068
INFO:tensorflow:loss = 0.00029878103, step = 401 (3.816 sec)
INFO:tensorflow:global_step/sec: 25.8688
INFO:tensorflow:loss = 0.00020871352, step = 501 (3.865 sec)
INFO:tensorflow:global_step/sec: 24.9545
INFO:tensorflow:loss = 0.00015666419, step = 601 (4.008 sec)
INFO:tensorflow:global_step/sec: 25.2118
INFO:tensorflow:loss = 0.00012052382, step = 701 (3.966 sec)
INFO:tensorflow:global_step/sec: 22.598
INFO:tensorflow:loss = 0.000109548244, step = 801 (4.426 sec)
INFO:tensorflow:global_step/sec: 25.2499
INFO:tensorflow:loss = 8.7993896e-05, step = 901 (3.959 sec)
INFO:tensorflow:Saving checkpoints for 1000 into C:\Users\vip\AppData\Local\Temp\tmp1fdgvpeq\model.ckpt.
INFO:tensorflow:Loss for final step: 8.049416e-05.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from C:\Users\vip\AppData\Local\Temp\tmp1fdgvpeq\model.ckpt-1000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
Accuracy: 0.950500
</code></pre>
                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/nlp/" rel="tag"># nlp</a>
                    </li>
                    
                    <li>
                        <a href="/tags/自然语言处理/" rel="tag"># 自然语言处理</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="NLP系列" href="/2019-03-21/nlp/4Text_Classification/Chapter2_Chapter1_Text_Classification_based_on_Deep_Learning/1.text-classification/">
            ← NLP系列
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="NLP系列" href="/2019-03-21/nlp/5Text_topic_extraction_and_representation_v2/1_tfidf_wordcloud/">
            NLP系列 →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#使用TensorFlow构建卷积神经网络完成新闻分类"><span class="toc-text">使用TensorFlow构建卷积神经网络完成新闻分类</span></a></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Pastor Dean &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020-01-16/thinking/Thinking modelBiological thinking Biological thinking looking at the business world from an evolutionary perspective/">Thinking modelBiological thinking Biological thinking: looking at the business world from an evolutionary perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-13/thinking/Modern Darwin Integrated Model  Biological Thinking Mode Opening God Perspective/">Modern Darwin Integrated Model Biological Thinking Mode Opening God is Perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-11/thinking/Metacognition Changing the stubborn thinking of the brain/">Metacognition Changing the stubborn thinking of the brain</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">Categories</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Biological-Thinking/">Biological Thinking</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cognitive-Neuroscience/">Cognitive Neuroscience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FFmpeg/">FFmpeg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MacOS/">MacOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PM/">PM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/RPC/">RPC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ubuntu/">Ubuntu</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Vim/">Vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/WebRTC/">WebRTC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deeplearn/">deeplearn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/http/">http</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machineLearning/">machineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/文摘/">文摘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构师/">架构师</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/知识图谱/">知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/">职业规划</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/个人提升/">个人提升</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机基础/">计算机基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机相关技术资料整理/">计算机相关技术资料整理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/认知升级/">认知升级</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财务自由/">财务自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财富自由/">财富自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">Tag Cloud</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/AI/" style="font-size: 14px;">AI</a> <a href="/tags/Android/" style="font-size: 14px;">Android</a> <a href="/tags/Biological/" style="font-size: 17.75px;">Biological</a> <a href="/tags/Browser/" style="font-size: 14px;">Browser</a> <a href="/tags/Business/" style="font-size: 16.5px;">Business</a> <a href="/tags/Cognitive/" style="font-size: 17.75px;">Cognitive</a> <a href="/tags/DeepLearning/" style="font-size: 15.25px;">DeepLearning</a> <a href="/tags/Docker/" style="font-size: 14px;">Docker</a> <a href="/tags/FFmpeg/" style="font-size: 21.5px;">FFmpeg</a> <a href="/tags/FastCGI/" style="font-size: 14px;">FastCGI</a> <a href="/tags/IP划分/" style="font-size: 14px;">IP划分</a> <a href="/tags/IP地址/" style="font-size: 14px;">IP地址</a> <a href="/tags/Knowledge-Graph/" style="font-size: 16.5px;">Knowledge Graph</a> <a href="/tags/Linux-Shell/" style="font-size: 14px;">Linux Shell</a> <a href="/tags/MacOS/" style="font-size: 15.25px;">MacOS</a> <a href="/tags/Neuroscience/" style="font-size: 17.75px;">Neuroscience</a> <a href="/tags/RPC/" style="font-size: 14px;">RPC</a> <a href="/tags/Thinking/" style="font-size: 17.75px;">Thinking</a> <a href="/tags/Tutorial/" style="font-size: 20.25px;">Tutorial</a> <a href="/tags/WebRTC/" style="font-size: 21.5px;">WebRTC</a> <a href="/tags/WebSocket/" style="font-size: 14px;">WebSocket</a> <a href="/tags/algorithm/" style="font-size: 15.25px;">algorithm</a> <a href="/tags/config/" style="font-size: 14px;">config</a> <a href="/tags/decisionTree/" style="font-size: 14px;">decisionTree</a> <a href="/tags/git/" style="font-size: 17.75px;">git</a> <a href="/tags/google-adsense/" style="font-size: 14px;">google adsense</a> <a href="/tags/hexo/" style="font-size: 17.75px;">hexo</a> <a href="/tags/http/" style="font-size: 17.75px;">http</a> <a href="/tags/knn/" style="font-size: 14px;">knn</a> <a href="/tags/lighttpd/" style="font-size: 15.25px;">lighttpd</a> <a href="/tags/mxnet/" style="font-size: 14px;">mxnet</a> <a href="/tags/mysql/" style="font-size: 22.75px;">mysql</a> <a href="/tags/nlp/" style="font-size: 24px;">nlp</a> <a href="/tags/nodejs/" style="font-size: 14px;">nodejs</a> <a href="/tags/openvpn/" style="font-size: 14px;">openvpn</a> <a href="/tags/other/" style="font-size: 15.25px;">other</a> <a href="/tags/paddle/" style="font-size: 14px;">paddle</a> <a href="/tags/planning/" style="font-size: 20.25px;">planning</a> <a href="/tags/pracitce/" style="font-size: 15.25px;">pracitce</a> <a href="/tags/rich/" style="font-size: 14px;">rich</a> <a href="/tags/shell/" style="font-size: 14px;">shell</a> <a href="/tags/svn/" style="font-size: 14px;">svn</a> <a href="/tags/ubuntu/" style="font-size: 14px;">ubuntu</a> <a href="/tags/vim/" style="font-size: 16.5px;">vim</a> <a href="/tags/webpack/" style="font-size: 14px;">webpack</a> <a href="/tags/webrtc/" style="font-size: 19px;">webrtc</a> <a href="/tags/个人发展/" style="font-size: 14px;">个人发展</a> <a href="/tags/互联网实事/" style="font-size: 14px;">互联网实事</a> <a href="/tags/外链/" style="font-size: 14px;">外链</a> <a href="/tags/提升个人思维/" style="font-size: 14px;">提升个人思维</a> <a href="/tags/文摘/" style="font-size: 15.25px;">文摘</a> <a href="/tags/斜杠青年/" style="font-size: 14px;">斜杠青年</a> <a href="/tags/机器学习/" style="font-size: 16.5px;">机器学习</a> <a href="/tags/架构师/" style="font-size: 14px;">架构师</a> <a href="/tags/测试工具/" style="font-size: 14px;">测试工具</a> <a href="/tags/睡后成长/" style="font-size: 14px;">睡后成长</a> <a href="/tags/睡后收入/" style="font-size: 14px;">睡后收入</a> <a href="/tags/税后收入/" style="font-size: 14px;">税后收入</a> <a href="/tags/笔记/" style="font-size: 14px;">笔记</a> <a href="/tags/自然语言处理/" style="font-size: 24px;">自然语言处理</a> <a href="/tags/视频流/" style="font-size: 15.25px;">视频流</a> <a href="/tags/计算机相关技术资料整理/" style="font-size: 14px;">计算机相关技术资料整理</a> <a href="/tags/认知升级/" style="font-size: 14px;">认知升级</a> <a href="/tags/限速/" style="font-size: 14px;">限速</a> <a href="/tags/面试/" style="font-size: 14px;">面试</a> <a href="/tags/项目管理/" style="font-size: 14px;">项目管理</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/images/favicon-16x16-next.png" alt="Pastor Dean">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Pastor Dean">Pastor Dean &copy; 2020</a>
			
				
			        <span hidden="true" id="/2019-03-21/nlp/4Text_Classification/Chapter2_Chapter1_Text_Classification_based_on_Deep_Learning/2.News_Classification_based_on_CNN/" class="leancloud-visitors" data-flag-title="NLP系列">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>


<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>



<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





</body>
</html>
