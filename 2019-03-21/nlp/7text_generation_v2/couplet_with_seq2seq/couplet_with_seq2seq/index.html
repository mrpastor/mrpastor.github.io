<!DOCTYPE html>
<html lang="en">







<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>NLP系列 | Pastor Dean</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="pastor">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/images/favicon-16x16-next.png">
	<link rel="apple-touch-icon" href="/images/favicon-16x16-next.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Pastor Dean">
	<meta property="og:type" content="article">
	<meta property="og:title" content="NLP系列 | Pastor Dean">
	<meta property="og:description" content>
	<meta property="og:url" content="https://mrpastor.github.io/2019-03-21/nlp/7text_generation_v2/couplet_with_seq2seq/couplet_with_seq2seq/">

	
	<meta property="article:published_time" content="2019-03-21T19:03:00+08:00"> 
	<meta property="article:author" content="pastor">
	<meta property="article:published_first" content="Pastor Dean, /2019-03-21/nlp/7text_generation_v2/couplet_with_seq2seq/couplet_with_seq2seq/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Pastor Dean">
                    <img src="/images/favicon-32x32-next.png" alt="Pastor Dean">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/ || home" title="home">home</a>
            </li>
            
            <li>
                <a href="/categories/ || th" title="categories">categories</a>
            </li>
            
            <li>
                <a href="/archives/ || archive" title="archives">archives</a>
            </li>
            
            <li>
                <a href="/tools/ || tools" title="tools">tools</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/mrpastor" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2019-03-21T11:19:18.000Z">
                    2019-03-21
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/NLP/">NLP</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">NLP系列</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h1 id="seq2seq构建写对联AI"><a href="#seq2seq构建写对联AI" class="headerlink" title="seq2seq构建写对联AI"></a>seq2seq构建写对联AI</h1><p>本案例代码参考<a href="https://github.com/wb14123/seq2seq-couplet" target="_blank" rel="noopener">基于google seq2seq的对联生成</a></p>
<h3 id="问题背景介绍"><a href="#问题背景介绍" class="headerlink" title="问题背景介绍"></a>问题背景介绍</h3><p>对联又称对子，对仗工整，平仄协调，是一字一音的汉文语言独特的艺术形式，是中国传统文化瑰宝。对联的上下联有着非常工整的对应关系，我们可以尝试使用神经网络学习对应关系，进而完成对对联任务，而之前提到的seq2seq模型，是非常典型的序列映射学习模型，可以在本场景下使用。</p>
<p><img alt class="post-img b-lazy" data-img="../img/couplet.jpeg" data-index="0" data-src="../img/couplet.jpeg"></p>
<h3 id="seq2seq对对联"><a href="#seq2seq对对联" class="headerlink" title="seq2seq对对联"></a>seq2seq对对联</h3><p>这里构建的对对联AI应用也是seq2seq模型，使用的就是我们在上一门中讲解到的模型。</p>
<p><img alt class="post-img b-lazy" data-img="../img/[1]_seq2seq_1.gif" data-index="1" data-src="../img/[1]_seq2seq_1.gif"></p>
<p><img alt class="post-img b-lazy" data-img="../img/[8]_seq2seq_8.gif" data-index="2" data-src="../img/[8]_seq2seq_8.gif"></p>
<p><img alt class="post-img b-lazy" data-img="../img/attention_tensor_dance.gif" data-index="3" data-src="../img/attention_tensor_dance.gif"></p>
<h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">序列截断与补齐，保持一样的长度</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">padding_seq</span><span class="params">(seq)</span>:</span></span><br><span class="line">    results = []</span><br><span class="line">    max_len = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> seq:</span><br><span class="line">        <span class="keyword">if</span> max_len &lt; len(s):</span><br><span class="line">            max_len = len(s)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(seq)):</span><br><span class="line">        l = max_len - len(seq[i])</span><br><span class="line">        results.append(seq[i] + [<span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> range(l)])</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">把文本序列映射为下标id序列</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_text</span><span class="params">(words, vocab_indices)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [vocab_indices[word] <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> word <span class="keyword">in</span> vocab_indices]</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">把输出的下标id序列映射回文本序列</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode_text</span><span class="params">(labels, vocabs, end_token = <span class="string">'&lt;/s&gt;'</span>)</span>:</span></span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> labels:</span><br><span class="line">        word = vocabs[idx]</span><br><span class="line">        <span class="keyword">if</span> word == end_token:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">' '</span>.join(results)</span><br><span class="line">        results.append(word)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">' '</span>.join(results)</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">加载词表</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_vocab</span><span class="params">(vocab_file)</span>:</span></span><br><span class="line">     f = open(vocab_file, <span class="string">'rb'</span>)</span><br><span class="line">     vocabs = [line.decode(<span class="string">'utf8'</span>)[:<span class="number">-1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> f]</span><br><span class="line">     f.close()</span><br><span class="line">     <span class="keyword">return</span> vocabs</span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">数据读取器</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SeqReader</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_file, target_file, vocab_file, batch_size,</span></span></span><br><span class="line"><span class="function"><span class="params">            queue_size = <span class="number">2048</span>, worker_size = <span class="number">2</span>, end_token = <span class="string">'&lt;/s&gt;'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            padding = True, max_len = <span class="number">50</span>)</span>:</span></span><br><span class="line">        self.input_file = input_file</span><br><span class="line">        self.target_file = target_file</span><br><span class="line">        self.end_token = end_token</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.padding = padding</span><br><span class="line">        self.max_len = max_len</span><br><span class="line">        <span class="comment"># 读取词汇表</span></span><br><span class="line">        self.vocabs = read_vocab(vocab_file)</span><br><span class="line">        <span class="comment"># 构建词汇与下标对应的字典</span></span><br><span class="line">        self.vocab_indices = dict((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(self.vocabs))</span><br><span class="line">        self.data_queue = Queue(queue_size)</span><br><span class="line">        self.worker_size = worker_size</span><br><span class="line">        <span class="comment"># 计算全量数据有多少个batch</span></span><br><span class="line">        <span class="keyword">with</span> open(self.input_file, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> i, l <span class="keyword">in</span> enumerate(f):</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            f.close()</span><br><span class="line">            self.single_lines = i+<span class="number">1</span></span><br><span class="line">        self.data_size = int(self.single_lines / batch_size)</span><br><span class="line">        self.data_pos = <span class="number">0</span></span><br><span class="line">        self._init_reader()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">        for i in range(self.worker_size):</span></span><br><span class="line"><span class="string">            t = Thread(target=self._init_reader())</span></span><br><span class="line"><span class="string">            t.daemon = True</span></span><br><span class="line"><span class="string">            t.start()</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取一个batch的数据</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read_single_data</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.data_pos &gt;= len(self.data):</span><br><span class="line">            random.shuffle(self.data)</span><br><span class="line">            self.data_pos = <span class="number">0</span></span><br><span class="line">        result = self.data[self.data_pos]</span><br><span class="line">        self.data_pos += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取数据到batch字典中</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            batch = &#123;<span class="string">'in_seq'</span>: [],</span><br><span class="line">                    <span class="string">'in_seq_len'</span>: [],</span><br><span class="line">                    <span class="string">'target_seq'</span>: [],</span><br><span class="line">                    <span class="string">'target_seq_len'</span>: []&#125;</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, self.batch_size):</span><br><span class="line">                item = self.read_single_data()</span><br><span class="line">                batch[<span class="string">'in_seq'</span>].append(item[<span class="string">'in_seq'</span>])</span><br><span class="line">                batch[<span class="string">'in_seq_len'</span>].append(item[<span class="string">'in_seq_len'</span>])</span><br><span class="line">                batch[<span class="string">'target_seq'</span>].append(item[<span class="string">'target_seq'</span>])</span><br><span class="line">                batch[<span class="string">'target_seq_len'</span>].append(item[<span class="string">'target_seq_len'</span>])</span><br><span class="line">            <span class="keyword">if</span> self.padding:</span><br><span class="line">                batch[<span class="string">'in_seq'</span>] = padding_seq(batch[<span class="string">'in_seq'</span>])</span><br><span class="line">                batch[<span class="string">'target_seq'</span>] = padding_seq(batch[<span class="string">'target_seq'</span>])</span><br><span class="line">            <span class="keyword">yield</span> batch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取文件，准备成序列对</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_reader</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.data = []</span><br><span class="line">        input_f = open(self.input_file, <span class="string">'rb'</span>)</span><br><span class="line">        target_f = open(self.target_file, <span class="string">'rb'</span>)</span><br><span class="line">        <span class="keyword">for</span> input_line <span class="keyword">in</span> input_f:</span><br><span class="line">            input_line = input_line.decode(<span class="string">'utf-8'</span>)[:<span class="number">-1</span>]</span><br><span class="line">            target_line = target_f.readline().decode(<span class="string">'utf-8'</span>)[:<span class="number">-1</span>]</span><br><span class="line">            input_words = [x <span class="keyword">for</span> x <span class="keyword">in</span> input_line.split(<span class="string">' '</span>) <span class="keyword">if</span> x != <span class="string">''</span>]</span><br><span class="line">            <span class="keyword">if</span> len(input_words) &gt;= self.max_len:</span><br><span class="line">                input_words = input_words[:self.max_len<span class="number">-1</span>]</span><br><span class="line">            input_words.append(self.end_token)</span><br><span class="line">            target_words = [x <span class="keyword">for</span> x <span class="keyword">in</span> target_line.split(<span class="string">' '</span>) <span class="keyword">if</span> x != <span class="string">''</span>]</span><br><span class="line">            <span class="keyword">if</span> len(target_words) &gt;= self.max_len:</span><br><span class="line">                target_words = target_words[:self.max_len<span class="number">-1</span>]</span><br><span class="line">            target_words = [<span class="string">'&lt;s&gt;'</span>,] + target_words</span><br><span class="line">            target_words.append(self.end_token)</span><br><span class="line">            in_seq = encode_text(input_words, self.vocab_indices)</span><br><span class="line">            target_seq = encode_text(target_words, self.vocab_indices)</span><br><span class="line">            self.data.append(&#123;</span><br><span class="line">                <span class="string">'in_seq'</span>: in_seq,</span><br><span class="line">                <span class="string">'in_seq_len'</span>: len(in_seq),</span><br><span class="line">                <span class="string">'target_seq'</span>: target_seq,</span><br><span class="line">                <span class="string">'target_seq_len'</span>: len(target_seq) - <span class="number">1</span></span><br><span class="line">            &#125;)</span><br><span class="line">        input_f.close()</span><br><span class="line">        target_f.close()</span><br><span class="line">        self.data_pos = len(self.data)</span><br></pre></td></tr></table></figure>
<h2 id="评估函数"><a href="#评估函数" class="headerlink" title="评估函数"></a>评估函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright 2017 Google Inc. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"># ==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""Python implementation of BLEU and smooth-BLEU.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This module provides a Python implementation of BLEU and smooth-BLEU.</span></span><br><span class="line"><span class="string">Smooth BLEU is computed following the method outlined in the paper:</span></span><br><span class="line"><span class="string">Chin-Yew Lin, Franz Josef Och. ORANGE: a method for evaluating automatic</span></span><br><span class="line"><span class="string">evaluation metrics for machine translation. COLING 2004.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_ngrams</span><span class="params">(segment, max_order)</span>:</span></span><br><span class="line">  <span class="string">"""Extracts all n-grams upto a given maximum order from an input segment.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    segment: text segment from which n-grams will be extracted.</span></span><br><span class="line"><span class="string">    max_order: maximum length in tokens of the n-grams returned by this</span></span><br><span class="line"><span class="string">        methods.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    The Counter containing all n-grams upto max_order in segment</span></span><br><span class="line"><span class="string">    with a count of how many times each n-gram occurred.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  ngram_counts = collections.Counter()</span><br><span class="line">  <span class="keyword">for</span> order <span class="keyword">in</span> range(<span class="number">1</span>, max_order + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(segment) - order + <span class="number">1</span>):</span><br><span class="line">      ngram = tuple(segment[i:i+order])</span><br><span class="line">      ngram_counts[ngram] += <span class="number">1</span></span><br><span class="line">  <span class="keyword">return</span> ngram_counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_bleu</span><span class="params">(reference_corpus, translation_corpus, max_order=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 smooth=False)</span>:</span></span><br><span class="line">  <span class="string">"""Computes BLEU score of translated segments against one or more references.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    reference_corpus: list of lists of references for each translation. Each</span></span><br><span class="line"><span class="string">        reference should be tokenized into a list of tokens.</span></span><br><span class="line"><span class="string">    translation_corpus: list of translations to score. Each translation</span></span><br><span class="line"><span class="string">        should be tokenized into a list of tokens.</span></span><br><span class="line"><span class="string">    max_order: Maximum n-gram order to use when computing BLEU score.</span></span><br><span class="line"><span class="string">    smooth: Whether or not to apply Lin et al. 2004 smoothing.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns:</span></span><br><span class="line"><span class="string">    3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram</span></span><br><span class="line"><span class="string">    precisions and brevity penalty.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  matches_by_order = [<span class="number">0</span>] * max_order</span><br><span class="line">  possible_matches_by_order = [<span class="number">0</span>] * max_order</span><br><span class="line">  reference_length = <span class="number">0</span></span><br><span class="line">  translation_length = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> (references, translation) <span class="keyword">in</span> zip(reference_corpus,</span><br><span class="line">                                       translation_corpus):</span><br><span class="line">    reference_length += min(len(r) <span class="keyword">for</span> r <span class="keyword">in</span> references)</span><br><span class="line">    translation_length += len(translation)</span><br><span class="line"></span><br><span class="line">    merged_ref_ngram_counts = collections.Counter()</span><br><span class="line">    <span class="keyword">for</span> reference <span class="keyword">in</span> references:</span><br><span class="line">      merged_ref_ngram_counts |= _get_ngrams(reference, max_order)</span><br><span class="line">    translation_ngram_counts = _get_ngrams(translation, max_order)</span><br><span class="line">    overlap = translation_ngram_counts &amp; merged_ref_ngram_counts</span><br><span class="line">    <span class="keyword">for</span> ngram <span class="keyword">in</span> overlap:</span><br><span class="line">      matches_by_order[len(ngram)<span class="number">-1</span>] += overlap[ngram]</span><br><span class="line">    <span class="keyword">for</span> order <span class="keyword">in</span> range(<span class="number">1</span>, max_order+<span class="number">1</span>):</span><br><span class="line">      possible_matches = len(translation) - order + <span class="number">1</span></span><br><span class="line">      <span class="keyword">if</span> possible_matches &gt; <span class="number">0</span>:</span><br><span class="line">        possible_matches_by_order[order<span class="number">-1</span>] += possible_matches</span><br><span class="line"></span><br><span class="line">  precisions = [<span class="number">0</span>] * max_order</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, max_order):</span><br><span class="line">    <span class="keyword">if</span> smooth:</span><br><span class="line">      precisions[i] = ((matches_by_order[i] + <span class="number">1.</span>) /</span><br><span class="line">                       (possible_matches_by_order[i] + <span class="number">1.</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">if</span> possible_matches_by_order[i] &gt; <span class="number">0</span>:</span><br><span class="line">        precisions[i] = (float(matches_by_order[i]) /</span><br><span class="line">                         possible_matches_by_order[i])</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        precisions[i] = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> min(precisions) &gt; <span class="number">0</span>:</span><br><span class="line">    p_log_sum = sum((<span class="number">1.</span> / max_order) * math.log(p) <span class="keyword">for</span> p <span class="keyword">in</span> precisions)</span><br><span class="line">    geo_mean = math.exp(p_log_sum)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    geo_mean = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  ratio = float(translation_length) / reference_length</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ratio &gt; <span class="number">1.0</span>:</span><br><span class="line">    bp = <span class="number">1.</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    bp = math.exp(<span class="number">1</span> - <span class="number">1.</span> / ratio)</span><br><span class="line"></span><br><span class="line">  bleu = geo_mean * bp</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (bleu, precisions, bp, ratio, translation_length, reference_length)</span><br></pre></td></tr></table></figure>
<h2 id="定义seq2seq"><a href="#定义seq2seq" class="headerlink" title="定义seq2seq"></a>定义seq2seq</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.layers <span class="keyword">import</span> core <span class="keyword">as</span> layers_core</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定LSTM的cell类型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getLayeredCell</span><span class="params">(layer_size, num_units, input_keep_prob,</span></span></span><br><span class="line"><span class="function"><span class="params">        output_keep_prob=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> rnn.MultiRNNCell([rnn.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(name=<span class="string">'basic_lstm_cell'</span>,num_units=num_units),</span><br><span class="line">        input_keep_prob, output_keep_prob) <span class="keyword">for</span> i <span class="keyword">in</span> range(layer_size)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 双向RNN</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bi_encoder</span><span class="params">(embed_input, in_seq_len, num_units, layer_size, input_keep_prob)</span>:</span></span><br><span class="line">    <span class="comment"># 对输入编码</span></span><br><span class="line">    bi_layer_size = int(layer_size / <span class="number">2</span>)</span><br><span class="line">    encode_cell_fw = getLayeredCell(bi_layer_size, num_units, input_keep_prob)</span><br><span class="line">    encode_cell_bw = getLayeredCell(bi_layer_size, num_units, input_keep_prob)</span><br><span class="line">    bi_encoder_output, bi_encoder_state = tf.nn.bidirectional_dynamic_rnn(</span><br><span class="line">            cell_fw = encode_cell_fw,</span><br><span class="line">            cell_bw = encode_cell_bw,</span><br><span class="line">            inputs = embed_input,</span><br><span class="line">            sequence_length = in_seq_len,</span><br><span class="line">            dtype = embed_input.dtype,</span><br><span class="line">            time_major = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接 编码的output和state</span></span><br><span class="line">    encoder_output = tf.concat(bi_encoder_output, <span class="number">-1</span>)</span><br><span class="line">    encoder_state = []</span><br><span class="line">    <span class="keyword">for</span> layer_id <span class="keyword">in</span> range(bi_layer_size):</span><br><span class="line">        encoder_state.append(bi_encoder_state[<span class="number">0</span>][layer_id])</span><br><span class="line">        encoder_state.append(bi_encoder_state[<span class="number">1</span>][layer_id])</span><br><span class="line">    encoder_state = tuple(encoder_state)</span><br><span class="line">    <span class="keyword">return</span> encoder_output, encoder_state</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加“注意力”的解码器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_decoder_cell</span><span class="params">(encoder_output, in_seq_len, num_units, layer_size,</span></span></span><br><span class="line"><span class="function"><span class="params">        input_keep_prob)</span>:</span></span><br><span class="line">    <span class="comment"># 可以选择不同的注意力机制</span></span><br><span class="line">    attention_mechanim = tf.contrib.seq2seq.BahdanauAttention(num_units,</span><br><span class="line">            encoder_output, in_seq_len, normalize = <span class="keyword">True</span>)</span><br><span class="line">    <span class="comment"># attention_mechanim = tf.contrib.seq2seq.LuongAttention(num_units,</span></span><br><span class="line">    <span class="comment">#         encoder_output, in_seq_len, scale = True)</span></span><br><span class="line">    cell = getLayeredCell(layer_size, num_units, input_keep_prob)</span><br><span class="line">    cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention_mechanim,</span><br><span class="line">            attention_layer_size=num_units)</span><br><span class="line">    <span class="keyword">return</span> cell</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出端的全连接层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decoder_projection</span><span class="params">(output, output_size)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.layers.dense(output, output_size, activation=<span class="keyword">None</span>,</span><br><span class="line">            use_bias=<span class="keyword">False</span>, name=<span class="string">'output_mlp'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练阶段解码器部分</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_decoder</span><span class="params">(encoder_output, in_seq_len, target_seq, target_seq_len,</span></span></span><br><span class="line"><span class="function"><span class="params">        encoder_state, num_units, layers, embedding, output_size,</span></span></span><br><span class="line"><span class="function"><span class="params">        input_keep_prob, projection_layer)</span>:</span></span><br><span class="line">    <span class="comment"># 解码结构的cell</span></span><br><span class="line">    decoder_cell = attention_decoder_cell(encoder_output, in_seq_len, num_units,</span><br><span class="line">            layers, input_keep_prob)</span><br><span class="line">    <span class="comment"># batch size</span></span><br><span class="line">    batch_size = tf.shape(in_seq_len)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 初始状态</span></span><br><span class="line">    init_state = decoder_cell.zero_state(batch_size, tf.float32).clone(</span><br><span class="line">            cell_state=encoder_state)</span><br><span class="line">    <span class="comment"># 训练器</span></span><br><span class="line">    helper = tf.contrib.seq2seq.TrainingHelper(</span><br><span class="line">                target_seq, target_seq_len, time_major=<span class="keyword">False</span>)</span><br><span class="line">    <span class="comment"># 解码器</span></span><br><span class="line">    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper,</span><br><span class="line">            init_state, output_layer=projection_layer)</span><br><span class="line">    <span class="comment"># 解码输出</span></span><br><span class="line">    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder,</span><br><span class="line">            maximum_iterations=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> outputs.rnn_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测阶段的解码过程</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">infer_decoder</span><span class="params">(encoder_output, in_seq_len, encoder_state, num_units, layers,</span></span></span><br><span class="line"><span class="function"><span class="params">        embedding, output_size, input_keep_prob, projection_layer)</span>:</span></span><br><span class="line">    decoder_cell = attention_decoder_cell(encoder_output, in_seq_len, num_units,</span><br><span class="line">            layers, input_keep_prob)</span><br><span class="line"></span><br><span class="line">    batch_size = tf.shape(in_seq_len)[<span class="number">0</span>]</span><br><span class="line">    init_state = decoder_cell.zero_state(batch_size, tf.float32).clone(</span><br><span class="line">            cell_state=encoder_state)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> start tokens and end tokens are hard code</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(</span></span><br><span class="line"><span class="string">            embedding, tf.fill([batch_size], 0), 1)</span></span><br><span class="line"><span class="string">    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper,</span></span><br><span class="line"><span class="string">            init_state, output_layer=projection_layer)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 使用beam search解码</span></span><br><span class="line">    decoder = tf.contrib.seq2seq.BeamSearchDecoder(</span><br><span class="line">        cell=decoder_cell,</span><br><span class="line">        embedding=embedding,</span><br><span class="line">        start_tokens=tf.fill([batch_size], <span class="number">0</span>),</span><br><span class="line">        end_token=<span class="number">1</span>,</span><br><span class="line">        initial_state=init_state,</span><br><span class="line">        beam_width=<span class="number">10</span>,</span><br><span class="line">        output_layer=projection_layer,</span><br><span class="line">        length_penalty_weight=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder,</span><br><span class="line">            maximum_iterations=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> outputs.sample_id</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 序列到序列模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seq2seq</span><span class="params">(in_seq, in_seq_len, target_seq, target_seq_len, vocab_size,</span></span></span><br><span class="line"><span class="function"><span class="params">        num_units, layers, dropout)</span>:</span></span><br><span class="line">    in_shape = tf.shape(in_seq)</span><br><span class="line">    batch_size = in_shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> target_seq != <span class="keyword">None</span>:</span><br><span class="line">        input_keep_prob = <span class="number">1</span> - dropout</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_keep_prob = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    projection_layer=layers_core.Dense(vocab_size, use_bias=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对输入和输出序列做embedding</span></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br><span class="line">        embedding = tf.get_variable(</span><br><span class="line">                name = <span class="string">'embedding'</span>,</span><br><span class="line">                shape = [vocab_size, num_units])</span><br><span class="line">    embed_input = tf.nn.embedding_lookup(embedding, in_seq, name=<span class="string">'embed_input'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 编码</span></span><br><span class="line">    encoder_output, encoder_state = bi_encoder(embed_input, in_seq_len,</span><br><span class="line">            num_units, layers, input_keep_prob)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解码</span></span><br><span class="line">    decoder_cell = attention_decoder_cell(encoder_output, in_seq_len, num_units,</span><br><span class="line">            layers, input_keep_prob)</span><br><span class="line">    batch_size = tf.shape(in_seq_len)[<span class="number">0</span>]</span><br><span class="line">    init_state = decoder_cell.zero_state(batch_size, tf.float32).clone(</span><br><span class="line">            cell_state=encoder_state)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> target_seq != <span class="keyword">None</span>:</span><br><span class="line">        embed_target = tf.nn.embedding_lookup(embedding, target_seq,</span><br><span class="line">                name=<span class="string">'embed_target'</span>)</span><br><span class="line">        helper = tf.contrib.seq2seq.TrainingHelper(</span><br><span class="line">                    embed_target, target_seq_len, time_major=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> start tokens and end tokens are hard code</span></span><br><span class="line">        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(</span><br><span class="line">                embedding, tf.fill([batch_size], <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">    decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper,</span><br><span class="line">            init_state, output_layer=projection_layer)</span><br><span class="line">    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder,</span><br><span class="line">            maximum_iterations=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">if</span> target_seq != <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> outputs.rnn_output</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> outputs.sample_id</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seq_loss</span><span class="params">(output, target, seq_len)</span>:</span></span><br><span class="line">    target = target[:, <span class="number">1</span>:]</span><br><span class="line">    cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output,</span><br><span class="line">            labels=target)</span><br><span class="line">    batch_size = tf.shape(target)[<span class="number">0</span>]</span><br><span class="line">    loss_mask = tf.sequence_mask(seq_len, tf.shape(output)[<span class="number">1</span>])</span><br><span class="line">    cost = cost * tf.to_float(loss_mask)</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_sum(cost) / tf.to_float(batch_size)</span><br></pre></td></tr></table></figure>
<h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, train_input_file, train_target_file,</span></span></span><br><span class="line"><span class="function"><span class="params">            test_input_file, test_target_file, vocab_file,</span></span></span><br><span class="line"><span class="function"><span class="params">            num_units, layers, dropout,</span></span></span><br><span class="line"><span class="function"><span class="params">            batch_size, learning_rate, output_dir,</span></span></span><br><span class="line"><span class="function"><span class="params">            save_step = <span class="number">100</span>, eval_step = <span class="number">1000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            param_histogram=False, restore_model=False,</span></span></span><br><span class="line"><span class="function"><span class="params">            init_train=True, init_infer=False)</span>:</span></span><br><span class="line">        self.num_units = num_units</span><br><span class="line">        self.layers = layers</span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        self.save_step = save_step</span><br><span class="line">        self.eval_step = eval_step</span><br><span class="line">        self.param_histogram = param_histogram</span><br><span class="line">        self.restore_model = restore_model</span><br><span class="line">        self.init_train = init_train</span><br><span class="line">        self.init_infer = init_infer</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> init_train:</span><br><span class="line">            self.train_reader = SeqReader(train_input_file,</span><br><span class="line">                    train_target_file, vocab_file, batch_size)</span><br><span class="line">            self.train_reader.start()</span><br><span class="line">            self.train_data = self.train_reader.read()</span><br><span class="line">            self.eval_reader = SeqReader(test_input_file, test_target_file,</span><br><span class="line">                    vocab_file, batch_size)</span><br><span class="line">            self.eval_reader.start()</span><br><span class="line">            self.eval_data = self.eval_reader.read()</span><br><span class="line"></span><br><span class="line">        self.model_file = path.join(output_dir, <span class="string">'model.ckpl'</span>)</span><br><span class="line">        self.log_writter = tf.summary.FileWriter(output_dir)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> init_train:</span><br><span class="line">            self._init_train()</span><br><span class="line">            self._init_eval()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> init_infer:</span><br><span class="line">            self.infer_vocabs =read_vocab(vocab_file)</span><br><span class="line">            self.infer_vocab_indices = dict((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span></span><br><span class="line">                    enumerate(self.infer_vocabs))</span><br><span class="line">            self._init_infer()</span><br><span class="line">            self.reload_infer_model()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gpu_session_config</span><span class="params">(self)</span>:</span></span><br><span class="line">        config = tf.ConfigProto()</span><br><span class="line">        config.gpu_options.allow_growth = <span class="keyword">True</span></span><br><span class="line">        <span class="keyword">return</span> config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_train</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.train_graph = tf.Graph()</span><br><span class="line">        <span class="keyword">with</span> self.train_graph.as_default():</span><br><span class="line">            self.train_in_seq = tf.placeholder(tf.int32, shape=[self.batch_size, <span class="keyword">None</span>])</span><br><span class="line">            self.train_in_seq_len = tf.placeholder(tf.int32, shape=[self.batch_size])</span><br><span class="line">            self.train_target_seq = tf.placeholder(tf.int32, shape=[self.batch_size, <span class="keyword">None</span>])</span><br><span class="line">            self.train_target_seq_len = tf.placeholder(tf.int32, shape=[self.batch_size])</span><br><span class="line">            output = seq2seq(self.train_in_seq, self.train_in_seq_len,</span><br><span class="line">                    self.train_target_seq, self.train_target_seq_len,</span><br><span class="line">                    len(self.train_reader.vocabs),</span><br><span class="line">                    self.num_units, self.layers, self.dropout)</span><br><span class="line">            self.train_output = tf.argmax(tf.nn.softmax(output), <span class="number">2</span>)</span><br><span class="line">            self.loss = seq_loss(output, self.train_target_seq,</span><br><span class="line">                    self.train_target_seq_len)</span><br><span class="line">            params = tf.trainable_variables()</span><br><span class="line">            gradients = tf.gradients(self.loss, params)</span><br><span class="line">            clipped_gradients, _ = tf.clip_by_global_norm(</span><br><span class="line">                        gradients, <span class="number">0.5</span>)</span><br><span class="line">            self.train_op = tf.train.AdamOptimizer(</span><br><span class="line">                    learning_rate=self.learning_rate</span><br><span class="line">                ).apply_gradients(zip(clipped_gradients,params))</span><br><span class="line">            <span class="keyword">if</span> self.param_histogram:</span><br><span class="line">                <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">                    tf.summary.histogram(<span class="string">'train_'</span> + v.name, v)</span><br><span class="line">            tf.summary.scalar(<span class="string">'loss'</span>, self.loss)</span><br><span class="line">            self.train_summary = tf.summary.merge_all()</span><br><span class="line">            self.train_init = tf.global_variables_initializer()</span><br><span class="line">            self.train_saver = tf.train.Saver()</span><br><span class="line">        self.train_session = tf.Session(graph=self.train_graph,</span><br><span class="line">                config=self.gpu_session_config())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_eval</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.eval_graph = tf.Graph()</span><br><span class="line">        <span class="keyword">with</span> self.eval_graph.as_default():</span><br><span class="line">            self.eval_in_seq = tf.placeholder(tf.int32, shape=[self.batch_size, <span class="keyword">None</span>])</span><br><span class="line">            self.eval_in_seq_len = tf.placeholder(tf.int32, shape=[self.batch_size])</span><br><span class="line">            self.eval_output = seq2seq(self.eval_in_seq,</span><br><span class="line">                    self.eval_in_seq_len, <span class="keyword">None</span>, <span class="keyword">None</span>,</span><br><span class="line">                    len(self.eval_reader.vocabs),</span><br><span class="line">                    self.num_units, self.layers, self.dropout)</span><br><span class="line">            <span class="keyword">if</span> self.param_histogram:</span><br><span class="line">                <span class="keyword">for</span> v <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">                    tf.summary.histogram(<span class="string">'eval_'</span> + v.name, v)</span><br><span class="line">            self.eval_summary = tf.summary.merge_all()</span><br><span class="line">            self.eval_saver = tf.train.Saver()</span><br><span class="line">        self.eval_session = tf.Session(graph=self.eval_graph,</span><br><span class="line">                config=self.gpu_session_config())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_infer</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.infer_graph = tf.Graph()</span><br><span class="line">        <span class="keyword">with</span> self.infer_graph.as_default():</span><br><span class="line">            self.infer_in_seq = tf.placeholder(tf.int32, shape=[<span class="number">1</span>, <span class="keyword">None</span>])</span><br><span class="line">            self.infer_in_seq_len = tf.placeholder(tf.int32, shape=[<span class="number">1</span>])</span><br><span class="line">            self.infer_output = seq2seq(self.infer_in_seq,</span><br><span class="line">                    self.infer_in_seq_len, <span class="keyword">None</span>, <span class="keyword">None</span>,</span><br><span class="line">                    len(self.infer_vocabs),</span><br><span class="line">                    self.num_units, self.layers, self.dropout)</span><br><span class="line">            self.infer_saver = tf.train.Saver()</span><br><span class="line">        self.infer_session = tf.Session(graph=self.infer_graph,</span><br><span class="line">                config=self.gpu_session_config())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, epochs, start=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.init_train:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">'Train graph is not inited!'</span>)</span><br><span class="line">        <span class="keyword">with</span> self.train_graph.as_default():</span><br><span class="line">            <span class="keyword">if</span> path.isfile(self.model_file + <span class="string">'.meta'</span>) <span class="keyword">and</span> self.restore_model:</span><br><span class="line">                print(<span class="string">"Reloading model file before training."</span>)</span><br><span class="line">                self.train_saver.restore(self.train_session, self.model_file)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.train_session.run(self.train_init)</span><br><span class="line">            total_loss = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(start, epochs):</span><br><span class="line">                data = next(self.train_data)</span><br><span class="line">                in_seq = data[<span class="string">'in_seq'</span>]</span><br><span class="line">                in_seq_len = data[<span class="string">'in_seq_len'</span>]</span><br><span class="line">                target_seq = data[<span class="string">'target_seq'</span>]</span><br><span class="line">                target_seq_len = data[<span class="string">'target_seq_len'</span>]</span><br><span class="line">                output, loss, train, summary = self.train_session.run(</span><br><span class="line">                        [self.train_output, self.loss, self.train_op, self.train_summary],</span><br><span class="line">                        feed_dict=&#123;</span><br><span class="line">                            self.train_in_seq: in_seq,</span><br><span class="line">                            self.train_in_seq_len: in_seq_len,</span><br><span class="line">                            self.train_target_seq: target_seq,</span><br><span class="line">                            self.train_target_seq_len: target_seq_len&#125;)</span><br><span class="line">                total_loss += loss</span><br><span class="line">                self.log_writter.add_summary(summary, step)</span><br><span class="line">                <span class="keyword">if</span> step % self.save_step == <span class="number">0</span>:</span><br><span class="line">                    self.train_saver.save(self.train_session, self.model_file)</span><br><span class="line">                    print(<span class="string">"Saving model. Step: %d, loss: %f"</span> % (step,</span><br><span class="line">                        total_loss / self.save_step))</span><br><span class="line">                    <span class="comment"># print sample output</span></span><br><span class="line">                    sid = random.randint(<span class="number">0</span>, self.batch_size<span class="number">-1</span>)</span><br><span class="line">                    input_text =decode_text(in_seq[sid],</span><br><span class="line">                        self.eval_reader.vocabs)</span><br><span class="line">                    output_text =decode_text(output[sid],</span><br><span class="line">                            self.train_reader.vocabs)</span><br><span class="line">                    target_text =decode_text(target_seq[sid],</span><br><span class="line">                            self.train_reader.vocabs).split(<span class="string">' '</span>)[<span class="number">1</span>:]</span><br><span class="line">                    target_text = <span class="string">' '</span>.join(target_text)</span><br><span class="line">                    print(<span class="string">'******************************'</span>)</span><br><span class="line">                    print(<span class="string">'src: '</span> + input_text)</span><br><span class="line">                    print(<span class="string">'output: '</span> + output_text)</span><br><span class="line">                    print(<span class="string">'target: '</span> + target_text)</span><br><span class="line">                <span class="keyword">if</span> step % self.eval_step == <span class="number">0</span>:</span><br><span class="line">                    bleu_score = self.eval(step)</span><br><span class="line">                    print(<span class="string">"Evaluate model. Step: %d, score: %f, loss: %f"</span> % (</span><br><span class="line">                        step, bleu_score, total_loss / self.save_step))</span><br><span class="line">                    eval_summary = tf.Summary(value=[tf.Summary.Value(</span><br><span class="line">                        tag=<span class="string">'bleu'</span>, simple_value=bleu_score)])</span><br><span class="line">                    self.log_writter.add_summary(eval_summary, step)</span><br><span class="line">                <span class="keyword">if</span> step % self.save_step == <span class="number">0</span>:</span><br><span class="line">                    total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评估</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eval</span><span class="params">(self, train_step)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> self.eval_graph.as_default():</span><br><span class="line">            self.eval_saver.restore(self.eval_session, self.model_file)</span><br><span class="line">            bleu_score = <span class="number">0</span></span><br><span class="line">            target_results = []</span><br><span class="line">            output_results = []</span><br><span class="line">            <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">0</span>, self.eval_reader.data_size):</span><br><span class="line">                data = next(self.eval_data)</span><br><span class="line">                in_seq = data[<span class="string">'in_seq'</span>]</span><br><span class="line">                in_seq_len = data[<span class="string">'in_seq_len'</span>]</span><br><span class="line">                target_seq = data[<span class="string">'target_seq'</span>]</span><br><span class="line">                target_seq_len = data[<span class="string">'target_seq_len'</span>]</span><br><span class="line">                outputs = self.eval_session.run(</span><br><span class="line">                        self.eval_output,</span><br><span class="line">                        feed_dict=&#123;</span><br><span class="line">                            self.eval_in_seq: in_seq,</span><br><span class="line">                            self.eval_in_seq_len: in_seq_len&#125;)</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(len(outputs)):</span><br><span class="line">                    output = outputs[i]</span><br><span class="line">                    target = target_seq[i]</span><br><span class="line">                    output_text =decode_text(output,</span><br><span class="line">                            self.eval_reader.vocabs).split(<span class="string">' '</span>)</span><br><span class="line">                    target_text =decode_text(target[<span class="number">1</span>:],</span><br><span class="line">                            self.eval_reader.vocabs).split(<span class="string">' '</span>)</span><br><span class="line">                    prob = int(self.eval_reader.data_size * self.batch_size / <span class="number">10</span>)</span><br><span class="line">                    target_results.append([target_text])</span><br><span class="line">                    output_results.append(output_text)</span><br><span class="line">                    <span class="keyword">if</span> random.randint(<span class="number">1</span>, prob) == <span class="number">1</span>:</span><br><span class="line">                        print(<span class="string">'===================='</span>)</span><br><span class="line">                        input_text =decode_text(in_seq[i],</span><br><span class="line">                                self.eval_reader.vocabs)</span><br><span class="line">                        print(<span class="string">'src:'</span> + input_text)</span><br><span class="line">                        print(<span class="string">'output: '</span> + <span class="string">' '</span>.join(output_text))</span><br><span class="line">                        print(<span class="string">'target: '</span> + <span class="string">' '</span>.join(target_text))</span><br><span class="line">            <span class="keyword">return</span> compute_bleu(target_results, output_results)[<span class="number">0</span>] * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reload_infer_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">with</span> self.infer_graph.as_default():</span><br><span class="line">            self.infer_saver.restore(self.infer_session, self.model_file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">infer</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.init_infer:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">'Infer graph is not inited!'</span>)</span><br><span class="line">        <span class="keyword">with</span> self.infer_graph.as_default():</span><br><span class="line">            in_seq =encode_text(text.split(<span class="string">' '</span>) + [<span class="string">'&lt;/s&gt;'</span>,],</span><br><span class="line">                    self.infer_vocab_indices)</span><br><span class="line">            in_seq_len = len(in_seq)</span><br><span class="line">            outputs = self.infer_session.run(self.infer_output,</span><br><span class="line">                    feed_dict=&#123;</span><br><span class="line">                        self.infer_in_seq: [in_seq],</span><br><span class="line">                        self.infer_in_seq_len: [in_seq_len]&#125;)</span><br><span class="line">            output = outputs[<span class="number">0</span>]</span><br><span class="line">            output_text =decode_text(output, self.infer_vocabs)</span><br><span class="line">            <span class="keyword">return</span> output_text</span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">m = Model(</span><br><span class="line">        <span class="string">'./couplet/train/in.txt'</span>,</span><br><span class="line">        <span class="string">'./couplet/train/out.txt'</span>,</span><br><span class="line">        <span class="string">'./couplet/test/in.txt'</span>,</span><br><span class="line">        <span class="string">'./couplet/test/out.txt'</span>,</span><br><span class="line">        <span class="string">'./couplet/vocabs'</span>,</span><br><span class="line">        num_units=<span class="number">1024</span>, layers=<span class="number">4</span>, dropout=<span class="number">0.2</span>,</span><br><span class="line">        batch_size=<span class="number">32</span>, learning_rate=<span class="number">0.001</span>,</span><br><span class="line">        output_dir=<span class="string">'./models/output_couplet'</span>,</span><br><span class="line">        restore_model=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">m.train(<span class="number">5000000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /home/xiniu/.virtualenvs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py:417: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.
Instructions for updating:
seq_dim is deprecated, use seq_axis instead
WARNING:tensorflow:From /home/xiniu/.virtualenvs/tensorflow/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:432: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.
Instructions for updating:
batch_dim is deprecated, use batch_axis instead
Saving model. Step: 0, loss: 0.983172
******************************
src: 拾 云 补 我 丹 青 色
output: 邳 邳 汵 汵 汵 汵 码 汵 汵 釆 釆 芎 枞 芎 邳 邳 邳 邳 邳 邳 幮 幮 幮 幮 幮 幮 幮 幮
target: 留 白 遗 谁 锦 绣 文
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:当 阳 桥 下 英 雄 胆
output: 
target: 马 嵬 坡 前 美 女 魂
====================
src:身 逢 盛 世 ， 谁 舞 龙 头 兴 伟 业
output: 
target: 誉 满 神 州 ， 喜 看 科 大 展 雄 风
====================
src:四 面 涛 声 ， 万 里 黄 河 天 上 去
output: 
target: 重 霄 鹤 影 ， 一 川 碧 雪 画 中 飞
====================
src:三 秩 繁 荣 ， 万 众 同 圆 中 国 梦
output: 
target: 八 方 勤 奋 ， 九 州 齐 步 小 康 程
====================
src:家 山 依 旧 绿 ， 夕 照 微 红 ， 不 见 炊 烟 四 起
output: 
target: 鬓 发 已 然 衰 ， 乡 音 犹 在 ， 笑 邀 老 酒 同 沽
====================
src:古 道 寒 鸦 噪
output: 
target: 闲 池 老 鹤 栖
====================
src:醉 翁 亭 里 醉 醉 翁 ， 亭 醒 翁 醉
output: 
target: 上 阶 楼 内 上 上 阶 ， 楼 下 阶 上
====================
src:头 曲 三 曲 交 响 曲
output: 
target: 八 章 九 章 合 奏 章
====================
src:春 露 含 嫣 泛 紫 气
output: 
target: 野 花 吐 馨 迎 朝 阳
====================
src:裕 民 壮 志 兴 宏 业
output: 
target: 通 政 雄 才 展 大 猷
====================
src:想 当 年 抗 战 保 疆 ， 革 命 先 驱 忘 死 舍 生 ， 赢 胜 利 曙 光 初 吐
output: 
target: 看 今 日 开 来 继 往 ， 弄 潮 后 辈 扬 鞭 策 马 ， 创 辉 煌 夙 愿 终 圆
====================
src:尚 有 闲 情 摩 古 画
output: 
target: 坤 崇 厚 德 播 春 风
====================
src:一 剪 梅 花 三 弄 影
output: 
target: 万 年 春 梦 九 回 肠
====================
src:梦 窄 何 须 天 测
output: 
target: 心 宽 不 必 地 量
====================
src:黄 岳 霞 飞 ， 十 分 春 色 和 茶 煮
output: 
target: 皖 江 潮 涌 ， 一 派 涛 声 谐 韵 流
====================
src:长 天 易 启 逍 遥 意
output: 
target: 斗 室 难 囚 自 在 心
Evaluate model. Step: 0, score: 0.000000, loss: 0.983172
Saving model. Step: 100, loss: 69.179844
******************************
src: 酒 肉 僧 人 中 岳 客
output: 一 一 ， ， ， ，
target: 丹 青 和 尚 全 州 来
Saving model. Step: 200, loss: 64.788209
******************************
src: 树 倚 深 堂 秋 影 静
output: 月 月 月 月 月 月
target: 风 吹 小 月 雁 声 稀
Saving model. Step: 300, loss: 63.650225
******************************
src: 龙 虎 榜 中 人 第 一
output: 一 山 一 月 ， 春
target: 烟 花 队 里 醉 千 场
Saving model. Step: 400, loss: 62.874522
******************************
src: 三 勋 恩 泽 永
output: 一 年 一 春 春
target: 一 代 德 操 馨
Saving model. Step: 500, loss: 61.886383
******************************
src: 弃 汝 子 并 弃 汝 妻 ， 此 际 殊 多 不 了 事
output: 一 人 有 ， ， ， ， ， ， 有 有 有 有 人 人
target: 哭 吾 婿 亦 哭 吾 女 ， 从 今 永 作 未 亡 人
Saving model. Step: 600, loss: 62.753094
******************************
src: 山 吹 鸣 凤 曲
output: 月 月 月 花 香
target: 水 忆 钓 鱼 人
Saving model. Step: 700, loss: 64.927043
******************************
src: 秋 风 瑟 瑟 莲 花 落
output: 柳 月 柳 月 柳 柳 寒
target: 春 雨 潇 潇 竹 叶 青
Saving model. Step: 800, loss: 60.404067
******************************
src: 沿 途 都 是 灵 官 殿
output: 不 子 无 心 不 有 情
target: 大 劫 难 逃 白 虎 堂
Saving model. Step: 1000, loss: 60.141472
******************************
src: 句 里 寒 梅 香 淡 淡
output: 花 花 柳 水 醉 花 花
target: 画 中 少 女 乐 陶 陶
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:信 笔 书 绝 妙
output: 风 心 有 上 心
target: 随 机 应 变 通
====================
src:天 昊 昊 ， 地 茫 茫 ， 雄 姿 粗 犷 须 眉 气
output: 风 风 风 ， ， 月 ， ， ， 风 风 风 上 上 心
target: 水 潺 潺 ， 风 习 习 ， 俊 美 羞 赧 倩 女 情
====================
src:联 兴 五 载 ， 历 雪 经 霜 ， 卫 滨 大 地 联 花 艳
output: 春 风 春 ， ， ， 风 风 ， ， ， 风 风 风 海 海 春
target: 韵 振 千 秋 ， 陶 情 寄 志 ， 古 郡 楹 坛 韵 律 长
====================
src:月 出 深 峰 里
output: 花 花 月 水 花
target: 星 摇 积 浪 中
====================
src:南 北 东 西 ， 门 庭 若 市 初 一 好
output: 春 风 一 海 ， ， 风 一 万 万 万 春
target: 赵 钱 孙 李 ， 儿 女 满 堂 十 五 圆
====================
src:非 常 老 练 不 轻 举
output: 不 有 无 心 有 有 心
target: 特 别 从 容 勿 易 行
====================
src:穿 云 过 雨 逍 遥 燕
output: 竹 月 花 花 柳 水 花
target: 泼 墨 挥 毫 快 意 人
====================
src:时 过 境 迁 ， 古 道 斜 阳 悲 瘦 马
output: 风 风 水 月 ， ， 风 风 月 水 花 花
target: 珠 黄 人 老 ， 天 涯 芳 草 忆 华 年
====================
src:多 把 芳 菲 泛 春 酒
output: 风 风 无 月 月 月 花
target: 不 知 风 月 属 何 人
====================
src:再 见
output: 无 心
target: 频 过
====================
src:小 康 路 上 ， 尤 须 修 身 养 性
output: 心 心 有 ， ， ， 心 有 有 有 心
target: 奔 梦 途 中 ， 更 应 立 德 正 行
====================
src:吟 诗 最 喜 遇 佳 句
output: 月 月 春 风 水 水 花
target: 修 道 何 须 拜 圣 人
====================
src:春 雪 无 尘 空 四 大
output: 花 花 一 里 万 一 花
target: 慧 灯 有 耀 悟 群 生
====================
src:几 番 风 雨 ， 送 走 一 穷 二 白
output: 两 杯 一 月 ， ， 一 一 一 一 花
target: 六 十 春 秋 ， 迎 来 万 紫 千 红
====================
src:窗 含 一 卷 春 秋 画
output: 竹 月 花 花 月 水 花
target: 岭 蕴 千 行 雪 月 诗
====================
src:三 壶 浊 酒 愁 方 尽
output: 几 里 花 来 月 月 花
target: 一 夜 秋 风 恨 正 长
====================
src:九 重 天 子 垂 青 问
output: 几 里 无 心 一 里 心
target: 一 榻 先 生 卧 白 云
Evaluate model. Step: 1000, score: 0.000000, loss: 60.141472
Saving model. Step: 1100, loss: 59.905542
******************************
src: 天 鹅 展 翅 ， 文 化 飘 香 ， 三 门 胜 迹 邀 驴 友
output: 春 水 春 春 ， ， 千 千 ， ， ， 风 风 千 万 千 来
target: 佳 节 举 杯 ， 黄 河 助 兴 ， 廿 届 春 风 奋 马 蹄
Saving model. Step: 1200, loss: 59.397225
******************************
src: 道 德 开 基 ， 泽 流 山 海
output: 和 风 国 国 ， 国 国 国 春
target: 文 章 佐 世 ， 炳 焕 乾 坤
Saving model. Step: 1300, loss: 57.859651
******************************
src: 春 雨 兴 龙 角
output: 春 风 水 水 春
target: 秋 风 振 凤 毛
Saving model. Step: 1400, loss: 58.316416
******************************
src: 豪 气 冲 天 云 雾 散
output: 风 风 月 月 月 新 香
target: 雄 风 盖 世 口 碑 多
Saving model. Step: 1500, loss: 58.508467
******************************
src: 从 晋 陶 潜 入 此 村 来 ， 鸡 犬 相 闻 ， 一 桃 叶 青 了 一 竹 露
output: 人 风 一 ， ， ， ， ， ， 风 月 月 月 ， ， 一 一 一 一 一 千 心
target: 自 宋 苏 轼 吟 诗 句 道 ， 风 情 复 习 ， 几 野 桑 睡 着 几 家 蚕
Saving model. Step: 1600, loss: 58.547522
******************************
src: 南 国 飞 花 ， 嫣 红 姹 紫 ， 奋 起 龚 州 花 扮 美
output: 春 中 岁 彩 ， 春 春 春 春 ， 春 春 春 福 福 新 春
target: 西 江 流 韵 ， 播 瑞 腾 辉 ， 争 先 禹 甸 韵 生 香
Saving model. Step: 1700, loss: 57.584847
******************************
src: 锦 衾 重 自 暖
output: 人 月 有 无 人
target: 红 烛 剪 还 明
Saving model. Step: 1800, loss: 57.852394
******************************
src: 落 黄 心 绪 乱
output: 老 月 月 云 香
target: 飞 白 笔 锋 寒
Saving model. Step: 1900, loss: 57.353564
******************************
src: 大 刀 阔 斧 真 来 劲
output: 大 世 风 山 有 有 来
target: 小 米 步 枪 也 立 功
Saving model. Step: 2000, loss: 57.791187
******************************
src: 一 缕 乡 思 弹 不 断
output: 一 分 月 月 不 无 来
target: 几 丛 欲 草 剪 还 生
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:燕 舞 晴 空 ， 帘 前 细 赏 诗 中 画
output: 风 中 绿 月 ， 落 月 风 风 月 月 情
target: 牛 耕 沃 土 ， 岭 表 频 添 锦 上 花
====================
src:山 林 草 木 森 森 景
output: 日 下 风 风 入 白 风
target: 岭 岫 石 岩 磊 磊 峡
====================
src:信 笔 书 绝 妙
output: 清 风 月 有 来
target: 行 文 点 又 无
====================
src:崤 山 聚 首 ， 搭 优 势 平 台 ， 异 彩 三 门 春 正 好
output: 大 日 同 中 ， ， ， 风 风 国 ， 千 风 风 月 梦 新 来
target: 中 部 联 姻 ， 促 良 缘 盛 事 ， 神 州 六 骏 梦 同 圆
====================
src:有 风 伏 热
output: 无 月 无 香
target: 无 雨 冬 晴
====================
src:彩 凤 鸣 岗 ， 人 文 故 里 翻 新 韵
output: 春 风 焕 月 ， 喜 风 风 风 月 国 情
target: 金 鸡 报 晓 ， 礼 乐 源 头 唱 好 春
====================
src:大 漠 燃 情 ， 大 道 飞 花 ， 新 程 共 享 千 秋 岁
output: 新 来 大 日 ， ， 春 春 国 ， ， 春 春 万 万 里 春
target: 天 山 起 舞 ， 天 池 溢 彩 ， 疆 域 同 歌 万 里 春
====================
src:竹 影 摇 明 月
output: 风 风 落 白 风
target: 柳 枝 舞 劲 风
====================
src:汽 笛 啸 云 端 ， 拓 破 天 荒 ， 畅 驭 金 龙 腾 屋 脊
output: 大 山 扬 大 气 ， ， 春 春 国 ， ， 风 风 气 展 春 春
target: 春 风 融 雪 域 ， 舒 通 国 脉 ， 平 铺 铁 轨 逼 珠 峰
====================
src:无 多 风 雨 闲 敲 句
output: 无 有 风 风 有 有 情
target: 小 有 壶 觞 可 对 花
====================
src:有 弟 为 僧 ， 眉 头 常 聚 神 仙 气
output: 无 心 有 月 ， 不 不 无 心 月 人 心
target: 欲 之 同 道 ， 心 里 难 抛 儿 女 情
Evaluate model. Step: 2000, score: 0.000000, loss: 57.791187
Saving model. Step: 2100, loss: 56.984802
******************************
src: 江 风 送 我 帆 尤 疾
output: 月 月 无 心 月 有 多
target: 春 色 迷 人 眼 欲 花
Saving model. Step: 2200, loss: 55.672489
******************************
src: 秋 日 融 融 ， 麻 将 数 桌 ， 小 赌 怡 情 真 惬 意
output: 风 风 一 月 ， 一 秋 春 里 ， 一 来 风 月 醉 清 风
target: 晚 风 爽 爽 ， 欢 歌 几 曲 ， 畅 抒 顺 气 好 开 心
Saving model. Step: 2300, loss: 55.791397
******************************
src: 虎 落 平 阳 ， 鸡 飞 狗 走
output: 春 开 玉 月 ， 大 展 春 香
target: 龙 临 小 岛 ， 燕 舞 莺 歌
Saving model. Step: 2400, loss: 54.259680
******************************
src: 百 座 琼 楼 临 水 畔
output: 一 帘 秋 水 醉 风 诗
target: 几 间 陋 室 傍 山 隈
Saving model. Step: 2500, loss: 54.634726
******************************
src: 柳 岸 蜿 蜒 濡 绿 带
output: 梅 花 入 水 醉 红 红
target: 词 风 凄 婉 漫 红 楼
Saving model. Step: 2600, loss: 54.626771
******************************
src: 非 常 之 举 ， 莫 名 其 妙
output: 不 不 不 心 ， 不 有 不 生
target: 特 别 无 言 ， 不 懂 何 因
Saving model. Step: 2700, loss: 54.737775
******************************
src: 折 柳 问 君 春 几 许
output: 寒 花 似 月 月 三 秋
target: 临 梅 把 酒 月 三 更
Saving model. Step: 2800, loss: 54.746768
******************************
src: 心 诚 自 有 门 前 客
output: 世 在 常 无 世 里 人
target: 酒 好 定 来 座 上 宾
Saving model. Step: 2900, loss: 54.268380
******************************
src: 仰 社 稷 嘉 风 ， 登 高 以 远
output: 看 心 心 大 气 ， 大 业 无 来
target: 标 乾 坤 正 气 ， 鼎 盛 而 昌
Saving model. Step: 3000, loss: 53.481878
******************************
src: 凡 颖 自 殊 擢 秀 日
output: 春 心 不 有 作 天 天
target: 道 人 独 饿 填 空 肠
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:和 谐 世 博 园 ， 广 厦 万 间 先 得 月
output: 大 大 春 春 气 ， 千 秋 一 里 不 成 天
target: 奥 秘 空 中 站 ， 神 舟 八 号 试 飞 天
====================
src:舜 地 铺 春 ， 又 是 一 年 盛 景
output: 新 风 逐 梦 ， 共 来 万 里 新
target: 农 民 创 富 ， 还 依 四 代 雄 风
====================
src:落 雪 梨 花 一 地 香 ， 甚 喜
output: 清 风 柳 月 无 一 曲 ， 春 流
target: 接 天 荷 叶 无 穷 碧 ， 壮 观
====================
src:白 醙 香 浮 蝶 恋 花 ， 密 密 细 窥 涤 器
output: 青 风 落 落 风 风 水 ， 清 来 一 点 成 风
target: 青 帘 影 动 莺 穿 柳 ， 声 声 高 叫 提 壶
====================
src:硬 齿 先 亡 ， 柔 舌 后 已 ， 千 古 几 人 明 道 理
output: 清 风 不 在 ， 一 千 秋 一 ， 一 秋 一 里 醉 人 人
target: 苍 鹰 断 翅 ， 麻 雀 回 窝 ， 不 同 各 异 度 生 涯
====================
src:不 惧 身 残 ， 心 灯 更 比 华 灯 亮
output: 无 来 意 意 ， 人 意 无 来 不 意 多
target: 当 惊 志 壮 ， 盲 道 咸 同 锦 道 宽
====================
src:春 风 盛 世 花 千 树
output: 岁 气 和 风 岁 万 年
target: 骏 业 豪 情 酒 一 杯
Evaluate model. Step: 3000, score: 0.265031, loss: 53.481878
Saving model. Step: 3100, loss: 54.348823
******************************
src: 常 从 曹 宪 识 难 字
output: 不 是 高 心 不 自 人
target: 喜 与 王 充 释 异 书
Saving model. Step: 3200, loss: 53.547293
******************************
src: 一 寸 光 阴 二 寸 金 ， 年 年 看 涨
output: 一 年 山 上 千 千 风 ， 月 月 长 来
target: 千 般 风 雨 万 般 事 ， 比 比 皆 非
Saving model. Step: 3300, loss: 52.863027
******************************
src: 零 落 雨 中 花 ， 春 梦 惊 回 栖 凤 宅
output: 长 春 风 雅 水 ， 春 风 一 在 醉 云 香
target: 绸 缪 天 下 事 ， 壮 心 销 尽 石 鱼 斋
Saving model. Step: 3400, loss: 53.100193
******************************
src: 抛 诗 泼 墨 楹 联 热
output: 放 月 开 心 月 月 香
target: 挥 毫 铺 萱 宋 词 寒
Saving model. Step: 3500, loss: 52.764975
******************************
src: 云 龙 高 昂 ， 拖 一 脉 秀 水
output: 春 花 画 ， ， 一 一 重 新 人
target: 佛 光 普 照 ， 保 四 方 黎 民
Saving model. Step: 3600, loss: 52.881379
******************************
src: 拖 罗 一 饼 香 天 下
output: 绿 子 千 中 入 古 中
target: 钟 记 独 家 誉 岭 南
Saving model. Step: 3700, loss: 52.608606
******************************
src: 华 夏 空 中 ， 千 龙 飞 舞
output: 春 龙 大 下 ， 万 海 腾 飞
target: 复 兴 路 上 ， 万 马 奔 腾
Saving model. Step: 3800, loss: 52.226515
******************************
src: 原 汁 原 味 农 家 饭
output: 大 世 清 人 大 世 人
target: 糊 里 糊 涂 老 板 鞋
Saving model. Step: 3900, loss: 51.557316
******************************
src: 比 年 爱 读 漆 园 书 ， 喜 闻 天 上 大 椿 ， 植 根 曾 阅 八 千 岁
output: 把 世 生 情 来 大 地 ， 看 梦 春 山 春 水 ， 我 水 同 来 一 万 年
target: 此 地 尽 容 征 士 隐 ， 好 趁 篱 东 黄 菊 ， 漉 酒 连 倾 三 百 杯
Saving model. Step: 4000, loss: 51.337827
******************************
src: 明 月 探 花 鸡 尾 酒
output: 春 风 落 柳 柳 飞 花
target: 春 风 拂 柳 片 儿 汤
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:绣 幕
output: 书 机
target: 珠 帘
====================
src:要 使 见 闻 多 ， 一 席 满 时 ， 尽 勾 留 北 调 英 雄 ， 南 腔 儿 女
output: 不 来 真 旧 梦 ， 看 一 年 ， 一 年 ， 一 年 大 世 ， 大 世 大 人 人
target: 莫 教 风 月 老 ， 十 分 好 处 ， 但 献 出 壶 中 美 酒 ， 袖 里 鲜 花
====================
src:车 间 作 舞 台 ， 演 出 人 生 灿 烂
output: 世 里 同 新 梦 ， 欣 来 世 界 同 荣
target: 机 器 为 歌 手 ， 讴 成 曲 调 悠 扬
====================
src:快 意 恩 仇 终 了 断
output: 清 风 不 事 不 无 人
target: 忧 思 悲 喜 总 无 常
====================
src:纵 使 有 钱 难 买 命
output: 不 能 无 事 不 为 人
target: 须 知 无 药 可 医 贫
====================
src:遗 策
output: 重 孙
target: 秘 笈
====================
src:名 山 千 古 ， 名 宦 千 古
output: 大 世 一 州 ， 人 人 一 州
target: 斯 人 在 兹 ， 斯 文 在 兹
Evaluate model. Step: 4000, score: 0.411435, loss: 51.337827
Saving model. Step: 4100, loss: 50.553307
******************************
src: 几 度 朔 风 云 化 雨
output: 一 轮 秋 雨 月 含 春
target: 一 场 夜 雪 水 成 冰
Saving model. Step: 4200, loss: 51.389370
******************************
src: 门 前 鞍 马 稀 ， 不 行 乍 办
output: 世 上 梅 人 子 ， 何 可 相 知
target: 舍 下 贵 人 少 ， 最 好 能 来
Saving model. Step: 4300, loss: 50.467492
******************************
src: 旷 世 英 才 ， 民 族 英 雄 ， 戬 鬼 舞 长 缨 ， 碧 血 丹 心 真 铁 汉
output: 今 山 国 地 ， 民 华 ， ， ， 民 风 天 水 水 ， 青 心 大 水 耀 东 山
target: 滇 军 猛 士 ， 中 华 猛 将 ， 抛 头 射 落 日 ， 远 山 近 水 满 江 红
Saving model. Step: 4400, loss: 51.451502
******************************
src: 檐 下 雨 帘 檐 上 雾
output: 月 中 春 子 月 中 花
target: 水 中 人 影 水 边 情
Saving model. Step: 4500, loss: 51.797554
******************************
src: 身 居 梁 上 曾 为 客
output: 心 在 人 中 不 是 人
target: 名 播 天 涯 本 有 星
Saving model. Step: 4600, loss: 50.252081
******************************
src: 薄 酒 三 杯 酬 贵 客
output: 清 花 一 缕 醉 清 天
target: 红 花 两 朵 戴 新 人
Saving model. Step: 4700, loss: 50.528886
******************************
src: 他 石 攻 玉
output: 今 地 为 金
target: 上 台 出 联
Saving model. Step: 4800, loss: 50.704376
******************************
src: 蝶 梦 翩 翩 花 共 月
output: 梅 香 淡 舞 月 如 春
target: 箫 声 阵 阵 曲 含 春
Saving model. Step: 4900, loss: 49.776188
******************************
src: 直 上 楼 头 呵 月 饮
output: 闲 游 水 外 见 诗 飞
target: 偏 从 砚 底 读 梅 开
Saving model. Step: 5000, loss: 50.832852
******************************
src: 泪 眼 观 ， 山 河 破 碎 ， 走 南 闯 北 救 危 难
output: 文 康 下 ， 上 上 无 人 ， 把 我 中 中 上 后 雄
target: 赤 心 在 ， 生 死 全 抛 ， 经 夏 历 冬 存 英 名
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:海 颂 悲 歌 思 勤 劳 ， 慈 父 淳 朴 四 季
output: 民 生 大 世 无 民 德 ， 神 州 一 代 三 家
target: 山 披 素 带 挽 俭 节 ， 老 农 忠 厚 一 生
====================
src:两 语 三 言 敷 衍 话
output: 一 生 一 片 乐 成 心
target: 千 叮 万 嘱 赤 诚 谈
====================
src:未 曾 秋 至 鬓 先 老
output: 不 有 人 生 梦 不 寒
target: 写 到 春 来 心 不 甘
====================
src:竹 杖 芒 鞋 ， 伛 步 云 峰 ， 抚 膺 览 四 海
output: 春 风 玉 幄 ， 看 风 风 月 ， 引 笔 满 三 春
target: 菊 篱 岩 户 ， 悠 歌 雾 涧 ， 抒 志 焕 三 光
====================
src:风 花 雪 月 无 风 骨 ， 何 必 吟 风 弄 月
output: 月 雨 春 风 不 醉 情 ， 只 知 有 梦 如 风
target: 礼 易 诗 书 有 礼 节 ， 应 当 达 礼 知 书
====================
src:大 雪 翩 翩 铺 锦 笺 ， 碧 柳 添 诗 ， 飞 禽 绘 画
output: 春 风 浩 暖 红 红 ， 春 风 映 玉 水 ， 碧 水 飘 香
target: 白 银 冽 冽 妆 原 野 ， 红 梅 增 艳 ， 走 曽 描 花
====================
src:声 声 敲 碧 玉
output: 月 色 映 青 山
target: 岁 岁 乐 丰 年
====================
src:倦 倚 枫 亭 ， 紫 箫 语 断 惊 云 雁
output: 闲 开 柳 影 ， 柳 影 轻 香 醉 柳 花
target: 闲 行 柳 岸 ， 碧 水 情 长 映 月 宫
====================
src:格 物 致 知 真 学 问
output: 文 风 不 是 大 人 心
target: 扬 明 发 彩 见 襟 怀
====================
src:华 夏 启 新 航 ， 继 往 开 来 ， 金 蛇 狂 舞 岐 江 韵
output: 春 风 开 盛 世 ， 喜 今 盛 世 ， 盛 世 同 开 盛 世 图
target: 中 山 承 厚 德 ， 修 身 敬 业 ， 紫 燕 轻 裁 桂 岭 春
Evaluate model. Step: 5000, score: 0.405460, loss: 50.832852
Saving model. Step: 5100, loss: 49.901008
******************************
src: 和 风 牵 柳 臂 ， 澍 雨 吻 桃 腮 ， 偕 看 千 里 湖 山 谁 走 秀
output: 明 雨 入 青 香 ， 看 花 流 翠 水 ， 喜 看 一 湖 春 水 我 飘 天
target: 紫 燕 逐 花 潮 ， 黄 莺 嬉 麦 浪 ， 共 赏 三 春 郊 野 绿 登 台
Saving model. Step: 5200, loss: 50.370654
******************************
src: 田 边 排 立 ， 白 鹭 似 谙 耕 事 苦
output: 月 上 不 ， ， 青 心 不 有 梦 州 高
target: 墙 脚 急 鸣 ， 促 织 尤 懂 九 天 寒
Saving model. Step: 5300, loss: 50.063563
******************************
src: 沽 水 桅 樯 ， 揽 京 韵 杭 风 ， 撑 起 千 年 画 卷
output: 和 山 春 子 ， 听 人 生 大 展 ， 迎 一 万 代 文
target: 河 东 儿 女 ， 秉 人 文 科 技 ， 创 新 两 个 课 题
Saving model. Step: 5400, loss: 50.017901
******************************
src: 登 楼 弹 月 ， 兰 雪 堂 除 ， 西 望 长 安 千 古 地
output: 入 雨 飞 诗 ， 风 花 入 上 ， 天 风 共 在 万 江 春
target: 把 酒 吟 风 ， 杏 花 村 渡 ， 中 流 永 济 一 方 天
Saving model. Step: 5500, loss: 49.584595
******************************
src: 时 逆 潮 流 ， 我 行 僻 径
output: 我 开 月 去 ， 我 上 清 台
target: 笑 逐 野 水 ， 双 宿 兰 舟
Saving model. Step: 5600, loss: 49.290235
******************************
src: 真 人 大 意 ， 有 一 冰 壶 失 手
output: 无 政 无 花 ， 无 无 地 子 无 心
target: 智 者 细 心 ， 派 双 龙 子 托 之
Saving model. Step: 5700, loss: 49.065030
******************************
src: 夕 照 松 间 林 黛 玉
output: 春 流 水 上 柳 青 红
target: 春 风 陌 上 李 香 君
Saving model. Step: 5800, loss: 48.838600
******************************
src: 听 海 笑 人 欢 ， 喜 唱 九 州 永 泰
output: 迎 春 开 国 舞 ， 迎 来 万 海 新 新
target: 看 盐 丰 鱼 跃 ， 高 歌 四 域 长 春
Saving model. Step: 5900, loss: 48.563482
******************************
src: 须 效 灵 鲲 搏 瀚 海
output: 不 将 明 马 仰 青 天
target: 欲 栽 大 木 柱 长 天
Saving model. Step: 6000, loss: 48.982730
******************************
src: 嫩 蕊
output: 青 花
target: 枯 杈
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:果 大 江 气 韵 ， 千 载 人 文 ， 辉 煌 不 负 新 时 代
output: 看 大 地 新 风 ， 一 生 春 色 ， 春 色 同 描 大 地 人
target: 究 多 景 风 情 ， 一 城 绮 梦 ， 锦 绣 重 开 北 固 楼
====================
src:当 年 岁 月 燃 烧 ， 粮 山 棉 海 迎 红 日
output: 有 我 春 风 满 夜 ， 春 色 风 流 入 碧 阳
target: 此 际 城 乡 焕 彩 ， 锦 路 华 堂 庆 小 康
====================
src:惇 德 秉 义 ， 英 雄 进 步 三 国 志
output: 大 国 创 民 ， 国 粹 、 一 代 民 民
target: 智 水 仁 山 ， 胜 景 抒 怀 千 亩 坪
====================
src:娇 娃 血 性 浑 闲 事
output: 白 水 风 光 不 是 心
target: 壮 士 心 红 留 志 丹
====================
src:征 人 折 箭 恨
output: 对 月 伴 花 香
target: 闺 妇 卷 帘 愁
Evaluate model. Step: 6000, score: 0.672440, loss: 48.982730
Saving model. Step: 6100, loss: 48.831857
******************************
src: 临 风 诗 送 韵
output: 对 月 月 吟 情
target: 邀 月 酒 生 香
Saving model. Step: 6200, loss: 48.589330
******************************
src: 镇 河 山 而 稳 固 ， 藉 万 仞 九 嶷 ， 堪 为 砥 柱
output: 兴 史 子 、 以 歌 ， 看 九 千 万 脉 ， 共 是 英 图
target: 播 孝 德 以 馨 香 ， 溯 三 湘 一 带 ， 自 有 渊 源
Saving model. Step: 6300, loss: 47.900101
******************************
src: 背 倚 省 垣 ， 铸 辉 煌 不 惟 地 利
output: 心 怀 国 世 ， 扬 德 想 不 以 天 生
target: 时 当 盛 世 ， 求 发 展 全 仗 人 和
Saving model. Step: 6400, loss: 48.684890
******************************
src: 丝 弦 缱 绻 轻 盈 曲
output: 柳 影 轻 飞 不 落 心
target: 笔 墨 疏 狂 桀 骜 心
Saving model. Step: 6500, loss: 48.858344
******************************
src: 坐 下 来 养 养 精 神 ， 听 亭 中 南 腔 北 调
output: 看 西 上 来 开 大 下 ， 把 古 地 古 云 来 香
target: 攀 上 去 开 开 眼 界 ， 望 天 外 风 卷 云 舒
Saving model. Step: 6600, loss: 48.173863
******************************
src: 俗 世 无 边 多 际 遇
output: 春 生 有 意 有 真 心
target: 人 生 有 限 欠 机 缘
Saving model. Step: 6700, loss: 48.330225
******************************
src: 新 朋 旧 友 喜 临 门 ， 齐 夸 烹 饪 好
output: 大 地 新 山 新 好 地 ， 不 看 画 春 香
target: 海 味 山 珍 皆 入 馅 ， 远 胜 菜 根 香
Saving model. Step: 6800, loss: 48.219211
******************************
src: 生 财 猪 拱 户
output: 报 富 业 迎 春
target: 致 富 燕 迎 春
Saving model. Step: 6900, loss: 48.083381
******************************
src: 皆 道 小 风 周 末 好
output: 不 知 新 道 水 中 高
target: 可 知 方 竹 月 头 空
Saving model. Step: 7000, loss: 47.817075
******************************
src: 一 世 烟 花 空 落 寞
output: 几 杯 月 泪 不 成 遥
target: 半 生 纨 绔 自 逍 遥
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:海 气 百 重 楼 ， 岂 独 浮 云 能 蔽 日
output: 山 山 三 万 里 ， 不 能 一 月 不 如 春
target: 文 章 千 古 事 ， 萧 条 异 代 不 同 时
====================
src:遗 像 肃 清 高 ， 有 陨 自 天 ， 电 戟 霜 戈 沉 浩 气
output: 忠 贞 无 古 学 ， 无 私 不 负 ， 英 雄 俎 豆 壮 雄 风
target: 新 祠 严 壮 烈 ， 持 忠 入 地 ， 疾 风 劲 草 识 纯 臣
====================
src:空 溪 猿 狙 愁 啼 暮
output: 一 夜 春 风 月 落 香
target: 古 道 雁 行 倦 戏 秋
====================
src:言 志 抒 情 ， 两 行 文 字 千 秋 业
output: 文 章 作 意 ， 一 代 文 章 一 代 心
target: 挥 毫 泼 墨 ， 五 岳 烟 霞 万 副 联
====================
src:慕 君 有 志 蹈 火 赴 汤 ， 总 为 中 华 崛 起 ， 何 求 其 勋 昭 日 月
output: 为 我 为 人 死 以 忠 烈 ， 不 能 为 国 之 民 ， 不 能 为 国 壮 乾 坤
target: 教 我 无 私 忧 国 虑 民 ， 但 图 神 州 兴 旺 ， 敢 将 赤 胆 鉴 乾 坤
====================
src:高 人 往 往 行 低 调
output: 大 地 欣 来 爱 大 人
target: 俗 辈 常 常 做 佞 臣
====================
src:尚 有 闲 情 摩 古 画
output: 欲 无 好 酒 醉 新 诗
target: 坤 崇 厚 德 播 春 风
====================
src:稀 客 不 加 菜
output: 小 人 不 是 人
target: 熟 人 忙 递 烟
====================
src:寂 寞 花 开 难 自 主
output: 清 明 月 冷 不 知 人
target: 相 思 泪 落 已 无 由
====================
src:聊 斋 故 事 多 ， 老 鬼 出 山 犹 托 梦
output: 不 奈 春 风 去 ， 清 风 入 酒 不 知 人
target: 国 粹 知 音 少 ， 秋 风 听 雨 不 成 声
====================
src:清 风 入 卷 书 生 气
output: 明 月 无 情 月 色 情
target: 暮 蔼 凝 怀 老 朽 心
Evaluate model. Step: 7000, score: 0.840510, loss: 47.817075
Saving model. Step: 7100, loss: 48.333594
******************************
src: 人 生 来 去 本 虚 幻
output: 世 事 不 须 不 了 愁
target: 世 事 无 常 莫 较 真
Saving model. Step: 7200, loss: 47.943479
******************************
src: 梨 落 香 肩 衣 上 雪
output: 花 开 红 酒 酒 中 花
target: 絮 萦 素 手 指 间 云
Saving model. Step: 7300, loss: 47.429941
******************************
src: 国 正 天 心 顺
output: 国 高 国 富 兴
target: 官 清 民 自 安
Saving model. Step: 7400, loss: 47.439896
******************************
src: 几 髭 吟 断 敲 奇 句
output: 一 曲 吟 成 作 老 心
target: 五 典 翻 残 乞 僻 辞
Saving model. Step: 7500, loss: 46.708812
******************************
src: 心 游 书 海 香 无 染
output: 身 有 人 头 意 有 然
target: 情 系 笔 端 字 有 神
Saving model. Step: 7600, loss: 46.868555
******************************
src: 勤 能 得 业 为 良 友
output: 自 可 为 人 是 大 人
target: 有 益 身 心 在 好 书
Saving model. Step: 7700, loss: 46.917361
******************************
src: 空 喊 加 油 白 使 劲
output: 不 开 入 地 风 知 香
target: 偷 窥 上 瘾 不 甘 心
Saving model. Step: 7800, loss: 46.962515
******************************
src: 临 风 排 酒 闲 听 海
output: 把 月 听 弦 自 入 天
target: 邀 月 推 枰 欲 赋 诗
Saving model. Step: 7900, loss: 47.313086
******************************
src: 竹 影 涟 漪 迎 墨 客
output: 荷 香 淡 烂 醉 春 花
target: 菊 香 灿 烂 报 金 秋
Saving model. Step: 8000, loss: 46.684709
******************************
src: 举 世 无 伦 清 醒 者 ， 青 史 铭 忠 ， 屈 子 岂 输 比 干 少
output: 为 秋 有 片 有 心 心 ， 青 波 有 影 ， 人 山 犹 是 是 天 长
target: 千 秋 一 样 断 肠 人 ， 碧 潮 卷 恨 ， 汨 罗 犹 胜 海 塘 多
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:兰 襟 楚 楚 散 芳 泽
output: 竹 树 荷 花 醉 故 人
target: 玉 颜 亭 亭 与 花 双
====================
src:举 杯 歌 幸 福
output: 迎 春 庆 宏 图
target: 向 党 报 恩 情
====================
src:别 酒 心 先 醉
output: 清 风 意 自 闲
target: 去 舟 泪 已 潸
====================
src:炮 竹 响 亮 冲 九 宇
output: 龙 龙 腾 舞 耀 千 秋
target: 中 国 声 音 冠 全 球
====================
src:江 天 一 色 轰 轰 烈
output: 海 海 千 年 共 自 难
target: 杨 柳 千 丝 寸 寸 柔
====================
src:风 送 清 馨 盈 槛 外
output: 雨 摇 绿 水 醉 江 边
target: 心 仪 澄 碧 落 江 中
====================
src:终 一 统 河 山 ， 天 授 甲 图 铭 甲 意
output: 万 千 年 国 粹 ， 民 生 国 富 展 宏 图
target: 念 同 根 血 脉 ， 时 逢 申 岁 沸 申 江
====================
src:莲 叶 开 盘 ， 倏 尔 珍 珠 熠 熠
output: 荷 花 绕 影 ， 何 妨 玉 骨 悠 闲
target: 荷 花 醉 酒 ， 依 然 风 度 翩 翩
====================
src:贬 斥 失 德 ， 雷 锋 标 尺 身 前 立
output: 弘 扬 立 志 ， 社 稷 宏 图 国 外 兴
target: 宏 扬 正 义 ， 模 范 言 行 事 后 评
====================
src:羊 毫 作 笔 ， 书 华 夏 辉 煌 业 绩
output: 猴 岁 迎 春 ， 展 宏 图 壮 画 图 篇
target: 猴 棒 化 针 ， 绣 祖 国 美 丽 江 山
====================
src:锥 ， 锥 ， 锥 ， 锥 出 穷 鬼 去
output: 啐 ， 狗 噪 - ， - 出 上 头 来
target: 拉 ， 拉 ， 拉 ， 拉 进 财 神 来
====================
src:月 泻 清 辉 ， 风 送 桂 香 来 小 院
output: 花 开 绿 野 ， 雨 摇 绿 水 润 长 天
target: 湖 生 丽 景 ， 烟 笼 柳 色 舞 长 堤
====================
src:一 日 有 夫 一 日 贵
output: 三 分 无 日 半 天 春
target: 半 年 辛 苦 半 年 闲
====================
src:扬 眉 吐 气 ， 让 神 州 增 光 添 彩
output: 举 路 迎 春 ， 看 万 里 春 风 送 春
target: 飒 爽 英 姿 ， 为 祖 国 争 金 夺 银
====================
src:多 彩 田 园 谁 绘 出
output: 一 生 春 色 我 来 来
target: 无 穷 景 色 网 传 来
Evaluate model. Step: 8000, score: 0.786046, loss: 46.684709
Saving model. Step: 8100, loss: 46.606567
******************************
src: 红 叶 新 诗 霜 后 寄
output: 绿 花 白 竹 水 中 流
target: 玉 衣 金 缕 土 中 埋
Saving model. Step: 8200, loss: 47.552244
******************************
src: 寿 岁 有 涯 ， 安 心 即 乐
output: 春 年 无 处 ， 大 气 无 春
target: 嘉 名 长 在 ， 遗 墨 犹 温
Saving model. Step: 8300, loss: 47.340977
******************************
src: 既 悖 既 纯 ， 永 作 宪 矩
output: 其 诚 其 己 ， 可 为 其 头
target: 克 忠 克 力 ， 当 陟 台 阶
Saving model. Step: 8400, loss: 46.666164
******************************
src: 餐 风 宿 露 寻 芳 渚
output: 入 水 清 云 入 玉 园
target: 破 雾 穿 云 洗 旧 尘
Saving model. Step: 8500, loss: 45.909014
******************************
src: 动 物 猴 聪 颖
output: 迎 生 虎 自 车
target: 人 灵 我 笨 拙
Saving model. Step: 8600, loss: 45.818120
******************************
src: 政 善 人 和 ， 华 夏 皆 追 中 国 梦
output: 民 生 国 阜 ， 春 风 永 上 小 康 风
target: 民 丰 物 富 ， 陵 城 满 是 小 康 花
Saving model. Step: 8700, loss: 45.595134
******************************
src: 国 华 家 业 天 天 好
output: 国 丽 人 情 岁 色 新
target: 美 伴 柔 情 月 月 长
Saving model. Step: 8800, loss: 46.131187
******************************
src: 放 舟 去 揽 丰 都 梦
output: 踏 马 欣 开 大 发 春
target: 携 笛 来 吟 巴 国 春
Saving model. Step: 8900, loss: 45.774760
******************************
src: 房 新 院 美 人 常 乐
output: 户 暮 人 清 景 更 香
target: 日 丽 风 清 鸟 伴 歌
Saving model. Step: 9000, loss: 45.743536
******************************
src: 老 道 缚 云 闲 扫 观
output: 新 山 流 月 不 吟 游
target: 山 翁 邀 鹤 静 纹 枰
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:硬 齿 先 亡 ， 柔 舌 后 已 ， 千 古 几 人 明 道 理
output: 清 风 不 染 ， 清 风 一 片 ， 一 人 一 片 有 人 情
target: 苍 鹰 断 翅 ， 麻 雀 回 窝 ， 不 同 各 异 度 生 涯
====================
src:岸 随 春 水 阔
output: 风 到 水 光 凉
target: 舟 横 野 津 湾
====================
src:林 樱 古 乐 膺 银 奖
output: 玉 宇 新 辉 耀 白 云
target: 艺 术 新 团 奏 玉 筝
====================
src:儒 道 同 源 ， 诸 君 勉 力 国 方 治
output: 文 章 共 爱 ， 此 代 风 流 日 月 增
target: 慎 勤 为 要 ， 良 吏 敦 行 古 有 闻
====================
src:恨 容 偏 落 泪
output: 无 恨 不 伤 情
target: 娇 态 欲 沉 春
====================
src:负 手 千 山 寻 大 道
output: 开 心 一 曲 见 新 人
target: 泛 舟 一 叶 入 闲 云
Evaluate model. Step: 9000, score: 0.699609, loss: 45.743536
Saving model. Step: 9100, loss: 45.982395
******************************
src: 花 亚 深 秋 悲 冷 色
output: 月 飞 旧 梦 醉 新 情
target: 兰 交 同 气 契 真 情
Saving model. Step: 9200, loss: 46.162248
******************************
src: 一 曲 相 思 吟 到 老
output: 三 秋 寂 落 共 来 今
target: 千 般 落 寞 赋 成 诗
Saving model. Step: 9300, loss: 45.730751
******************************
src: 吞 一 万 里 长 江 ， 吐 八 百 里 洞 庭 ， 敢 教 天 下 波 涛 ， 尽 为 我 用
output: 观 千 千 年 日 韵 ， 看 千 载 人 华 ， ， 千 此 三 山 一 景 ， 共 在 人 来
target: 复 几 千 年 古 迹 ， 展 卅 余 年 画 卷 ， 饱 览 巴 陵 胜 概 ， 还 有 何 忧
Saving model. Step: 9400, loss: 46.646062
******************************
src: 小 诗 试 拟 孟 东 野
output: 大 笔 当 忘 小 南 人
target: 高 吟 不 减 谢 宣 城
Saving model. Step: 9500, loss: 46.041625
******************************
src: 好 汉 惜 好 汉
output: 老 君 是 真 人
target: 见 家 识 见 家
Saving model. Step: 9600, loss: 45.647432
******************************
src: 心 态 平 和 遗 憾 少
output: 心 情 浩 转 好 然 多
target: 风 姿 绰 约 自 如 多
Saving model. Step: 9700, loss: 45.687586
******************************
src: 佳 月 四 时 有 ， 更 把 浮 荣 喻 生 灭
output: 清 心 一 路 无 ， 无 能 一 念 念 心 尘
target: 归 舟 一 叶 轻 ， 不 将 真 性 染 埃 尘
Saving model. Step: 9800, loss: 45.655432
******************************
src: 共 赋 新 诗 发 宫 徵
output: 不 将 佳 韵 醉 山 天
target: 已 闻 清 乐 动 云 韵
Saving model. Step: 9900, loss: 44.503411
******************************
src: 西 极 燕 游 王 母 乐
output: 南 人 风 上 子 孙 欢
target: 后 宫 氏 族 子 夫 微
Saving model. Step: 10000, loss: 45.255381
******************************
src: 瑞 气 盈 门 人 财 旺
output: 春 云 接 户 春 地 新
target: 祥 光 满 堂 福 寿 兴
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:梅 意 若 痴 春 可 解
output: 柳 枝 如 绿 月 如 烟
target: 柔 情 似 水 月 能 知
====================
src:旧 街 建 旧 街 、 建 古 建 今 、 今 日 旧 街 街 不 旧
output: 大 地 迎 春 色 、 新 春 、 新 年 、 新 年 喜 梦 更 新
target: 新 集 修 新 集 、 修 前 修 后 、 后 期 新 集 集 常 新
====================
src:田 翁 杖 酒 还 如 梦
output: 柳 岸 飞 花 不 似 情
target: 朝 士 归 帆 且 趁 秋
====================
src:赊 副 醉 联 还 酒 债
output: 吟 来 雅 韵 醉 诗 情
target: 编 些 鬼 话 送 人 情
====================
src:青 鬓 玉 颜 长 似 旧
output: 红 尘 玉 笛 不 如 春
target: 鸳 鸯 翡 翠 两 争 新
====================
src:万 户 王 侯 尽 尘 土
output: 一 生 大 道 是 人 心
target: 千 秋 风 月 自 精 神
====================
src:金 果 洇 秋 寺
output: 金 光 照 古 今
target: 霜 花 净 梵 钟
====================
src:电 脑 游 玩 无 益 处
output: 人 心 不 老 不 知 人
target: 手 机 辛 苦 有 功 德
====================
src:贞 子 重 来 妖 魅 减
output: 神 州 不 必 老 文 明
target: 乃 哥 依 旧 赌 徒 多
====================
src:马 上 江 山 鞭 指 点
output: 人 间 世 界 步 蹄 头
target: 壶 中 岁 月 酒 消 磨
====================
src:三 尺 长 剑 平 天 下
output: 一 片 清 风 入 画 中
target: 两 寸 妙 笔 著 春 秋
Evaluate model. Step: 10000, score: 1.037887, loss: 45.255381
Saving model. Step: 10100, loss: 44.965087
******************************
src: 日 落 江 天 红 一 抹
output: 风 牵 月 地 乐 千 边
target: 心 思 祖 国 梦 无 垠
Saving model. Step: 10200, loss: 44.754994
******************************
src: 稽 文 考 献 ， 新 编 山 史
output: 崇 赫 励 笔 ， 大 地 民 香
target: 扬 风 摧 雅 ， 大 启 词 场
Saving model. Step: 10300, loss: 45.373895
******************************
src: 九 域 牢 基 固 本 ， 涌 绿 摇 红 ， 何 人 培 沃 土
output: 一 秋 大 气 兴 春 ， 和 金 立 后 ， 此 我 有 春 花
target: 千 村 浚 道 引 流 ， 洗 穷 去 白 ， 我 党 化 源 泉
Saving model. Step: 10400, loss: 44.786909
******************************
src: 龙 舟 划 破 千 江 水
output: 蛇 曲 闲 来 一 里 情
target: 一 醉 方 休 万 事 空
Saving model. Step: 10500, loss: 44.728842
******************************
src: 墨 点 兰 花 诗 味 重
output: 诗 摇 柳 岸 墨 情 浓
target: 风 开 柳 絮 性 情 真
Saving model. Step: 10600, loss: 45.089859
******************************
src: 陶 公 山 静 卧 ， 树 影 苍 茫 ， 紫 气 千 重 隆 福 地
output: 天 北 水 清 安 ， 风 光 永 漫 ， 青 天 一 彩 映 天 台
target: 南 渡 水 平 流 ， 日 华 烂 漫 ， 卿 云 五 色 映 坡 仑
Saving model. Step: 10700, loss: 44.844246
******************************
src: 白 水 滩 滩 水 白 ， 滩 水 如 飞 雪
output: 青 花 水 畔 水 中 ， 花 川 似 画 云
target: 红 茶 山 山 茶 红 ， 山 茶 似 披 霞
Saving model. Step: 10800, loss: 44.887577
******************************
src: 时 代 更 新 ， 教 化 与 文 明 共 进
output: 人 生 共 后 ， 共 神 共 睦 共 同 赢
target: 民 生 向 上 ， 精 神 和 物 质 双 赢
Saving model. Step: 10900, loss: 44.876297
******************************
src: 东 江 湖 畔 ， 博 学 深 思 ， 园 丁 志 励 新 猷 美
output: 南 水 楼 中 ， 风 躬 济 后 ， 社 子 人 中 大 业 多
target: 黄 草 镇 中 ， 劳 神 尽 责 ， 伯 乐 心 诚 大 器 宏
Saving model. Step: 11000, loss: 44.080705
******************************
src: 赏 菊 游 园 ， 侵 衣 玉 露 还 留 醉
output: 临 风 赏 月 ， 落 酒 风 风 不 作 来
target: 寻 幽 探 胜 ， 吻 面 清 风 不 觉 寒
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:走 马 灯 看 龙 虎 榜
output: 飞 龙 虎 跃 虎 龙 门
target: 杀 猪 佬 卖 狗 皮 膏
====================
src:岁 月 流 金 ， 剩 却 归 舟 几 许 ？ 空 有 一 江 聆 晚 唱
output: 天 涯 落 日 ， 何 曾 落 叶 无 边 ？ 何 来 万 里 落 红 尘
target: 伊 人 隔 岸 ， 犹 如 落 梦 三 千 ， 恨 无 双 翼 逐 斜 阳
====================
src:浮 浪 青 萍 ， 踏 碎 繁 星 编 玉 带
output: 飞 云 碧 水 ， 飞 飞 碧 水 映 红 霞
target: 妩 媚 红 荷 ， 笑 迎 素 月 理 娇 妆
====================
src:百 年 名 校 树 嘉 声 ， 喜 前 程 似 锦 ， 正 圆 美 梦
output: 万 里 春 风 和 和 韵 ， 喜 大 业 宏 图 ， 永 绘 宏 图
target: 一 路 高 歌 追 胜 境 ， 当 大 步 流 星 ， 直 上 青 云
====================
src:何 妨 一 醉 溪 山 卧
output: 不 见 千 年 水 水 流
target: 但 得 千 杯 泉 石 听
====================
src:喜 爆 千 声 歌 盛 世
output: 春 风 万 户 庆 新 春
target: 金 鸡 三 遍 报 新 春
====================
src:五 城 同 创 ， 百 福 倶 臻 ， 美 丽 荆 州 圆 梦 想
output: 万 里 同 歌 ， 千 秋 共 庆 ， 和 谐 社 会 展 宏 图
target: 万 众 共 吟 ， 八 音 齐 奏 ， 悠 扬 楚 韵 颂 文 明
====================
src:何 处 夕 阳 堪 忆 旧
output: 此 时 春 色 不 思 多
target: 桥 边 红 药 又 飘 香
====================
src:杜 宇 声 声 啼 旧 梦
output: 桃 花 朵 朵 醉 新 春
target: 芙 蓉 朵 朵 促 新 诗
====================
src:风 送 清 馨 盈 槛 外
output: 雨 滋 绿 水 润 江 南
target: 心 仪 澄 碧 落 江 中
Evaluate model. Step: 11000, score: 1.038232, loss: 44.080705
Saving model. Step: 11100, loss: 44.420513
******************************
src: 攀 登 难 遂 青 云 志
output: 放 酒 犹 吟 白 雪 诗
target: 把 酒 且 吟 白 首 诗
Saving model. Step: 11200, loss: 44.854592
******************************
src: 雪 笺 柳 笔 待 风 画
output: 雪 影 梅 丝 邀 月 歌
target: 竹 管 丝 弦 和 鸟 鸣
Saving model. Step: 11300, loss: 44.464183
******************************
src: 敬 惜 资 源 ， 循 世 态 谋 篇 ， 繁 荣 相 土 宜 低 碳
output: 和 除 国 力 ， 喜 民 生 国 发 ， 盛 起 宏 图 壮 大 球
target: 提 升 实 力 ， 惠 民 生 布 局 ， 拓 展 新 天 赖 转 型
Saving model. Step: 11400, loss: 45.404420
******************************
src: 敲 句 须 惜 一 寸 墨
output: 临 诗 不 负 两 年 书
target: 赋 诗 莫 吝 十 年 功
Saving model. Step: 11500, loss: 45.142768
******************************
src: 萦 情 芳 草 无 涯 ， 何 处 探 春 寻 旧 约
output: 有 意 青 山 有 梦 ， 此 乡 有 我 有 新 颜
target: 极 目 江 山 如 画 ， 故 应 为 我 发 新 诗
Saving model. Step: 11600, loss: 44.351148
******************************
src: 行 云 不 恋 青 峰 栈
output: 落 鹤 常 知 白 带 人
target: 游 子 总 思 玉 树 家
Saving model. Step: 11700, loss: 43.785803
******************************
src: 孝 义 节
output: 文 心 心
target: 思 志 诚
Saving model. Step: 11800, loss: 44.631718
******************************
src: 奥 运 百 年 开 领 域
output: 春 风 一 片 共 春 心
target: 秋 风 一 夜 瘦 容 颜
Saving model. Step: 11900, loss: 44.390913
******************************
src: 海 经 烛 物 辞 非 诞
output: 天 上 人 心 乐 有 真
target: 木 客 能 歌 诗 亦 神
Saving model. Step: 12000, loss: 43.633223
******************************
src: 渔 岛 之 子 、 扬 帆 、 试 航 ， 乘 风 破 浪
output: 山 雄 、 子 、 大 腐 、 大 业 ， 立 凤 、 潮
target: 英 雄 儿 女 、 拼 搏 、 创 业 ， 耕 云 播 雨
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:玉 笛 凌 波 ， 一 曲 红 尘 远
output: 青 山 入 地 ， 千 秋 古 道 新
target: 春 风 得 意 ， 满 山 绿 叶 浓
====================
src:扬 名 天 井 红 ， 缘 于 大 梦
output: 引 古 今 风 雅 ， 醉 作 中 华
target: 图 志 芦 溪 山 ， 为 富 瑶 民
====================
src:疏 通 竹 径 将 迎 月
output: 淡 淡 荷 花 不 染 尘
target: 远 爱 春 波 正 满 湖
====================
src:烽 烟 接 塞 外
output: 风 月 照 人 间
target: 铁 马 过 冰 河
====================
src:太 空 漫 步 ， 神 州 九 万 里 灰 霾 ， 奔 来 眼 底
output: 一 世 相 逢 ， 一 片 一 轮 中 外 梦 ， 醉 在 心 头
target: 寰 宇 聚 焦 ， 极 地 千 平 方 臭 氧 ， 惊 醒 议 程
====================
src:水 调 歌 头 春 润 泽
output: 花 开 树 上 韵 飘 香
target: 木 兰 花 令 梦 香 甜
====================
src:卧 佛 几 时 梦 醒
output: 寻 心 一 世 心 悲
target: 云 门 哪 日 天 开
Evaluate model. Step: 12000, score: 0.878220, loss: 43.633223
Saving model. Step: 12100, loss: 44.088389
******************************
src: 银 钩 墨 尚 新 ， 书 得 凤 笺 无 限 事
output: 玉 阁 楼 有 秀 ， 风 流 竹 色 有 多 尘
target: 画 楼 帘 卷 翠 ， 烟 凝 象 口 疑 吹 香
Saving model. Step: 12200, loss: 44.110955
******************************
src: 遥 看 汉 水 鸭 头 绿
output: 不 得 桃 涯 笔 上 寒
target: 莫 取 天 津 桥 上 春
Saving model. Step: 12300, loss: 44.179104
******************************
src: 四 季 星 云 印 证 ， 芳 踪 岩 洞 无 双 处
output: 一 秋 诗 韵 浮 神 ， 碧 迹 人 声 第 一 时
target: 千 秋 水 月 传 真 ， 胜 迹 泉 山 数 一 樵
Saving model. Step: 12400, loss: 44.182534
******************************
src: 梦 里 花 开 香 透 枕
output: 窗 中 月 暖 月 盈 杯
target: 酒 中 月 满 韵 盈 杯
Saving model. Step: 12500, loss: 44.000129
******************************
src: 听 天 由 命 知 天 命
output: 得 面 为 功 作 世 心
target: 扑 地 接 球 抱 地 球
Saving model. Step: 12600, loss: 43.873758
******************************
src: 浴 水 鸳 鸯 皆 对 对
output: 临 花 月 蝶 又 飞 飞
target: 采 花 蝴 蝶 尽 双 双
Saving model. Step: 12700, loss: 43.534413
******************************
src: 桃 红 李 白 柳 三 变
output: 月 艳 花 红 花 一 青
target: 菊 黄 草 青 杨 玉 环
Saving model. Step: 12800, loss: 44.534225
******************************
src: 龙 战 当 年 ， 巨 星 遽 殒 天 无 色
output: 龙 鸣 此 处 ？ 大 义 犹 留 我 有 风
target: 鹤 归 何 处 ？ 忠 骨 长 埋 土 亦 香
Saving model. Step: 12900, loss: 43.645827
******************************
src: 松 声 竹 声 钟 磬 声 ， 声 声 自 应
output: 水 色 水 色 水 花 月 ， 色 色 相 空
target: 山 色 水 色 烟 霞 色 ， 色 色 皆 空
Saving model. Step: 13000, loss: 44.228569
******************************
src: 武 汉 包 头 防 日 照
output: 英 山 上 后 对 人 山
target: 秦 皇 即 墨 颂 江 邮
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:明 月 临 池 ， 传 书 鸿 雁 浮 孤 影
output: 春 风 入 户 ， 醉 醉 清 风 入 画 屏
target: 春 风 曲 水 ， 漾 柳 龙 宫 托 紫 笺
====================
src:人 勤 春 早 绘 新 景
output: 政 善 民 安 庆 大 年
target: 民 乐 年 丰 展 宏 图
====================
src:江 山 一 统 腾 龙 日
output: 山 水 千 寻 逐 梦 人
target: 岁 月 三 春 入 虎 年
====================
src:天 宝 物 华 ， 千 里 莺 啼 千 里 绿
output: 春 秋 秋 暖 ， 一 方 春 满 一 枝 红
target: 年 丰 人 寿 ， 万 家 雀 跃 万 家 歌
====================
src:岁 月 如 诗 ， 谁 人 独 秉 生 花 笔
output: 人 生 似 梦 ， 我 辈 同 吟 发 子 歌
target: 城 乡 似 锦 ， 我 辈 同 耕 创 业 篇
====================
src:千 载 奇 逢 ， 只 在 好 书 良 友
output: 一 生 正 气 ， 不 能 不 老 佳 人
target: 一 生 清 福 ， 无 如 坐 茂 临 流
====================
src:丰 草 虎 蹲 秋 没 石
output: 清 风 柳 绿 柳 垂 丝
target: 华 林 马 射 夜 张 灯
Evaluate model. Step: 13000, score: 1.054799, loss: 44.228569
Saving model. Step: 13100, loss: 43.743906
******************************
src: 靠 科 学 ， 富 裕 临 门 早
output: 迎 人 明 ， 和 风 满 人 新
target: 讲 文 明 ， 春 风 及 第 先
Saving model. Step: 13200, loss: 43.857819
******************************
src: 明 湖 映 日 月 ， 繁 星 做 证
output: 大 山 开 天 明 ， 大 年 成 真
target: 趵 突 涌 文 化 ， 百 姓 认 同
Saving model. Step: 13300, loss: 43.833594
******************************
src: 一 心 可 换 十 分 亮
output: 两 手 难 开 万 里 金
target: 双 手 擦 来 万 步 新
Saving model. Step: 13400, loss: 45.017147
******************************
src: 旋 攀 龙 脊 招 鸣 鹤
output: 不 看 春 中 看 醉 虹
target: 且 坐 阁 端 抚 彩 云
Saving model. Step: 13500, loss: 44.209497
******************************
src: 谢 王 子 夸 ， 谢 董 郎 骂
output: 汉 女 夫 辣 ， - 女 女 汤
target: 吃 药 蛋 美 ， 吃 绿 豆 香
Saving model. Step: 13600, loss: 43.382341
******************************
src: 一 邪 教 骗 万 民 心 ， 用 意 险 恶
output: 千 载 不 为 千 丈 毒 ， 为 善 知 生
target: 千 堆 雪 砌 百 罗 汉 ， 真 相 大 白
Saving model. Step: 13700, loss: 43.796750
******************************
src: 下 界 红 尘 飞 不 到
output: 中 中 白 气 到 无 来
target: 上 清 紫 府 迥 非 凡
Saving model. Step: 13800, loss: 43.560072
******************************
src: 武 胜 街 尚 武 ， 江 山 永 固
output: 文 明 日 长 名 ， 日 李 长 春
target: 文 化 路 崇 文 ， 桃 李 长 春
Saving model. Step: 13900, loss: 43.184391
******************************
src: 岚 影 清 波 云 棹 月
output: 柳 光 明 雪 水 云 人
target: 星 光 白 露 雾 迷 花
Saving model. Step: 14000, loss: 43.422277
******************************
src: 心 惊 胆 战
output: 志 动 心 磨
target: 舌 敝 唇 焦
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:雁 阵 书 人 字
output: 花 香 醉 客 心
target: 星 空 绘 几 何
====================
src:兴 银 邑 ， 筑 银 山 ， 聚 财 永 固 千 秋 业
output: 树 金 牌 ， 传 赤 子 ， 创 业 都 安 万 里 春
target: 沐 春 晖 ， 荣 春 色 ， 纳 税 常 怀 寸 草 心
====================
src:两 岸 青 山 卧 江 底
output: 一 轮 碧 水 绕 云 间
target: 一 行 白 鹭 上 蓝 天
====================
src:疏 通 竹 径 将 迎 月
output: 淡 泊 梅 花 自 在 天
target: 远 爱 春 波 正 满 湖
====================
src:勤 俭 持 家 远
output: 勤 俭 为 国 强
target: 诗 书 继 世 长
====================
src:金 匾 生 辉 ， 茶 兼 四 百 人 文 味
output: 金 牌 献 德 ， 德 耀 千 秋 世 界 春
target: 骏 图 竞 彩 ， 堂 共 十 年 天 地 春
====================
src:青 石 路 ， 木 牌 坊 ， 歙 地 明 珠 嵌 画 卷
output: 绿 水 山 ， 山 水 水 ， 新 风 美 景 醉 诗 情
target: 古 城 楼 ， 深 街 巷 ， 徽 州 灿 玉 缀 诗 篇
====================
src:牛 刀 笔 小 试 牛 刀 ， 厥 词 大 放
output: 凤 凰 阁 上 游 凤 尾 ， 其 志 无 边
target: 马 掌 柜 专 钉 马 掌 ， 生 意 不 多
====================
src:人 杰 地 灵 ， 系 宋 元 时 八 闽 客 家 首 府
output: 人 和 风 雅 ， 和 谐 万 户 、 文 化 古 今 人
target: 物 华 天 宝 ， 为 近 现 代 九 州 历 史 名 城
Evaluate model. Step: 14000, score: 1.220398, loss: 43.422277
Saving model. Step: 14100, loss: 43.528501
******************************
src: 干 正 事
output: 小 真 心
target: 为 公 民
Saving model. Step: 14200, loss: 42.959012
******************************
src: 月 光 清 朗 千 江 现
output: 风 里 长 森 万 宇 空
target: 万 象 森 罗 玉 镜 含
Saving model. Step: 14300, loss: 42.606996
******************************
src: 车 夫 非 有 意 ， 赔 钱 足 矣
output: 世 口 不 无 人 ， 得 口 之 乎
target: 狗 主 故 施 威 ， 缺 德 悲 哉
Saving model. Step: 14400, loss: 43.034098
******************************
src: 粒 我 蒸 民 ， 三 时 不 害
output: 为 人 报 事 ， 一 姓 难 香
target: 诞 降 嘉 种 ， 百 谷 用 成
Saving model. Step: 14500, loss: 42.901307
******************************
src: 廿 年 创 业 篇 ， 五 光 十 色 皆 成 画
output: 万 姓 争 春 景 ， 一 里 千 红 总 是 春
target: 百 卉 争 荣 日 ， 万 紫 千 红 总 是 春
Saving model. Step: 14600, loss: 43.444734
******************************
src: 若 想 降 龙 伏 虎
output: 不 如 入 凤 蝶 蜂
target: 休 来 引 蝶 招 蜂
Saving model. Step: 14700, loss: 43.427128
******************************
src: 文 学 一 科 冠 夫 子
output: 文 香 万 里 醉 英 京
target: 馨 香 千 古 颂 南 人
Saving model. Step: 14800, loss: 42.671368
******************************
src: 岛 似 太 阳 ， 看 大 江 浪 涌
output: 人 如 碧 色 ， 看 天 穹 天 飞
target: 湾 如 月 亮 ， 鉴 苍 昊 云 飞
Saving model. Step: 14900, loss: 42.561817
******************************
src: 野 渡 舟 为 开 路 者
output: 山 山 月 在 是 花 人
target: 山 居 萤 是 点 灯 人
Saving model. Step: 15000, loss: 42.682297
******************************
src: 书 中 凝 智 慧
output: 笔 内 悟 真 坤
target: 字 里 有 乾 坤
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:日 月 同 明 子 女 好
output: 人 生 不 老 人 生 悲
target: 人 言 并 信 武 文 斌
====================
src:孝 心 本 是 爱 心 ， 悉 心 向 善 留 佳 话
output: 大 道 常 存 善 义 ， 立 德 为 人 做 大 家
target: 义 举 常 襄 盛 举 ， 美 举 明 德 传 惠 风
====================
src:天 光 起 瑞 ， 宜 雨 宜 晴 ， 是 圆 梦 地 ， 居 来 钓 月 餐 霞 客
output: 春 色 盈 怀 ， 春 风 拂 柳 ， 喜 喜 春 风 ， 醉 醉 清 风 入 画 图
target: 海 气 连 家 ， 濯 缨 濯 志 ， 看 弄 潮 儿 ， 登 上 生 金 产 玉 舟
====================
src:巨 柱 擎 天 ， 漳 水 流 金 ， 宝 刹 千 秋 泽 宇 内
output: 神 仙 化 地 ， 金 龙 起 舞 ， 神 仙 万 里 仰 禅 中
target: 云 龙 驽 驾 ， 雄 狮 护 法 ， 佛 光 万 道 耀 山 中
====================
src:尽 孝 常 来 看 望
output: 无 情 不 必 不 知
target: 献 忠 何 惧 捐 躯
====================
src:金 花 五 朵 生 银 子
output: 玉 树 千 枝 映 碧 珠
target: 寡 汉 一 条 没 老 婆
====================
src:蜗 居 不 止 八 零 后
output: 猴 跃 常 存 四 海 中
target: 挨 冻 正 当 三 九 天
====================
src:舀 江 水 一 瓢 焙 茗 ， 明 目 纵 观 新 上 海
output: 看 山 河 千 载 清 风 ， 清 风 漫 过 大 中 华
target: 借 春 茶 几 叶 搭 台 ， 开 篇 即 是 大 文 章
Evaluate model. Step: 15000, score: 1.328084, loss: 42.682297
Saving model. Step: 15100, loss: 42.780795
******************************
src: 赋 来 诗 句 无 闲 语
output: 醉 去 梅 花 有 旧 阳
target: 醉 折 荷 花 想 艳 妆
Saving model. Step: 15200, loss: 42.774936
******************************
src: 三 巡 酒 过 堪 回 味
output: 一 点 风 深 不 醉 肠
target: 一 曲 情 终 欲 断 魂
Saving model. Step: 15300, loss: 42.222690
******************************
src: 宜 一 家 进 安 世 乐
output: 喜 万 年 同 大 家 春
target: 为 二 人 述 相 逢 行
Saving model. Step: 15400, loss: 42.486417
******************************
src: 月 遮 白 雪 夜 织 女
output: 风 照 红 花 花 落 人
target: 日 照 红 楼 花 袭 人
Saving model. Step: 15500, loss: 42.602255
******************************
src: 国 庆 连 家 庆 ， 贴 红 联 ， 挂 红 灯 ， 红 日 子 红 红 火 火
output: 春 联 共 国 ， ， 迎 酒 彩 ， 歌 春 酒 ， 黄 人 年 绿 满 蓝 舟
target: 婚 期 逢 假 期 ， 酿 美 酒 ， 迎 美 女 ， 美 前 程 美 美 甜 甜
Saving model. Step: 15600, loss: 43.171983
******************************
src: 施 大 爱 救 人 舍 己
output: 开 清 生 作 世 生 心
target: 引 诸 方 挂 肚 牵 肠
Saving model. Step: 15700, loss: 42.757233
******************************
src: 山 山 皆 出 麻 石 磨
output: 山 月 长 出 水 鱼 衣
target: 水 水 乏 冰 食 包 饱
Saving model. Step: 15800, loss: 42.622533
******************************
src: 一 夜 梅 花 香 醉 也
output: 半 般 春 禄 喜 还 乎
target: 万 家 福 字 梦 翩 然
Saving model. Step: 15900, loss: 42.887848
******************************
src: 一 座 城 心 ， 自 古 珠 光 盈 宝 气
output: 三 千 人 道 ， 无 来 天 物 展 新 香
target: 二 郎 庙 会 ， 从 来 人 聚 胜 天 香
Saving model. Step: 16000, loss: 42.786601
******************************
src: 十 年 树 木 耕 耘 苦
output: 一 岁 风 经 爱 慧 高
target: 百 代 传 名 智 慧 深
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:静 伴 闲 云 ， 灏 气 含 元 蟠 柱 础
output: 闲 观 明 月 ， 清 风 拂 壁 醉 江 南
target: 乐 随 野 鹤 ， 灵 光 抱 一 绕 宫 墙
====================
src:荷 塘 一 隅 ， 春 池 凫 双 鹜
output: 柳 荫 千 里 ， 柳 岸 燕 双 飞
target: 青 烟 幂 处 ， 碧 海 飞 孤 帆
====================
src:快 马 加 鞭 ， 指 日 同 圆 中 国 梦
output: 春 风 送 暖 ， 同 心 共 绘 小 康 图
target: 神 舟 伴 月 ， 巡 天 遥 看 九 州 春
====================
src:岁 星 仙 气 原 方 朔
output: 天 地 仙 人 自 古 今
target: 璧 月 新 词 是 义 山
====================
src:春 风 送 暖 ， 人 寿 年 丰 常 惬 意
output: 瑞 雪 兆 丰 ， 民 生 福 寿 永 盈 门
target: 秋 叶 映 辉 ， 善 行 厚 德 自 开 心
====================
src:揽 胜 登 楼 ， 问 贤 圣 凭 谁 俯 仰
output: 登 高 望 远 ， 看 天 天 共 仰 先 驱
target: 临 风 追 梦 ， 放 江 山 入 我 襟 怀
====================
src:种 德 人 福 ， 惜 花 春 起 早
output: 和 谐 社 会 ， 喜 庆 福 盈 门
target: 干 国 栋 家 ， 爱 月 夜 眠 迟
====================
src:晋 水 流 丹 ， 白 玉 兰 香 ， 岁 月 长 怀 家 国 梦
output: 春 风 化 雨 ， 春 风 秋 雨 ， 春 风 遍 润 世 风 情
target: 江 风 摇 碧 ， 菩 提 树 美 ， 山 河 不 泯 古 今 情
Evaluate model. Step: 16000, score: 1.276550, loss: 42.786601
Saving model. Step: 16100, loss: 42.271011
******************************
src: 浪 荡 扁 舟 波 愈 碎
output: 风 翻 大 浪 水 犹 流
target: 潮 冲 顽 石 角 将 圆
Saving model. Step: 16200, loss: 42.202940
******************************
src: 五 夜 漏 声 催 晓 箭
output: 一 州 春 色 入 春 人
target: 九 重 春 色 醉 仙 桃
Saving model. Step: 16300, loss: 43.472992
******************************
src: 剖 腹
output: 咬 眉
target: 画 魂
Saving model. Step: 16400, loss: 41.504525
******************************
src: 邻 家 姊 妹 ， 赤 足 浣 纱 心 不 在
output: 大 水 青 山 ， 白 身 飞 水 意 相 逢
target: 隔 岸 叔 侄 ， 牵 牛 荷 耜 笑 相 闻
Saving model. Step: 16500, loss: 42.750397
******************************
src: 人 生 多 笑 语
output: 世 月 有 清 穷
target: 岁 月 自 无 情
Saving model. Step: 16600, loss: 42.013652
******************************
src: 盛
output: 迟
target: 昌
Saving model. Step: 16700, loss: 42.674585
******************************
src: 雀 舌 翻 腾 伏 浅 碧
output: 龙 毫 飞 祥 展 清 华
target: 猴 魁 呈 瑞 醉 中 秋
Saving model. Step: 16800, loss: 41.628075
******************************
src: 献 桃 贺 岁 ， 舞 棒 金 猴 飞 燕 岭
output: 迎 福 迎 春 ， 迎 金 玉 柳 舞 春 城
target: 接 福 迎 春 ， 镶 霞 红 对 写 龙 章
Saving model. Step: 16900, loss: 41.418076
******************************
src: 满 市 新 容 ， 满 世 新 风 ， 情 牵 唐 洞 是 当 往
output: 一 方 春 景 ， 一 方 春 酒 ， 客 似 人 风 似 自 来
target: 一 湖 好 水 ， 一 壶 好 酒 ， 心 醉 东 江 胡 不 归
Saving model. Step: 17000, loss: 41.686647
******************************
src: 天 风 弄 笛 兰 亭 里
output: 月 雨 衔 居 画 苑 中
target: 春 燕 安 琴 杏 雨 中
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:落 叶 纷 纷 ， 方 醉 看 窗 前 雾 色
output: 轻 舟 寂 寂 ， 更 思 来 月 下 风 光
target: 清 风 淡 淡 ， 亦 拂 过 水 面 湖 光
====================
src:越 岭 涉 江 ， 求 索 人 生 无 注 脚
output: 中 原 有 路 ， 不 忘 世 界 有 真 情
target: 问 天 顿 地 ， 忠 贞 岁 月 有 骚 文
====================
src:诗 与 我 ， 联 赠 君 ， 未 解 心 愁 能 下 笔
output: 人 为 人 ， 心 如 画 ， 不 如 月 色 不 成 诗
target: 酒 传 情 ， 琴 会 友 ， 尽 明 雅 趣 可 修 身
====================
src:初 窥 风 月 羞 遮 眼
output: 不 负 春 光 不 动 心
target: 远 别 沙 尘 笑 展 颜
====================
src:阳 光 为 墨 天 作 纸 ， 描 中 华 美 景
output: 春 色 为 人 面 是 花 ， 绘 锦 绣 春 光
target: 岁 月 似 弦 地 如 琴 ， 奏 盛 世 强 音
====================
src:怜 月 常 于 人 寂 处
output: 伤 心 不 过 梦 中 时
target: 思 乡 每 在 夜 深 时
====================
src:德 政 布 寰 中 ， 八 骏 嘶 风 传 捷 报
output: 春 光 开 画 里 ， 九 州 焕 彩 展 宏 猷
target: 春 雷 鸣 广 宇 ， 五 羊 跳 跃 展 新 图
Evaluate model. Step: 17000, score: 1.180818, loss: 41.686647
Saving model. Step: 17100, loss: 42.016766
******************************
src: 高 雅 非 高 傲
output: 清 愚 不 是 人
target: 老 成 似 老 拙
Saving model. Step: 17200, loss: 41.938587
******************************
src: 安 居 平 五 路
output: 不 壁 一 千 风
target: 赤 壁 借 东 风
Saving model. Step: 17300, loss: 42.255912
******************************
src: 名 岳 腾 龙 皆 佛 性
output: 清 云 悟 水 有 禅 机
target: 白 云 流 水 是 禅 心
Saving model. Step: 17400, loss: 41.921644
******************************
src: 手 气
output: 心 肠
target: 腰 酸
Saving model. Step: 17500, loss: 42.507713
******************************
src: 处 处 风 情 好
output: 年 年 月 步 高
target: 喧 喧 车 马 驰
Saving model. Step: 17600, loss: 43.035639
******************************
src: 天 上 ， 飞 来 三 羊 开 泰
output: 人 中 ， 迎 起 五 谷 争 高
target: 地 下 ， 钻 出 五 子 登 科
Saving model. Step: 17700, loss: 42.337670
******************************
src: 芳 菲 前 途 无 量
output: 清 滚 中 世 人 情
target: 蔚 起 后 继 有 人
Saving model. Step: 17800, loss: 42.085011
******************************
src: 忘 却 天 涯 烟 草 路
output: 不 成 天 界 水 星 春
target: 修 来 世 上 寿 长 生
Saving model. Step: 17900, loss: 42.498506
******************************
src: 水 凭 容 器 鉴 清 浊 ， 行 倚 道 德 分 善 恶
output: 人 为 精 精 严 重 心 ， 培 育 人 模 育 精 生
target: 木 以 准 绳 正 曲 直 ， 法 引 规 矩 定 方 圆
Saving model. Step: 18000, loss: 41.797288
******************************
src: 挚 意 挚 情 似 故 友
output: 清 人 如 意 有 今 朋
target: 问 寒 问 暖 如 亲 人
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:梅 作 清 词 无 俗 句
output: 竹 为 雅 趣 有 清 风
target: 菊 呈 傲 骨 有 冰 心
====================
src:其 生 也 荣 ， 其 死 也 哀 ， 雨 露 雷 霆 皆 主 德
output: 其 人 不 死 ， 不 言 不 死 ， 风 流 尘 世 有 哀 思
target: 臣 门 如 市 ， 臣 心 如 水 ， 皇 天 后 土 鉴 愚 衷
====================
src:湖 北
output: 山 东
target: 海 南
====================
src:彩 屏 如 画 ， 望 秀 美 崤 函 ， 花 团 锦 簇
output: 春 色 如 诗 ， 看 春 风 化 雨 ， 凤 舞 龙 腾
target: 短 信 报 春 ， 喜 和 谐 社 会 ， 物 阜 民 康
====================
src:雾 列 牌 坊 ， 长 对 三 河 征 战 地
output: 风 流 世 界 ， 长 留 一 代 仰 英 才
target: 风 传 捷 报 ， 犹 听 八 面 凯 歌 声
Evaluate model. Step: 18000, score: 1.431464, loss: 41.797288
Saving model. Step: 18100, loss: 41.925583
******************************
src: 忽 惊 水 上 光 华 满
output: 不 有 人 间 气 德 宽
target: 始 觉 人 间 道 路 长
Saving model. Step: 18200, loss: 41.556684
******************************
src: 山 山 海 海 ， 山 海 关 ， 雄 关 镇 山 海
output: 古 月 月 光 ， 月 月 月 ， 明 风 照 水 星
target: 日 日 月 月 ， 日 月 潭 ， 清 潭 映 日 月
Saving model. Step: 18300, loss: 41.673686
******************************
src: 万 丈 雄 心 图 破 壁
output: 一 轮 妙 力 在 成 威
target: 一 番 斗 志 好 扬 帆
Saving model. Step: 18400, loss: 42.208757
******************************
src: 若 蝶 金 叶 翩 翩 舞
output: 如 玉 银 笛 渐 款 来
target: 如 镜 玉 轮 款 款 升
Saving model. Step: 18500, loss: 41.937235
******************************
src: 四 面 岚 烟 竹 榭 隐
output: 一 池 秋 月 水 歌 飞
target: 一 襟 风 月 鸟 山 空
Saving model. Step: 18600, loss: 41.577994
******************************
src: 流 水 高 山 鸣 古 乐
output: 清 风 明 雨 送 新 猷
target: 栉 风 沐 雨 立 新 功
Saving model. Step: 18700, loss: 42.061477
******************************
src: 青 衫 破 尽 乡 愁 老
output: 白 路 归 来 天 事 空
target: 前 路 望 来 故 梦 遥
Saving model. Step: 18800, loss: 41.802187
******************************
src: 花 雨 轻 霏 ， 结 青 莲 世 界
output: 风 烟 淡 郁 ， 看 绿 发 精 思
target: 云 峰 郁 起 ， 现 白 毫 相 光
Saving model. Step: 18900, loss: 41.077972
******************************
src: 亭 以 桥 名 ， 永 年 致 颂
output: 水 如 国 后 ， 大 后 风 闻
target: 功 成 夏 季 ， 过 客 咸 宜
Saving model. Step: 19000, loss: 41.779770
******************************
src: 天 涯 共 此 时 ， 祝 福 乡 音 传 千 里
output: 天 岛 迎 春 日 ， 腾 今 风 日 誉 一 家
target: 海 内 同 今 日 ， 拜 年 吉 语 进 万 家
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:五 枝 锦 树 荣 今 代
output: 一 片 红 楼 耀 古 今
target: 百 秩 仙 筹 萃 一 门
====================
src:钗 头 凤 句 最 悲 伤 ， 棒 打 鸳 鸯 散
output: 水 畔 花 香 如 故 土 ， 情 牵 玉 簟 香
target: 广 耜 斋 文 犹 歉 岁 ， 鹤 鸣 绿 水 寒
====================
src:笔 端 流 畅 意
output: 心 底 悟 真 情
target: 诗 尾 泻 舒 心
Evaluate model. Step: 19000, score: 1.364269, loss: 41.779770
Saving model. Step: 19100, loss: 41.837460
******************************
src: 篱 边 菊 已 经 霜 瘦
output: 窗 上 花 香 伴 日 斜
target: 岭 上 枫 方 向 日 红
Saving model. Step: 19200, loss: 41.641705
******************************
src: 周 游 学 海 追 先 哲
output: 后 鲁 龙 山 仰 后 昆
target: 同 步 书 山 励 后 生
Saving model. Step: 19300, loss: 41.307513
******************************
src: 一 杯 浊 酒 伤 行 色
output: 几 缕 清 风 乱 耳 愁
target: 几 管 秋 声 动 客 愁
Saving model. Step: 19400, loss: 41.562441
******************************
src: 莺 声 燕 语 留 春 住
output: 燕 阔 龙 高 伴 月 来
target: 海 誓 山 盟 待 汝 归
Saving model. Step: 19500, loss: 41.651700
******************************
src: 心 静 气 闲 ， 四 季 风 光 皆 入 眼
output: 情 高 地 淡 ， 一 多 风 色 总 怡 诗
target: 天 高 云 淡 ， 几 程 山 水 尽 成 诗
Saving model. Step: 19600, loss: 41.954834
******************************
src: 陋 室 书 香 常 醉 客
output: 春 窗 月 韵 好 迷 人
target: 素 墙 墨 趣 总 迷 人
Saving model. Step: 19700, loss: 41.691529
******************************
src: 入 山 不 记 来 时 路
output: 入 户 当 登 上 意 人
target: 出 寨 要 留 得 令 条
Saving model. Step: 19800, loss: 41.072585
******************************
src: 几 曲 清 箫 吹 小 院
output: 一 帘 热 字 上 长 头
target: 一 支 天 籁 入 心 窗
Saving model. Step: 19900, loss: 41.453941
******************************
src: 国 圆 大 梦
output: 民 乐 小 康
target: 民 步 小 康
Saving model. Step: 20000, loss: 41.626828
******************************
src: 三 斗 白 云 君 纳 否
output: 一 杯 明 海 我 为 之
target: 一 瓢 沧 海 我 收 之
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:四 海 同 元 服
output: 一 山 共 月 圆
target: 三 加 进 达 樽
====================
src:任 呼 茂 叔 穷 禅 客
output: 不 让 清 风 是 故 人
target: 早 判 公 羊 卖 饼 家
====================
src:云 眸 落 泪 千 山 雨
output: 月 影 随 心 万 里 情
target: 海 嘴 喷 油 百 库 钱
====================
src:金 龙 掣 电 倾 盆 雨
output: 玉 兔 开 花 报 喜 春
target: 疾 鼓 追 风 阴 晦 天
====================
src:多 付 闲 情 招 祸 水
output: 不 知 俗 念 问 人 人
target: 少 生 欲 念 惹 红 颜
====================
src:至 圣
output: 新 贤
target: 真 如
====================
src:人 才 观
output: 我 不 知
target: 开 发 区
Evaluate model. Step: 20000, score: 1.511780, loss: 41.626828
Saving model. Step: 20100, loss: 40.952841
******************************
src: 永 济 一 方 天 ， 信 为 人 脉 时 时 用
output: 长 华 千 古 事 ， 心 信 风 源 处 处 来
target: 中 华 千 古 梦 ， 诚 化 财 源 处 处 生
Saving model. Step: 20200, loss: 40.988183
******************************
src: 反 腐 倡 廉 ， 准 则 频 送 清 心 剂
output: 秉 廉 养 气 ， 廉 岛 不 留 大 日 钟
target: 鉴 人 正 己 ， 条 例 长 鸣 警 世 钟
Saving model. Step: 20300, loss: 41.002979
******************************
src: 风 含 翠 竹 娟 娟 净
output: 雨 润 清 花 自 冉 香
target: 雨 浥 红 莲 冉 冉 香
Saving model. Step: 20400, loss: 41.903536
******************************
src: 聚 浦 分 廉 天 府 地
output: 中 山 独 水 古 山 山
target: 登 山 涉 海 电 雷 诗
Saving model. Step: 20500, loss: 40.842911
******************************
src: 月 映 西 樵 珠 履 梦
output: 风 归 北 海 玉 河 心
target: 人 钦 南 海 大 同 书
Saving model. Step: 20600, loss: 41.354539
******************************
src: 犹 记 当 年 青 草 地
output: 不 忘 此 个 旧 桃 梢
target: 难 忘 那 片 绿 杨 林
Saving model. Step: 20700, loss: 41.279942
******************************
src: 画 地 为 牢 ， 蒲 团 暖 座
output: 书 街 有 路 ， 水 娆 高 人
target: 当 头 一 棒 ， 妖 孽 甭 逃
Saving model. Step: 20800, loss: 41.400214
******************************
src: 希 贤 希 圣 希 天 ， 尚 友 诗 书 ， 其 揆 则 一
output: 学 德 为 德 在 德 ， 人 牌 名 豆 ， 其 愧 之 多
target: 立 言 立 功 立 德 ， 名 山 俎 豆 ， 不 朽 者 三
Saving model. Step: 20900, loss: 41.481511
******************************
src: 携 药 品 登 门 ， 治 病 健 身 ， 边 远 医 生 美
output: 有 人 年 作 眼 ， 和 书 论 志 ， 文 微 世 国 多
target: 接 少 儿 到 校 ， 读 书 明 礼 ， 贫 乡 教 育 馨
Saving model. Step: 21000, loss: 41.619497
******************************
src: 荷 香 缕 缕 寻 月 色
output: 柳 色 摇 悠 醉 春 烟
target: 柳 韵 悠 悠 觅 云 姿
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:嫡 子 拉 风 ， 庶 几 忘 我
output: 王 公 作 序 ， 一 一 一 人
target: 彼 人 吹 水 ， 其 实 无 他
====================
src:万 户 金 鸡 歌 盛 世
output: 千 年 玉 兔 报 春 风
target: 九 霄 玉 兔 报 新 春
====================
src:头 中 点 戒 招 蜂 刺
output: 脚 下 无 私 打 马 拉
target: 鬓 上 插 花 惹 蝶 追
====================
src:学 子 辛 勤 成 大 器
output: 文 章 精 品 有 高 才
target: 园 丁 努 力 育 高 才
====================
src:今 朝 大 款 携 二 奶
output: 此 日 新 年 出 一 人
target: 历 来 美 酒 伴 风 流
====================
src:生 活 恰 如 鱼 饮 水
output: 和 谐 当 似 凤 栖 凰
target: 进 修 浑 似 燕 衔 泥
====================
src:千 里 梦 ， 咫 尺 情 ， 渡 头 月 色 天 涯 望
output: 一 生 情 ， 心 头 梦 ， 心 里 情 怀 世 上 来
target: 峰 峦 移 ， 舟 棹 静 ， 帆 面 风 声 耳 际 聆
====================
src:一 枕 残 书 深 夜 读
output: 几 分 雅 韵 满 天 香
target: 半 窗 明 月 异 乡 吟
====================
src:肯 唱 戏 是 阴 功 ， 谁 靠 菩 萨 吃 饭
output: 不 知 心 非 苦 苦 ， 我 为 大 道 为 人
target: 要 上 台 充 角 色 ， 须 看 时 景 穿 衣
====================
src:午 时 已 到 开 餐 否
output: 今 日 何 妨 对 酒 来
target: 肚 子 不 成 闹 事 啦
====================
src:玩 不 出 花 样
output: 心 无 不 苦 心
target: 白 浪 费 时 间
====================
src:八 百 里 洞 庭 ， 凭 岳 阳 壮 阔
output: 五 千 年 古 韵 ， 任 古 韵 悠 悠
target: 七 二 峰 螺 岛 ， 萃 天 下 灵 奇
Evaluate model. Step: 21000, score: 1.395569, loss: 41.619497
Saving model. Step: 21100, loss: 41.410087
******************************
src: 捧 爱 兴 邦 ， 奶 奶 奉 她 全 部 爱
output: 开 怀 贺 爱 ， 民 君 有 国 万 生 歌
target: 放 歌 颂 党 ， 妈 妈 教 我 一 支 歌
Saving model. Step: 21200, loss: 41.077808
******************************
src: 孝 父 母 天 赐 长 寿
output: 文 人 人 国 庆 大 福
target: 敬 双 亲 荣 神 益 人
Saving model. Step: 21300, loss: 41.807328
******************************
src: 填 书 塞 典 文 博 士
output: 放 赋 人 人 学 俗 人
target: 曲 线 救 国 歹 汉 奸
Saving model. Step: 21400, loss: 40.760749
******************************
src: 祝 亚 运 顺 风 ， 旗 开 得 胜
output: 看 新 华 圆 锦 ， 国 跃 成 功
target: 盼 中 华 夺 锦 ， 马 到 成 功
Saving model. Step: 21500, loss: 41.652135
******************************
src: 启 南 湖 一 叶 舟 ， 血 荐 轩 辕 ， 党 救 万 民 功 盖 世
output: 仰 北 国 千 秋 梦 ， 功 飞 天 宇 ， 人 昭 北 域 史 凌 诗
target: 绘 中 国 千 秋 画 ， 云 蒸 海 岳 ， 旗 辉 九 秩 景 如 虹
Saving model. Step: 21600, loss: 41.405142
******************************
src: 美 誉
output: 奇 宾
target: 嘉 褒
Saving model. Step: 21700, loss: 41.340503
******************************
src: 李 杜 题 诗 ， 捭 阖 星 云 日 月 书 青 史
output: 金 髦 入 道 ， 文 横 天 古 画 坤 壮 宏 图
target: 时 空 主 笔 ， 纵 横 今 古 乾 坤 展 鸿 图
Saving model. Step: 21800, loss: 40.836730
******************************
src: 风 轻 酒 暖 邀 云 醉
output: 月 暖 月 闲 任 月 明
target: 水 冷 心 寒 待 月 明
Saving model. Step: 21900, loss: 40.840516
******************************
src: 读 书 有 味 千 回 少
output: 对 句 无 言 一 品 空
target: 对 客 无 情 一 句 多
Saving model. Step: 22000, loss: 40.738073
******************************
src: 廉 泉 原 鉴 千 秋 洁
output: 清 海 长 添 万 世 通
target: 宦 海 平 添 一 脉 香
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:红 袖 影 翻 江 上 月
output: 白 云 霞 映 水 中 天
target: 紫 箫 声 逐 岭 头 云
====================
src:愁 如 逝 水 不 堪 问
output: 恨 似 流 云 不 可 寻
target: 酒 似 春 风 一 任 斟
====================
src:实 施 人 口 均 衡 发 展
output: 大 展 宏 图 大 展 宏 图
target: 应 对 老 龄 快 速 增 加
====================
src:巫 山 有 梦 留 残 照
output: 山 水 无 声 入 故 人
target: 帝 子 乘 风 下 翠 微
====================
src:奇 葩 男 、 奇 葩 女 ， 春 风 几 度
output: 新 人 家 、 新 人 家 ， 大 地 长 新
target: 乱 世 人 、 乱 世 狗 ， 等 闲 一 般
Evaluate model. Step: 22000, score: 1.534753, loss: 40.738073
Saving model. Step: 22100, loss: 40.692065
******************************
src: 呓 语 低 吟 碧 落 ， 抱 月 清 幽 ， 无 畏 根 深 冷 处
output: 春 躅 淡 曳 红 尘 ， 听 风 落 暖 ， 有 情 梦 淡 时 时
target: 娉 婷 摇 曳 红 尘 ， 迎 风 温 婉 ， 有 怜 香 浅 秋 时
Saving model. Step: 22200, loss: 41.069920
******************************
src: 革 命 尚 未 成 功
output: 为 心 同 是 为 力
target: 同 志 仍 需 努 力
Saving model. Step: 22300, loss: 41.656791
******************************
src: 归 处 何 依 ？ 此 身 自 与 沧 州 老
output: 何 时 共 乐 ， 此 脉 常 同 天 气 风
target: 酬 国 之 祚 ， 一 世 愿 同 紫 塞 寒
Saving model. Step: 22400, loss: 41.325904
******************************
src: 得 意 算 盘 ， 三 下 五 除 二
output: 开 心 卖 卖 ， 一 里 二 二 八
target: 招 工 相 面 ， 万 中 百 选 一
Saving model. Step: 22500, loss: 41.307732
******************************
src: 过 闻 喜 闻 过 则 喜
output: 来 来 乐 者 乐 者 和
target: 来 和 顺 和 来 而 顺
Saving model. Step: 22600, loss: 41.669844
******************************
src: 峰 峦 崇 岱 岳 ， 嶒 嶝 峥 嵘 峙 峻 岭
output: 山 海 涌 津 沽 ， 潆 洄 澎 湃 汇 洪 流
target: 河 海 润 津 沽 ， 潆 洄 澎 湃 汇 洪 流
Saving model. Step: 22700, loss: 41.233244
******************************
src: 树 生 渡 口 天 然 好
output: 心 顶 山 山 日 处 多
target: 山 到 江 边 分 外 明
Saving model. Step: 22800, loss: 40.147790
******************************
src: 映 雪 囊 萤 凿 壁 借
output: 飞 天 作 月 落 云 行
target: 负 薪 挂 角 带 经 锄
Saving model. Step: 22900, loss: 40.343244
******************************
src: 山 中 土 养 天 然 味
output: 海 上 人 开 大 态 情
target: 席 上 肉 兴 生 态 风
Saving model. Step: 23000, loss: 40.675579
******************************
src: 碧 瓦 朱 甍 照 城 郭
output: 青 云 玉 水 映 江 台
target: 浅 黄 轻 绿 映 楼 台
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:羊 毫 作 笔 ， 书 华 夏 辉 煌 业 绩
output: 猴 棒 挥 毫 ， 写 华 章 锦 绣 文 章
target: 猴 棒 化 针 ， 绣 祖 国 美 丽 江 山
====================
src:礼 成 二 戴 ， 名 耀 八 方 ， 儒 家 经 典 千 秋 颂
output: 德 泽 三 门 ， 德 昭 四 海 ， 华 夏 文 明 万 代 传
target: 脚 踏 棉 山 ， 眼 观 粮 海 ， 红 日 光 芒 万 古 留
====================
src:千 尺 廊 桥 千 尺 画
output: 一 江 水 水 一 江 诗
target: 一 湖 风 月 一 湖 诗
====================
src:可 珍 土 地 忙 中 乐
output: 不 见 人 间 乐 外 欢
target: 有 味 诗 书 苦 后 甜
====================
src:烈 日 当 空 ， 车 驰 山 路 救 灾 送 水
output: 春 风 化 雨 ， 花 绽 花 开 蝶 恋 花 香
target: 真 情 济 世 ， 爱 献 乡 民 动 地 感 天
====================
src:杜 宇 声 声 啼 旧 梦
output: 桃 花 朵 朵 映 新 春
target: 芙 蓉 朵 朵 促 新 诗
====================
src:巢 落 莺 哥 走
output: 山 高 月 下 来
target: 门 开 燕 子 归
====================
src:一 杯 菊 酒 醉 秋 月
output: 几 缕 春 风 拂 柳 烟
target: 两 袖 清 风 伴 落 花
====================
src:烛 灭
output: 花 开
target: 香 消
====================
src:赝 品 时 呈 ， 乱 花 渐 欲 迷 人 眼
output: 新 风 乍 起 ， 明 月 还 须 照 我 心
target: 金 睛 明 察 ， 狗 嘴 何 曾 长 象 牙
====================
src:狮 舞 雄 风 ， 荟 天 下 英 豪 ， 争 王 争 霸
output: 龙 腾 盛 世 ， 喜 中 华 大 地 ， 盛 世 扬 帆
target: 羊 开 泰 运 ， 壮 樵 山 文 翰 ， 入 梦 入 诗
Evaluate model. Step: 23000, score: 1.626593, loss: 40.675579
Saving model. Step: 23100, loss: 40.563663
******************************
src: 遥 望 银 河 思 浪 漫
output: 闲 钟 碧 榭 叹 徘 柔
target: 独 居 月 殿 可 温 馨
Saving model. Step: 23200, loss: 40.285375
******************************
src: 泼 墨 慕 文 成 巨 卷
output: 挥 情 作 善 是 高 文
target: 痴 书 弘 毅 聚 斯 斋
Saving model. Step: 23300, loss: 40.952627
******************************
src: 开 国 精 神 元 不 老
output: 中 公 德 月 自 先 贤
target: 抡 才 岁 月 冠 群 伦
Saving model. Step: 23400, loss: 40.808578
******************************
src: 昔 年 黯 影 今 朝 尽
output: 今 岁 新 心 一 日 来
target: 旧 岁 烦 痕 昨 夜 消
Saving model. Step: 23500, loss: 40.824891
******************************
src: 顷 刻 驰 驱 千 里 外
output: 山 今 风 业 万 时 中
target: 古 今 事 业 一 霄 中
Saving model. Step: 23600, loss: 40.318340
******************************
src: 携 唐 宋 诗 词 奔 涌 而 来 ， 赋 墨 客 文 人 ， 千 年 不 老 中 秋 月
output: 看 古 园 风 女 相 怀 在 见 ， 看 天 歌 楚 别 ， 一 里 长 思 北 子 诗
target: 是 家 山 儿 女 情 思 所 系 ， 问 悲 欢 离 合 ， 万 里 遥 听 游 子 吟
Saving model. Step: 23700, loss: 40.963029
******************************
src: 逐 北
output: 东 南
target: 平 南
Saving model. Step: 23800, loss: 40.535250
******************************
src: 月 影 初 临 空 朗 朗
output: 风 光 犹 杳 更 潺 飕
target: 风 声 已 定 水 湉 湉
Saving model. Step: 23900, loss: 40.171656
******************************
src: 喷 壁 四 时 雨
output: 开 怀 万 里 风
target: 寄 声 千 里 风
Saving model. Step: 24000, loss: 40.912145
******************************
src: 润 物 体 乾 培 国 运
output: 扬 功 济 道 铸 民 流
target: 成 思 端 致 见 风 怀
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:一 心 一 意 ， 只 予 有 缘 人 作 对
output: 无 事 无 非 ， 无 非 无 事 事 无 求
target: 几 字 几 词 ， 欣 获 臻 美 句 成 联
====================
src:拜 佛 何 须 来 寺 庙
output: 修 身 自 是 上 山 门
target: 打 坐 当 然 要 空 心
====================
src:几 人 登 顶 悟 真 道
output: 一 世 无 心 悟 佛 陀
target: 今 世 有 缘 拜 祖 师
====================
src:目 曾 瞻 壮 景 ， 人 皆 仰 貌 聆 声 ， 惊 势 动 情 ， 诗 兴 荡 崖 亲 兴 上
output: 心 正 有 灵 犀 ， 气 爽 清 风 ， 清 风 入 韵 ， 风 情 ， 风 流 韵 韵 中 来
target: 身 复 隐 奇 帘 ， 我 竟 凝 神 探 趣 ， 运 思 成 句 ， 瀑 流 溶 伍 巨 流 中
====================
src:才 斟 米 酒 撩 春 意
output: 欲 把 诗 书 寄 雅 情
target: 又 舞 羊 毫 咏 杜 鹃
====================
src:舍 慢 持 净 界
output: 心 静 见 真 情
target: 以 法 化 众 生
====================
src:慷 慨 视 别 剑
output: 萧 萧 听 鸣 琴
target: 凄 清 流 雅 音
====================
src:苏 武 留 胡 节 不 辱
output: 王 公 有 主 子 如 来
target: 欧 文 赴 美 愿 成 空
====================
src:樽 前 备 墨 时 邀 月
output: 笔 底 挥 毫 欲 赋 诗
target: 笔 下 生 花 静 有 香
====================
src:上 天 堂 ， 凌 绝 顶 ， 腾 云 驾 雾 着 霓 裳 ， 只 觉 身 临 仙 境
output: 上 山 水 ， 观 山 河 ， 观 水 观 山 观 水 月 ， 何 妨 画 卷 诗 人
target: 观 瀑 布 ， 赏 奇 花 ， 涉 水 爬 山 穿 锦 绣 ， 方 知 美 在 人 间
Evaluate model. Step: 24000, score: 1.719163, loss: 40.912145
Saving model. Step: 24100, loss: 40.421879
******************************
src: 夫 妻 上 擂 台 ， 成 双 作 对
output: 老 女 出 出 汉 ， 对 士 相 军
target: 男 女 下 武 池 ， 逞 独 耍 单
Saving model. Step: 24200, loss: 39.747900
******************************
src: 别 让 星 星 流 眼 泪
output: 不 将 风 色 动 心 情
target: 管 教 月 月 好 心 情
Saving model. Step: 24300, loss: 39.477560
******************************
src: 山 货 店 ， 竹 艺 店 ， 大 溪 开 店
output: 水 市 路 ， 新 画 路 ， 大 州 腾 家
target: 旺 铺 街 ， 财 富 街 ， 九 龙 兴 街
Saving model. Step: 24400, loss: 39.646577
******************************
src: 独 怜 秋 叶 飘 摇 落
output: 不 忆 春 风 落 洒 来
target: 更 爱 春 光 潇 洒 歌
Saving model. Step: 24500, loss: 39.168146
******************************
src: 秋 雨 如 丝 滋 故 土
output: 春 风 似 火 染 新 人
target: 西 风 似 墨 染 归 心
Saving model. Step: 24600, loss: 39.595880
******************************
src: 创 会 辛 勤 ， 建 祠 修 谱 光 先 祖
output: 弘 官 济 远 ， 教 业 扬 魂 启 后 人
target: 为 人 清 正 ， 伟 绩 忠 魂 荫 后 昆
Saving model. Step: 24700, loss: 40.020131
******************************
src: 寒 山 何 以 瘦
output: 浊 树 不 成 迟
target: 老 子 自 然 清
Saving model. Step: 24800, loss: 39.171483
******************************
src: 不 作 寻 常 风 月 咏
output: 且 看 无 事 古 云 闲
target: 再 思 往 惜 水 茶 情
Saving model. Step: 24900, loss: 39.790902
******************************
src: 百 会 征 联 文 集 雅
output: 一 军 对 对 字 传 新
target: 三 年 应 句 辑 编 优
Saving model. Step: 25000, loss: 39.693747
******************************
src: 审 无 私 ， 甘 作 财 经 卫 士
output: 心 有 道 ， 不 扬 善 道 为 章
target: 计 有 道 ， 弘 扬 公 德 文 明
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:灯 下 吟 诗 人 自 雅
output: 花 间 酌 酒 酒 尤 香
target: 山 中 吃 肉 虎 真 凶
====================
src:五 福 临 场 ， 莺 鸣 燕 舞 ， 舜 诵 南 风 ， 四 面 层 峦 来 紫 气
output: 三 春 送 暖 ， 春 满 花 开 ， 花 开 锦 绣 ， 千 秋 大 业 展 宏 图
target: 八 方 奏 乐 ， 水 唱 山 歌 ， 尧 耕 广 漠 ， 万 荣 飞 阁 誉 龙 头
====================
src:月 笼 寒 水 清 凉 境
output: 风 过 泸 州 浪 漫 时
target: 雾 锁 修 竹 幽 雅 居
====================
src:长 守 山 林 ， 甘 守 平 凡 ， 但 闻 世 人 知 伯 乐
output: 常 怀 故 里 ， 长 留 诗 句 ， 不 知 诗 酒 赋 诗 诗
target: 不 观 皮 相 ， 唯 观 筋 骨 ， 独 开 慧 眼 识 良 驹
====================
src:十 天 四 节 何 时 有
output: 一 日 一 心 无 处 无
target: 七 日 一 周 哪 月 无
====================
src:霜 冷 花 黄 ， 杯 中 有 酒 神 仙 妒
output: 风 清 月 白 ， 眼 底 无 声 诗 客 吟
target: 夜 阑 月 静 ， 亭 下 无 思 鬼 魅 愁
====================
src:雾 列 牌 坊 ， 长 对 三 河 征 战 地
output: 风 流 大 地 ， 再 开 四 海 锦 程 图
target: 风 传 捷 报 ， 犹 听 八 面 凯 歌 声
====================
src:一 庭 春 色 无 关 我
output: 几 度 秋 声 不 待 人
target: 对 面 娇 花 才 诱 人
====================
src:吟 诗 最 喜 遇 佳 句
output: 对 月 常 思 对 对 联
target: 修 道 何 须 拜 圣 人
====================
src:春 荣 渝 水 三 千 树
output: 风 送 桃 花 第 一 枝
target: 梦 染 丰 都 七 彩 图
====================
src:留 下 清 廉 当 后 路
output: 打 开 新 纪 上 高 楼
target: 何 来 权 贵 鉴 前 车
====================
src:一 团 开 处 春 无 价
output: 万 里 归 来 梦 有 缘
target: 七 泡 尝 来 梦 亦 香
====================
src:屏 小 云 气 山 开 通
output: 月 满 月 光 月 满 轮
target: 树 里 檐 声 雨 满 堂
Evaluate model. Step: 25000, score: 1.796805, loss: 39.693747
Saving model. Step: 25100, loss: 40.349395
******************************
src: 入 梦 赏 荷 依 柳 岸
output: 临 心 对 月 落 诗 弦
target: 无 眠 看 雨 奏 窗 台
Saving model. Step: 25200, loss: 39.946146
******************************
src: 春 风 十 里 柔 情 ， 怎 奈 何 青 山 招 不 来 ， 明 日 留 难 住
output: 明 事 一 时 大 道 ， 莫 知 他 一 海 ， 多 ， ， 老 花 不 我 知
target: 世 事 一 场 大 梦 ， 始 信 得 皮 袋 非 真 我 ， 梅 花 是 故 人
Saving model. Step: 25300, loss: 39.704413
******************************
src: 鬼 佬 恃 才 无 恶 意
output: 公 翁 有 句 有 愁 情
target: 醉 翁 对 酒 忒 钟 情
Saving model. Step: 25400, loss: 39.431829
******************************
src: 策 杖 巫 山 ， 齐 谁 眉 目
output: 横 歌 海 海 ， 任 我 胸 胸
target: 放 舟 沧 海 ， 荡 我 心 胸
Saving model. Step: 25500, loss: 38.963491
******************************
src: 香 火 千 年 ， 照 亮 迷 途 生 自 在
output: 清 风 万 里 ， 迎 开 梦 梦 梦 成 悲
target: 清 风 万 缕 ， 吹 开 好 梦 化 慈 悲
Saving model. Step: 25600, loss: 39.339904
******************************
src: 渴 鹿 趋 阳 焰
output: 灵 鸿 舞 海 星
target: 飞 蛾 赴 火 光
Saving model. Step: 25700, loss: 39.591200
******************************
src: 过 界 红 兵 图 杀 将
output: 中 天 紫 土 不 归 身
target: 卧 槽 黑 子 已 抽 车
Saving model. Step: 25800, loss: 39.805213
******************************
src: 人 生 本 就 难 一 论
output: 世 化 不 须 不 不 言
target: 文 字 何 尝 真 万 能
Saving model. Step: 25900, loss: 39.375774
******************************
src: 上 海 海 带 带 苦 味
output: 西 地 北 中 开 美 人
target: 天 津 津 贴 贴 穷 人
Saving model. Step: 26000, loss: 40.428164
******************************
src: 柳 下 堆 烟 绿
output: 花 中 映 月 明
target: 水 中 卧 月 明
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:贸 易 兴 隆 盈 万 利
output: 和 谐 社 会 乐 千 家
target: 春 风 得 意 纳 千 祥
====================
src:归 心 切 切 ， 雪 风 难 阻 返 乡 路
output: 举 步 望 穿 ， 云 雾 难 寻 入 梦 乡
target: 去 意 殷 殷 ， 金 玉 畅 通 出 国 途
====================
src:会 压 洪 波 先 得 路
output: 难 寻 大 道 不 关 情
target: 催 沽 美 酒 敢 辞 贫
====================
src:华 夏 春 光 传 马 赛
output: 中 华 大 业 展 鹏 程
target: 人 间 美 景 在 羊 城
====================
src:苦 辣 酸 甜 ， 遭 遇 一 生 应 不 少
output: 酸 甜 苦 辣 ， 品 尝 几 度 乐 无 穷
target: 诗 书 画 印 ， 兼 擅 四 绝 已 无 多
====================
src:一 部 茶 经 ， 七 千 锦 语 ， 字 字 珠 玑 香 国 饮
output: 三 分 景 色 ， 四 季 春 风 ， 人 文 荟 萃 壮 山 河
target: 八 方 雅 士 ， 四 路 欢 声 ， 纷 纷 车 马 向 天 门
====================
src:幽 谷 梅 花 先 试 雪
output: 长 江 月 色 总 流 金
target: 岭 南 杨 柳 早 知 春
====================
src:好 在 品 尝 方 得 体
output: 常 于 心 事 总 关 情
target: 勤 于 炒 作 却 无 名
====================
src:名 花 无 好 主
output: 老 板 有 高 朋
target: 小 草 有 高 怀
====================
src:舀 江 水 一 瓢 焙 茗 ， 明 目 纵 观 新 上 海
output: 看 山 山 万 里 山 山 ， 高 山 独 秀 古 今 山
target: 借 春 茶 几 叶 搭 台 ， 开 篇 即 是 大 文 章
====================
src:那 风 那 雨 携 春 味
output: 此 地 无 人 惹 夏 风
target: 此 字 此 文 带 土 香
Evaluate model. Step: 26000, score: 1.797901, loss: 40.428164
Saving model. Step: 26100, loss: 40.160984
******************************
src: 天 道 酬 勤 ， 金 榜 题 名 终 遂 愿
output: 人 龙 献 志 ， 金 江 送 路 不 知 人
target: 蛟 龙 得 水 ， 长 风 作 浪 不 由 云
Saving model. Step: 26200, loss: 39.514300
******************************
src: 年 轮 铭 故 事
output: 岁 色 忆 新 怀
target: 月 夜 会 情 人
Saving model. Step: 26300, loss: 39.337964
******************************
src: 雨 绿 春 山 风 送 暖
output: 花 开 柳 院 月 谈 欢
target: 花 香 醉 客 鸟 投 怀
Saving model. Step: 26400, loss: 38.800344
******************************
src: 勤 劳 能 致 富
output: 和 气 可 生 财
target: 和 睦 可 发 财
Saving model. Step: 26500, loss: 39.283952
******************************
src: 夜 幕 斜 垂 ， 雾 气 千 山 风 卷 去
output: 春 光 滚 荡 ， 烟 声 万 里 月 飞 来
target: 波 流 暗 落 ， 潮 音 万 里 浪 涛 空
Saving model. Step: 26600, loss: 39.319360
******************************
src: 说 短 道 长 凭 胆 量
output: 打 空 心 要 要 精 情
target: 测 凉 试 热 靠 心 肠
Saving model. Step: 26700, loss: 39.792177
******************************
src: 厌 闻 百 怪 千 奇 事
output: 醉 看 三 生 一 福 人
target: 喜 看 三 侠 五 义 书
Saving model. Step: 26800, loss: 38.765344
******************************
src: 富 乐 裹 葱 茏 ， 杜 圣 忘 忧 ， 径 剪 山 光 包 韵 脚
output: 春 蓉 开 水 韵 ， 清 仙 醉 舞 ， 风 邀 月 月 醉 春 情
target: 芙 蓉 流 洌 澈 ， 谪 仙 载 酒 ， 直 掬 水 色 润 诗 肠
Saving model. Step: 26900, loss: 39.182064
******************************
src: 归 心 已 逐 轻 桡 ， 几 夜 湖 山 生 梦 寐
output: 举 梦 又 有 春 节 ， 一 枝 风 竹 落 风 江
target: 晚 香 犹 有 佳 处 ， 一 区 松 菊 老 湘 滨
Saving model. Step: 27000, loss: 39.469606
******************************
src: 口 伐 声 中 交 伐 咬
output: 眼 星 月 里 自 光 明
target: 日 光 城 里 月 光 明
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:绿 岛 轻 舟 人 入 画
output: 青 山 绿 水 我 吟 诗
target: 椰 风 海 水 浪 弹 琴
====================
src:百 感 交 于 无 意 处
output: 一 生 不 尽 有 时 时
target: 千 情 自 在 不 言 中
====================
src:人 无 远 虑 忧 多 近
output: 心 有 灵 犀 意 不 平
target: 帐 有 盈 余 庆 不 亏
====================
src:粉 饰
output: 麻 秸
target: 装 潢
====================
src:七 月 兰 盆 施 大 德
output: 一 朝 春 色 满 中 华
target: 一 筵 水 陆 度 幽 魂
====================
src:野 渡 孤 心 ， 钓 月 上 船 听 故 事
output: 山 山 有 意 ， 临 风 把 盏 问 仙 人
target: 风 流 千 载 ， 持 觞 买 醉 梦 沧 桑
====================
src:寂 寞 花 开 难 自 主
output: 相 思 月 落 不 成 愁
target: 相 思 泪 落 已 无 由
====================
src:西 天 晓 月 枝 头 挂
output: 北 海 风 光 岭 上 飞
target: 北 海 春 潮 眼 里 生
====================
src:乐 教 梓 楠 同 受 范
output: 不 知 风 月 不 成 诗
target: 喜 观 桃 李 广 成 材
====================
src:佛 当 敬 ， 神 当 敬 ， 非 贤 毋 敬
output: 天 所 为 ， 地 无 私 ， 有 德 无 私
target: 钱 也 捐 ， 物 也 捐 ， 唯 德 不 捐
Evaluate model. Step: 27000, score: 1.690031, loss: 39.469606
Saving model. Step: 27100, loss: 39.927331
******************************
src: 彩 笔 传 情 歌 伟 业
output: 丹 心 焕 志 展 英 恩
target: 丹 霞 达 意 颂 党 恩
Saving model. Step: 27200, loss: 39.121264
******************************
src: 岂 可 无 梅 撑 画 骨
output: 须 经 有 月 入 梅 心
target: 曾 经 有 雪 映 诗 魂
Saving model. Step: 27300, loss: 39.961609
******************************
src: 共 祝 党 与 天 齐 寿
output: 同 喜 人 同 日 同 春
target: 更 愿 民 同 地 永 宁
Saving model. Step: 27400, loss: 39.327849
******************************
src: 残 阳 一 笛 花 村 入
output: 明 水 千 树 画 子 飞
target: 碧 山 千 江 燕 子 归
Saving model. Step: 27500, loss: 39.037501
******************************
src: 虎 拜 仁 慈 大
output: 龙 吟 福 德 高
target: 龙 行 道 德 高
Saving model. Step: 27600, loss: 39.662881
******************************
src: 看 我 非 我 ， 我 看 我 ， 我 也 非 我
output: 任 谁 是 谁 ？ 谁 是 谁 ， 谁 谁 谁 谁
target: 演 谁 像 谁 ， 谁 演 谁 ， 谁 就 像 谁
Saving model. Step: 27700, loss: 38.890640
******************************
src: 予 贫 残 稚 弱 以 无 边 大 爱 ， 捐 资 相 助 ， 倾 力 而 扶 ， 仁 行 善 举 福 桑 梓
output: 有 大 米 风 薇 以 以 胞 之 天 ， 大 者 不 容 ， 以 辛 不 在 ， 大 作 甘 风 泽 栋 梁
target: 愿 樗 栎 楩 楠 享 同 片 蓝 天 ， 困 厄 不 辞 ， 艰 难 自 任 ， 化 雨 春 风 育 栋 梁
Saving model. Step: 27800, loss: 39.933081
******************************
src: 天 寒 勤 问 酒
output: 月 富 好 思 书
target: 学 浅 多 读 书
Saving model. Step: 27900, loss: 39.427221
******************************
src: 大 粮 飞 雪 ， 金 峰 缠 带 ， 大 爱 延 长 ， 直 向 民 心 铺 富 路
output: 大 镇 爱 钟 ， 玉 歌 兴 衢 ， 红 村 焕 目 ， 常 凭 国 想 展 豪 风
target: 乡 间 鸣 笛 ， 高 速 通 车 ， 乡 程 缩 短 ， 更 追 梦 想 畅 春 风
Saving model. Step: 28000, loss: 38.738341
******************************
src: 十 里 荷 风 流 倩 影
output: 一 江 柳 色 醉 迷 人
target: 一 川 月 色 总 宜 人
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:临 水 乍 凝 双 袖 翠
output: 临 风 犹 带 一 枝 春
target: 凭 栏 偶 惹 一 身 香
====================
src:与 百 姓 有 缘 ， 才 能 到 此
output: 替 一 心 一 念 ， 不 可 忘 形
target: 期 寸 心 无 愧 ， 不 负 斯 民
====================
src:夕 夕 多 潮 朝 水 汐
output: 春 风 得 意 满 江 南
target: 山 山 出 矿 广 石 岩
====================
src:玉 路 长 通 争 跃 马
output: 春 风 又 起 好 开 花
target: 金 瓯 永 固 不 亡 羊
====================
src:松 下 云 闲 窥 落 子
output: 山 中 月 老 醉 游 人
target: 场 中 舞 秀 看 超 男
====================
src:灵 猴 值 岁 春 光 满
output: 瑞 雪 迎 梅 瑞 气 盈
target: 骏 马 嘶 风 志 气 高
====================
src:秀 阁 美 人 开 秀 阁
output: 青 山 绿 水 绕 青 山
target: 香 江 风 味 溢 香 江
====================
src:大 肚 ， 能 容 天 下 之 事
output: 真 心 ， 不 让 人 间 不 言
target: 笑 脸 ， 迎 接 十 方 来 客
====================
src:星 辉 南 极 岁 之 始
output: 日 照 东 西 风 不 来
target: 雨 足 西 江 云 自 闲
====================
src:狗 皮 膏 药 牛 皮 癣
output: 牛 嘴 皮 皮 狗 嘴 皮
target: 人 血 馒 头 猪 血 汤
====================
src:凭 草 木 传 神 ， 赋 彩 诗 篇 三 百 首
output: 把 文 明 作 笔 ， 挥 毫 墨 笔 五 千 年
target: 就 形 容 动 态 ， 涵 濡 造 化 万 千 姿
====================
src:净 瓶 杨 柳 枝 ， 洒 点 点 风 调 雨 顺
output: 红 杏 红 花 朵 ， 点 点 点 点 染 花 红
target: 紫 竹 白 莺 哥 ， 叫 声 声 国 泰 民 安
====================
src:清 江 滋 宿 草
output: 碧 水 泛 清 波
target: 细 雨 润 苞 花
Evaluate model. Step: 28000, score: 1.827040, loss: 38.738341
Saving model. Step: 28100, loss: 39.280227
******************************
src: 寄 寓 客 官 ， 守 宿 ， 寒 窗 空 寂 寞
output: 吟 行 老 竹 ， 兴 民 ， 老 口 更 清 寥
target: 节 茶 芸 英 ， 荫 荷 ， 苦 苑 获 芙 蓉
Saving model. Step: 28200, loss: 40.120201
******************************
src: 山 闲 云 影 静
output: 水 静 寺 光 明
target: 寺 古 佛 光 灵
Saving model. Step: 28300, loss: 38.932563
******************************
src: 联 入 千 家 ， 张 张 笑 脸 泛 春 意
output: 联 腾 万 海 ， 锣 业 联 歌 动 党 康
target: 龙 荫 四 季 ， 事 事 欢 心 度 小 康
Saving model. Step: 28400, loss: 39.142739
******************************
src: 无 一 丝 傲 气 ， 是 大 师 亦 是 大 哥 ， 怎 奈 何 谋 面 于 春 、 断 肠 在 夏
output: 几 几 更 青 心 ， 看 大 意 、 添 心 底 ， 怎 不 得 人 间 、 眼 、 不 火 为 天
target: 有 三 绝 殊 荣 ， 倾 心 血 更 倾 心 智 ， 长 留 这 瓷 魂 洁 白 、 炉 火 纯 青
Saving model. Step: 28500, loss: 39.402030
******************************
src: 红 尘 碧 海 痴 情 种
output: 碧 道 清 山 好 意 人
target: 古 佛 青 灯 失 意 人
Saving model. Step: 28600, loss: 39.225309
******************************
src: 航 海 史 中 航 海 使
output: 华 书 山 上 赋 书 人
target: 读 书 廊 上 读 书 郎
Saving model. Step: 28700, loss: 39.267307
******************************
src: 龙 睛 不 点 恐 飞 去
output: 燕 鼓 无 鸣 不 自 来
target: 锣 鼓 常 敲 却 舞 来
Saving model. Step: 28800, loss: 38.852876
******************************
src: 使 者 领 班 ， 百 年 礼 乐 行 三 献
output: 学 儿 出 曳 ， 一 片 风 声 唱 九 床
target: 女 仙 摇 佩 ， 一 派 箫 韶 起 半 空
Saving model. Step: 28900, loss: 39.312928
******************************
src: 国 泰 民 安 歌 盛 世
output: 风 香 鸟 语 颂 新 春
target: 花 香 鸟 语 庆 新 春
Saving model. Step: 29000, loss: 39.763332
******************************
src: 书 径 深 深 通 远 古
output: 书 山 峻 峻 仰 高 贤
target: 德 山 矗 矗 仰 先 贤
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:美 园 美 焕 古 今 情 ， 喜 远 养 禅 风 ， 近 养 仁 风 ， 远 近 无 双 朝 锦 绣
output: 大 地 长 流 天 下 梦 ， 喜 人 文 天 下 ， 同 心 气 象 ， 长 存 一 代 正 气 歌
target: 荣 氏 荣 开 荆 楚 梦 ， 有 天 之 道 业 ， 人 之 德 业 ， 天 人 合 一 阅 辉 煌
====================
src:以 油 瓶 投 深 水 者 ， 瓶 破 瓦 沉 ， 其 油 浮 上
output: 于 天 井 点 点 红 尘 ， 花 开 花 落 ， 其 梦 在 乎
target: 若 业 识 于 命 终 时 ， 识 迁 身 坏 ， 彼 业 现 前
====================
src:正 待 桃 红 春 上 路
output: 长 留 柳 绿 燕 穿 梭
target: 恰 逢 柳 绿 燕 回 门
====================
src:登 高 能 望 远
output: 入 世 可 知 贫
target: 历 久 可 知 心
====================
src:书 似 长 梯 ， 送 我 攀 登 知 识 峰 顶
output: 心 如 大 海 ， 看 他 俯 首 看 看 江 山
target: 学 如 航 船 ， 带 人 漫 步 真 理 海 洋
====================
src:人 情 义 理 当 兼 顾
output: 世 事 风 流 不 可 求
target: 世 故 伦 常 得 互 融
====================
src:灯 下 千 针 慈 母 线 ， 青 丝 成 皓 首
output: 门 前 一 片 红 尘 路 ， 绿 水 映 红 颜
target: 榻 边 百 馔 孝 儿 心 ， 寸 草 报 春 晖
====================
src:星 稀 月 秀 斋 常 静
output: 水 远 山 高 气 自 闲
target: 雨 过 山 青 心 最 闲
====================
src:右 翼 抬 头 ， 军 国 幽 灵 再 现
output: 中 华 圆 梦 ， 人 民 富 贵 无 疆
target: 小 泉 当 道 ， 东 条 魔 影 重 来
====================
src:夜 雨 扫 凉 灯 下 影
output: 晨 风 吹 绿 柳 头 风
target: 鸡 声 啼 破 枕 边 书
====================
src:鼓 大 河 风 ， 嵩 岳 迎 春 先 起 势
output: 兴 新 岁 月 ， 龙 城 焕 彩 更 扬 眉
target: 圆 中 国 梦 ， 愚 公 矢 志 再 移 山
====================
src:有 意 打 工 ， 风 平 倚 树 觅 新 枝 ， 三 生 大 幸
output: 无 心 无 意 ， 心 系 一 生 忧 乐 在 ， 一 路 平 安
target: 无 辜 下 岗 ， 夜 静 凭 栏 寻 旧 梦 ， 五 味 俱 全
Evaluate model. Step: 29000, score: 1.921451, loss: 39.763332
Saving model. Step: 29100, loss: 38.770399
******************************
src: 静 读 不 虚 兰 蕙 质
output: 闲 游 不 在 竹 云 风
target: 神 游 自 带 碧 螺 春
Saving model. Step: 29200, loss: 38.861765
******************************
src: 赏 月 同 喝 团 圆 酒
output: 观 春 共 饮 大 一 年
target: 迎 春 共 毓 统 一 花
Saving model. Step: 29300, loss: 39.182710
******************************
src: 人 行 中 路 月 生 海
output: 我 立 天 篱 风 上 天
target: 松 拂 疏 窗 竹 映 阑
Saving model. Step: 29400, loss: 38.583780
******************************
src: 掬 水 天 人 真 合 一
output: 寻 杯 月 色 好 同 双
target: 举 杯 月 我 恰 成 三
Saving model. Step: 29500, loss: 38.896584
******************************
src: 听 沽 水 新 声 ， 报 萃 精 华 ， 雅 士 咸 集 吟 好 韵
output: 喜 江 门 大 苑 ， 情 联 雅 事 ， 新 风 更 续 展 中 风
target: 看 津 门 联 苑 ， 楹 传 喜 庆 ， 高 阶 再 迈 振 雄 风
Saving model. Step: 29600, loss: 39.248295
******************************
src: 老 梅 据 地 争 今 古
output: 老 马 飞 天 戏 水 天
target: 一 鹤 湍 风 放 水 云
Saving model. Step: 29700, loss: 38.578786
******************************
src: 若 可 知 心 成 莫 逆
output: 不 如 得 意 得 人 杯
target: 何 妨 尽 兴 到 杯 干
Saving model. Step: 29800, loss: 38.985366
******************************
src: 花 红 藕 白 莲 蓬 绿
output: 柳 绿 茶 黄 竹 叶 青
target: 果 黝 松 苍 树 柢 黄
Saving model. Step: 29900, loss: 39.133929
******************************
src: 半 蛋 如 舟 ， 满 载 黄 金 白 玉
output: 一 生 似 水 ， 一 闻 玉 黛 白 莲
target: 一 盘 似 镜 ， 尽 收 粉 黛 青 红
Saving model. Step: 30000, loss: 39.228512
******************************
src: 言 行 一 致 称 高 尚
output: 心 辱 三 曾 是 大 夫
target: 荣 辱 不 惊 大 丈 夫
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:腾 飞 上 铁 ， 锐 意 改 革 谋 发 展 ， 勇 当 千 里 马
output: 奋 进 中 华 ， 和 谐 发 展 和 谐 兴 ， 更 上 一 层 楼
target: 和 谐 南 供 ， 安 全 送 电 保 畅 通 ， 争 做 领 头 羊
====================
src:自 命 清 高 装 隐 士
output: 人 生 淡 雅 醉 骚 人
target: 难 能 可 贵 是 虚 心
====================
src:三 春 桃 李 东 皇 染
output: 一 片 丹 心 北 斗 星
target: 万 里 风 云 北 极 生
====================
src:今 朝 旖 旎 风 光 秀
output: 此 际 玲 珑 气 象 新
target: 往 昔 峥 嵘 岁 月 稠
====================
src:金 秋 炫 彩 秋 菊 艳
output: 玉 宇 飞 花 春 雨 香
target: 丹 桂 飘 香 桂 月 明
====================
src:眼 前 漫 瞩 ， 惟 灵 气 所 钟 ， 神 仙 所 宅
output: 心 底 清 清 ， 有 风 云 不 涸 ， 天 地 之 灵
target: 楼 上 长 思 ， 是 朱 公 之 道 ， 项 子 之 心
====================
src:一 炉 香 来 皆 蓬 岛
output: 三 月 月 出 是 仙 宫
target: 三 尺 剑 去 尽 葛 藤
Evaluate model. Step: 30000, score: 2.074309, loss: 39.228512
Saving model. Step: 30100, loss: 39.111912
******************************
src: 江 南 联 友 ， 期 常 江 常 过 长 江 ， 常 讲 讲 对 联 常 识
output: 天 上 人 情 ， 看 天 山 而 游 远 海 ， 更 吟 听 诗 韵 长 来
target: 岭 北 道 家 ， 隐 远 岭 远 来 苑 岭 ， 远 聆 聆 同 道 远 谋
Saving model. Step: 30200, loss: 39.609224
******************************
src: 一 湾 绿 水 渔 村 小
output: 满 里 青 山 日 祖 宽
target: 万 里 青 山 佛 寺 幽
Saving model. Step: 30300, loss: 38.878098
******************************
src: 做 事 莫 嫌 难 ， 天 下 无 难 事
output: 为 民 须 有 爱 ， 世 间 有 少 心
target: 为 人 应 有 善 ， 世 间 多 善 人
Saving model. Step: 30400, loss: 38.445125
******************************
src: 陇 中 名 邑 ， 山 卧 平 湖 峰 积 翠
output: 海 外 仙 南 ， 水 流 古 水 水 流 红
target: 塞 上 江 南 ， 风 流 曲 径 院 飞 红
Saving model. Step: 30500, loss: 38.229547
******************************
src: 侬 本 多 情 ， 不 借 梅 花 不 借 月
output: 我 能 有 慨 ， 且 凭 流 水 不 流 风
target: 胸 怀 慷 慨 ， 但 随 逝 水 但 随 风
Saving model. Step: 30600, loss: 38.830921
******************************
src: 反 哺 农 乡 ， 开 千 秋 惠 政
output: 欢 谐 社 会 ， 唱 万 代 新 明
target: 和 谐 社 会 ， 启 万 代 文 明
Saving model. Step: 30700, loss: 38.880846
******************************
src: 茶 香 秋 梦 后
output: 月 雅 月 杯 中
target: 诗 韵 酒 酣 时
Saving model. Step: 30800, loss: 38.733662
******************************
src: 壬 子 功 勋 ， 芝 云 齐 绚 彩
output: 中 春 事 业 ， 桃 树 更 辉 阳
target: 三 民 伟 业 ， 葵 日 共 朝 阳
Saving model. Step: 30900, loss: 38.047046
******************************
src: 因 古 诗 享 誉 ， 飘 香 万 里 杜 康 酒
output: 为 天 联 添 香 ， 焕 愧 千 秋 锦 甸 城
target: 以 佳 话 留 名 ， 不 老 千 年 伊 洛 河
Saving model. Step: 31000, loss: 39.017662
******************************
src: 大 雪 飞 ， 萧 风 瑟 ， 本 该 对 句 难 出 手
output: 春 心 夜 ， 明 情 深 ， 心 愿 人 乐 总 关 心
target: 良 宵 短 ， 友 情 长 ， 但 求 欢 娱 总 开 心
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:动 车 穿 洞 过 桥 ， 瑶 寨 迎 来 千 里 马
output: 举 步 赏 春 去 景 ， 春 风 吹 到 九 州 花
target: 河 水 上 坡 越 岭 ， 山 民 饮 到 幸 福 泉
====================
src:一 纸 春 诗 梅 作 序
output: 半 帘 秋 月 柳 弹 琴
target: 两 束 艳 朵 骨 存 心
====================
src:孝 逾 陈 妇 ， 义 抗 桓 嫠 ， 勤 踵 敬 姜 ， 严 符 陶 母
output: 德 耀 古 今 ， 德 昭 日 月 ， 崇 高 尚 德 ， 永 祀 英 才
target: 乐 献 飞 琼 ， 尊 开 少 府 ， 彩 娱 菜 子 ， 文 愧 震 川
====================
src:砍 头 未 惧 英 雄 胆
output: 举 步 皆 为 霸 主 鞭
target: 诛 寇 常 挥 正 义 师
====================
src:聚 会
output: 开 怀
target: 悲 欢
====================
src:民 富 国 强 ， 国 泰 国 安 迎 国 庆
output: 人 和 地 利 ， 民 安 物 阜 颂 中 华
target: 人 勤 春 早 ， 春 风 春 雨 闹 春 耕
====================
src:力 守 边 关 ， 稽 古 屈 功 推 李 广
output: 功 垂 天 地 ， 扬 帆 破 浪 驾 龙 腾
target: 情 牵 天 下 ， 凭 谁 设 榻 效 陈 蕃
====================
src:妙 句 出 炉 须 百 炼
output: 清 风 明 月 是 三 更
target: 名 星 耀 眼 只 一 春
====================
src:白 城 描 绘 上 河 景
output: 赤 县 腾 飞 中 国 龙
target: 红 日 施 加 如 意 章
====================
src:梦 回 魂 已 断
output: 心 醉 泪 难 潸
target: 酒 醒 脑 犹 昏
====================
src:千 年 寺 庙 千 年 塔
output: 万 里 江 山 万 里 天
target: 万 代 江 山 万 代 人
====================
src:走 马 看 花 牵 走 狗
output: 飞 花 落 雁 落 空 花
target: 偷 天 换 日 扯 偷 心
====================
src:狗 皮 膏 药 牛 皮 癣
output: 狗 仔 哈 皮 狗 蛋 皮
target: 人 血 馒 头 猪 血 汤
====================
src:步 马 后 尘 威 不 减
output: 望 人 前 路 路 难 寻
target: 趋 羊 头 领 劲 更 足
Evaluate model. Step: 31000, score: 1.865657, loss: 39.017662
Saving model. Step: 31100, loss: 39.286089
******************************
src: 难 言 之 隐 有 毛 病
output: 不 解 不 然 无 古 心
target: 不 打 自 招 说 冒 牌
Saving model. Step: 31200, loss: 37.925992
******************************
src: 生 机 妙 发
output: 大 气 真 工
target: 意 趣 天 成
Saving model. Step: 31300, loss: 38.635538
******************************
src: 交 易 中 却 无 市 气
output: 人 谈 后 有 有 人 声
target: 笑 谈 里 还 带 书 香
Saving model. Step: 31400, loss: 38.790219
******************************
src: 道 相 当 何 见 于 人 ？ 维 大 巧 曰 亏 、 虚 明 自 照
output: 道 为 尽 不 来 不 法 ， 是 无 心 、 悟 、 不 不 何 空
target: 行 不 得 返 求 诸 己 ， 若 此 心 可 验 、 彼 境 而 知
Saving model. Step: 31500, loss: 39.419196
******************************
src: 颇 知 人 ， 颇 知 我 ， 亲 疏 莫 论
output: 不 听 墨 ， 不 听 琴 ， 书 淡 无 歌
target: 闲 弄 墨 ， 闲 弄 琴 ， 淡 雅 如 初
Saving model. Step: 31600, loss: 38.959037
******************************
src: 欢 声 笑 语 开 心 到
output: 笑 意 联 新 入 气 来
target: 辞 旧 迎 春 财 富 来
Saving model. Step: 31700, loss: 38.760586
******************************
src: 沧 海 入 怀 消 块 垒
output: 风 风 入 地 落 风 埃
target: 劲 风 扫 地 荡 尘 嚣
Saving model. Step: 31800, loss: 38.641555
******************************
src: 庚 辰 兴 旺 ， 龙 魂 披 彩 普 天 庆
output: 巳 亥 欢 平 ， 国 岁 腾 春 万 地 歌
target: 辛 巳 升 平 ， 蛇 序 迎 新 遍 地 春
Saving model. Step: 31900, loss: 38.465037
******************************
src: 不 忘 悯 农 诗 ， 便 是 感 恩 心 一 片
output: 不 知 成 苦 读 ， 何 妨 无 命 意 千 条
target: 未 经 吃 苦 事 ， 何 来 求 学 路 千 条
Saving model. Step: 32000, loss: 38.666858
******************************
src: 景 深 孚 甲 含 胎 际
output: 心 暖 人 家 到 阜 中
target: 春 在 人 心 物 性 间
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:和 谐 兴 旺 ， 党 引 春 风 添 虎 翼
output: 科 学 发 展 ， 民 臻 大 业 振 龙 威
target: 富 裕 平 安 ， 国 描 特 色 绘 龙 图
====================
src:细 雨 流 光 ， 孕 石 涧 春 芽 ， 竹 影 松 风 菊 露 ， 听 涛 阁 上 回 桥 月
output: 清 风 拂 面 ， 听 晨 钟 暮 鼓 ， 钟 声 声 响 响 声 ， 醉 客 心 中 醉 梦 人
target: 苍 台 弃 履 ， 调 犀 杯 酒 色 ， 梅 妻 鹤 子 鸥 盟 ， 洗 砚 池 头 浸 墨 花
====================
src:楼 阁 淡 疏 烟 ， 炉 中 百 和 添 香 兽
output: 山 林 开 画 境 ， 画 里 千 姿 映 画 屏
target: 河 汉 湛 秋 碧 ， 云 天 万 里 看 归 鸿
====================
src:一 树 绿 到 半 天 顶
output: 万 里 红 于 万 里 春
target: 万 山 青 过 双 溪 头
====================
src:居 有 楼 ， 行 有 车 ， 户 户 微 机 ， 网 上 喜 开 致 富 路
output: 人 无 私 ， 事 无 畏 ， 无 非 事 业 ， 人 间 喜 做 大 家 庭
target: 农 无 税 ， 学 无 费 ， 家 家 医 保 ， 梦 中 笑 醒 种 田 人
====================
src:秀 食 驰 名 三 姐 店
output: 金 樽 饮 酒 一 杯 茶
target: 香 厨 享 誉 五 星 衔
====================
src:将 勤 补 拙 ， 开 卷 观 兴 替
output: 以 德 为 邻 ， 举 杯 敬 古 今
target: 以 智 化 愚 ， 挥 毫 写 乐 忧
====================
src:治
output: 收
target: 戡
====================
src:诗 情 画 意 ， 墨 客 笔 端 生 妙 趣
output: 诗 赋 诗 词 ， 诗 词 酒 里 赋 新 诗
target: 民 心 乡 俗 ， 作 家 书 简 尽 淋 漓
====================
src:拜 佛 何 须 来 寺 庙
output: 出 门 不 必 上 天 堂
target: 打 坐 当 然 要 空 心
====================
src:奉 使 纪 浮 楂 ， 早 遣 天 骄 识 麟 凤
output: 传 承 传 世 泽 ， 长 教 大 地 起 鲲 鹏
target: 抡 才 忆 围 棘 ， 曾 同 伯 乐 辨 骊 黄
====================
src:冬 日 观 灯 雪 妖 娆
output: 春 风 拂 柳 柳 婆 娑
target: 春 夜 听 歌 雨 缠 绵
====================
src:溪 畔 流 光 ， 缀 得 千 花 秀
output: 山 中 吐 瑞 ， 迎 来 万 象 新
target: 枕 边 云 气 ， 梦 登 九 宇 烟
====================
src:节 约 办 婚 事 ， 亲 友 皆 欢 喜
output: 和 谐 共 和 谐 ， 和 谐 共 和 谐
target: 勤 俭 建 家 园 ， 夫 妻 更 和 睦
====================
src:梅 心 惊 破 春 情 意
output: 柳 眼 羞 成 夏 意 思
target: 桂 影 筛 出 月 横 波
Evaluate model. Step: 32000, score: 1.974521, loss: 38.666858
Saving model. Step: 32100, loss: 38.381612
******************************
src: 梦 醒 春 声 脆
output: 风 宽 月 子 斜
target: 心 怡 燕 影 娇
Saving model. Step: 32200, loss: 38.457991
******************************
src: 桂 花 松 子 有 仙 意
output: 梅 石 松 山 无 老 心
target: 葛 岭 孤 山 无 俗 人
Saving model. Step: 32300, loss: 38.189169
******************************
src: 一 纸 秋 声 无 落 处
output: 几 般 月 意 有 愁 时
target: 千 般 枉 顾 是 当 时
Saving model. Step: 32400, loss: 38.737712
******************************
src: 眠 花 宿 柳 登 徒 子
output: 落 月 飞 风 醉 子 思
target: 正 坐 危 襟 惠 相 公
Saving model. Step: 32500, loss: 38.937122
******************************
src: 刚 日 读 经 ， 柔 日 读 史
output: 春 州 作 诗 ， 妙 学 赋 诗
target: 神 至 赋 笔 ， 兴 至 赋 诗
Saving model. Step: 32600, loss: 38.967441
******************************
src: 程 门 立 雪 求 学 问
output: 学 业 兴 学 要 文 西
target: 隆 中 谋 策 望 疆 图
Saving model. Step: 32700, loss: 38.481725
******************************
src: 济 世 有 怀 ， 蜚 流 今 雪
output: 兴 人 无 语 ， 不 表 后 垂
target: 诲 人 不 倦 ， 师 范 永 存
Saving model. Step: 32800, loss: 38.711494
******************************
src: 月 入 深 山 问 碧 溪 ， 飞 花 何 去
output: 风 飘 古 室 一 清 豆 ， 醉 水 自 来
target: 香 飘 陋 室 盈 红 袖 ， 流 韵 自 来
Saving model. Step: 32900, loss: 38.790181
******************************
src: 山 川 四 望 是
output: 天 地 一 人 春
target: 天 地 一 壶 通
Saving model. Step: 33000, loss: 37.796535
******************************
src: 秋 实 春 华 成 果 硕
output: 冬 和 国 盛 有 延 长
target: 家 兴 业 旺 福 源 长
INFO:tensorflow:Restoring parameters from ./models/output_couplet/model.ckpl
====================
src:君 德 臣 贤 安 世 道
output: 人 文 德 德 振 家 声
target: 父 慈 子 孝 乐 天 伦
====================
src:地 藏 寺 八 百 年 旧 迹 犹 存 ， 誓 度 众 生 、 誓 成 正 觉
output: 佛 法 寺 千 万 佛 慈 慈 普 济 ， 普 济 众 生 、 普 济 众 生
target: 昆 明 市 十 万 人 偕 乐 之 所 ， 如 游 化 雨 、 如 登 春 台
====================
src:冬 泳 冷 观 众
output: 春 归 大 有 年
target: 北 漂 红 艺 人
====================
src:左 派 右 倾 谈 政 治
output: 东 来 西 去 卖 东 西
target: 贫 僧 老 道 讲 德 行
====================
src:字 湛 辞 新 ， 光 华 焕 发
output: 联 精 作 对 ， 联 语 抒 情
target: 行 芳 志 馥 ， 才 德 兼 长
====================
src:雨 霁 阅 芙 蓉 ， 一 帘 至 美 水 天 画
output: 风 清 吟 柳 絮 ， 万 里 飘 香 风 月 诗
target: 花 香 开 丽 景 ， 八 面 尚 真 云 月 心
====================
src:心 无 小 我 装 天 下
output: 胸 有 灵 犀 贯 古 今
target: 志 有 黎 民 载 永 生
====================
src:命 由 天 定
output: 德 自 自 修
target: 事 在 人 为
====================
src:诲 教 者 当 先 揽 镜
output: 为 人 人 以 慎 修 身
target: 简 言 之 趁 早 磨 刀
====================
src:天 上 人 间 ， 无 猜 花 月 两 相 恨
output: 世 间 世 界 ， 不 尽 风 云 一 世 情
target: 古 往 今 来 ， 有 幸 芝 兰 交 错 结
====================
src:玄 鸟 呈 祥 ， 封 商 兆 瑞
output: 吉 羊 献 瑞 ， 福 寿 延 年
target: 景 山 钟 秀 ， 迁 祖 荷 庥
Evaluate model. Step: 33000, score: 1.979254, loss: 37.796535
Saving model. Step: 33100, loss: 38.390072
******************************
src: 风 移 金 谷 屋
output: 月 舞 玉 花 符
target: 乔 木 好 音 多
Saving model. Step: 33200, loss: 38.409471
******************************
src: 草 秀 芳 花 艳
output: 风 深 翠 语 香
target: 林 深 鸟 语 甜
Saving model. Step: 33300, loss: 39.280556
******************************
src: 孝 犹 感 物 竟 连 栗
output: 德 可 无 风 不 染 松
target: 德 自 生 香 不 独 芝
Saving model. Step: 33400, loss: 38.996744
******************************
src: 雁 阵 横 排 ， 惹 动 思 乡 意
output: 莺 帆 漫 览 ， 飞 来 动 我 魂
target: 云 团 纵 起 ， 操 劳 了 梦 情
Saving model. Step: 33500, loss: 38.862225
******************************
src: 曾 于 太 白 峰 前 住
output: 不 是 青 风 笔 里 来
target: 都 是 春 风 画 里 人
Saving model. Step: 33600, loss: 38.234724
******************************
src: 诚 字 描 红 ， 圣 地 千 行 兴 骏 业
output: 春 诚 载 史 ， 春 黄 万 里 绘 春 风
target: 信 篇 写 灿 ， 炎 陵 万 户 沐 春 光
Saving model. Step: 33700, loss: 37.715899
******************************
src: 玉 韫 珠 怀 ， 山 川 辉 媚
output: 龙 浆 玉 馥 ， 日 样 芬 神
target: 琼 滋 芝 秀 ， 花 草 精 神
Saving model. Step: 33800, loss: 38.911881
******************************
src: 一 段 风 流 谁 似 尔
output: 三 分 寂 意 我 如 君
target: 十 年 诗 酒 爱 逢 君
</code></pre><p><img alt class="post-img b-lazy" data-img="../img/xiniu_neteasy.png" data-index="4" data-src="../img/xiniu_neteasy.png"></p>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/nlp/" rel="tag"># nlp</a>
                    </li>
                    
                    <li>
                        <a href="/tags/自然语言处理/" rel="tag"># 自然语言处理</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="NLP系列" href="/2019-03-21/nlp/4Text_Classification/Chapter1_Text_Classification_based_on_Machine_Learning/3.Principle_of_facebook_fasttext/">
            ← NLP系列
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="NLP系列" href="/2019-03-21/nlp/4Text_Classification/Chapter1_Text_Classification_based_on_Machine_Learning/5.Text_sentiment_analyse_base_on_fasttext/">
            NLP系列 →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#seq2seq构建写对联AI"><span class="toc-text">seq2seq构建写对联AI</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#问题背景介绍"><span class="toc-text">问题背景介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#seq2seq对对联"><span class="toc-text">seq2seq对对联</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据读取"><span class="toc-text">数据读取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#评估函数"><span class="toc-text">评估函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#定义seq2seq"><span class="toc-text">定义seq2seq</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型定义"><span class="toc-text">模型定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型训练"><span class="toc-text">模型训练</span></a></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Pastor Dean &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020-01-16/thinking/Thinking modelBiological thinking Biological thinking looking at the business world from an evolutionary perspective/">Thinking modelBiological thinking Biological thinking: looking at the business world from an evolutionary perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-13/thinking/Modern Darwin Integrated Model  Biological Thinking Mode Opening God Perspective/">Modern Darwin Integrated Model Biological Thinking Mode Opening God is Perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-11/thinking/Metacognition Changing the stubborn thinking of the brain/">Metacognition Changing the stubborn thinking of the brain</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">Categories</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Biological-Thinking/">Biological Thinking</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cognitive-Neuroscience/">Cognitive Neuroscience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FFmpeg/">FFmpeg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MacOS/">MacOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PM/">PM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/RPC/">RPC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ubuntu/">Ubuntu</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Vim/">Vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/WebRTC/">WebRTC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deeplearn/">deeplearn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/http/">http</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machineLearning/">machineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/文摘/">文摘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构师/">架构师</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/知识图谱/">知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/">职业规划</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/个人提升/">个人提升</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机基础/">计算机基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机相关技术资料整理/">计算机相关技术资料整理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/认知升级/">认知升级</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财务自由/">财务自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财富自由/">财富自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">Tag Cloud</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/AI/" style="font-size: 14px;">AI</a> <a href="/tags/Android/" style="font-size: 14px;">Android</a> <a href="/tags/Biological/" style="font-size: 17.75px;">Biological</a> <a href="/tags/Browser/" style="font-size: 14px;">Browser</a> <a href="/tags/Business/" style="font-size: 16.5px;">Business</a> <a href="/tags/Cognitive/" style="font-size: 17.75px;">Cognitive</a> <a href="/tags/DeepLearning/" style="font-size: 15.25px;">DeepLearning</a> <a href="/tags/Docker/" style="font-size: 14px;">Docker</a> <a href="/tags/FFmpeg/" style="font-size: 21.5px;">FFmpeg</a> <a href="/tags/FastCGI/" style="font-size: 14px;">FastCGI</a> <a href="/tags/IP划分/" style="font-size: 14px;">IP划分</a> <a href="/tags/IP地址/" style="font-size: 14px;">IP地址</a> <a href="/tags/Knowledge-Graph/" style="font-size: 16.5px;">Knowledge Graph</a> <a href="/tags/Linux-Shell/" style="font-size: 14px;">Linux Shell</a> <a href="/tags/MacOS/" style="font-size: 15.25px;">MacOS</a> <a href="/tags/Neuroscience/" style="font-size: 17.75px;">Neuroscience</a> <a href="/tags/RPC/" style="font-size: 14px;">RPC</a> <a href="/tags/Thinking/" style="font-size: 17.75px;">Thinking</a> <a href="/tags/Tutorial/" style="font-size: 20.25px;">Tutorial</a> <a href="/tags/WebRTC/" style="font-size: 21.5px;">WebRTC</a> <a href="/tags/WebSocket/" style="font-size: 14px;">WebSocket</a> <a href="/tags/algorithm/" style="font-size: 15.25px;">algorithm</a> <a href="/tags/config/" style="font-size: 14px;">config</a> <a href="/tags/decisionTree/" style="font-size: 14px;">decisionTree</a> <a href="/tags/git/" style="font-size: 17.75px;">git</a> <a href="/tags/google-adsense/" style="font-size: 14px;">google adsense</a> <a href="/tags/hexo/" style="font-size: 17.75px;">hexo</a> <a href="/tags/http/" style="font-size: 17.75px;">http</a> <a href="/tags/knn/" style="font-size: 14px;">knn</a> <a href="/tags/lighttpd/" style="font-size: 15.25px;">lighttpd</a> <a href="/tags/mxnet/" style="font-size: 14px;">mxnet</a> <a href="/tags/mysql/" style="font-size: 22.75px;">mysql</a> <a href="/tags/nlp/" style="font-size: 24px;">nlp</a> <a href="/tags/nodejs/" style="font-size: 14px;">nodejs</a> <a href="/tags/openvpn/" style="font-size: 14px;">openvpn</a> <a href="/tags/other/" style="font-size: 15.25px;">other</a> <a href="/tags/paddle/" style="font-size: 14px;">paddle</a> <a href="/tags/planning/" style="font-size: 20.25px;">planning</a> <a href="/tags/pracitce/" style="font-size: 15.25px;">pracitce</a> <a href="/tags/rich/" style="font-size: 14px;">rich</a> <a href="/tags/shell/" style="font-size: 14px;">shell</a> <a href="/tags/svn/" style="font-size: 14px;">svn</a> <a href="/tags/ubuntu/" style="font-size: 14px;">ubuntu</a> <a href="/tags/vim/" style="font-size: 16.5px;">vim</a> <a href="/tags/webpack/" style="font-size: 14px;">webpack</a> <a href="/tags/webrtc/" style="font-size: 19px;">webrtc</a> <a href="/tags/个人发展/" style="font-size: 14px;">个人发展</a> <a href="/tags/互联网实事/" style="font-size: 14px;">互联网实事</a> <a href="/tags/外链/" style="font-size: 14px;">外链</a> <a href="/tags/提升个人思维/" style="font-size: 14px;">提升个人思维</a> <a href="/tags/文摘/" style="font-size: 15.25px;">文摘</a> <a href="/tags/斜杠青年/" style="font-size: 14px;">斜杠青年</a> <a href="/tags/机器学习/" style="font-size: 16.5px;">机器学习</a> <a href="/tags/架构师/" style="font-size: 14px;">架构师</a> <a href="/tags/测试工具/" style="font-size: 14px;">测试工具</a> <a href="/tags/睡后成长/" style="font-size: 14px;">睡后成长</a> <a href="/tags/睡后收入/" style="font-size: 14px;">睡后收入</a> <a href="/tags/税后收入/" style="font-size: 14px;">税后收入</a> <a href="/tags/笔记/" style="font-size: 14px;">笔记</a> <a href="/tags/自然语言处理/" style="font-size: 24px;">自然语言处理</a> <a href="/tags/视频流/" style="font-size: 15.25px;">视频流</a> <a href="/tags/计算机相关技术资料整理/" style="font-size: 14px;">计算机相关技术资料整理</a> <a href="/tags/认知升级/" style="font-size: 14px;">认知升级</a> <a href="/tags/限速/" style="font-size: 14px;">限速</a> <a href="/tags/面试/" style="font-size: 14px;">面试</a> <a href="/tags/项目管理/" style="font-size: 14px;">项目管理</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/images/favicon-16x16-next.png" alt="Pastor Dean">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Pastor Dean">Pastor Dean &copy; 2020</a>
			
				
			        <span hidden="true" id="/2019-03-21/nlp/7text_generation_v2/couplet_with_seq2seq/couplet_with_seq2seq/" class="leancloud-visitors" data-flag-title="NLP系列">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>


<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>



<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





</body>
</html>
