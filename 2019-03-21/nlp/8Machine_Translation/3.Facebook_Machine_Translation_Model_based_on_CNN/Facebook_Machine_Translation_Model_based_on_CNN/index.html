<!DOCTYPE html>
<html lang="en">







<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>NLP系列 | Pastor Dean</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="pastor">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/images/favicon-16x16-next.png">
	<link rel="apple-touch-icon" href="/images/favicon-16x16-next.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Pastor Dean">
	<meta property="og:type" content="article">
	<meta property="og:title" content="NLP系列 | Pastor Dean">
	<meta property="og:description" content>
	<meta property="og:url" content="https://mrpastor.github.io/2019-03-21/nlp/8Machine_Translation/3.Facebook_Machine_Translation_Model_based_on_CNN/Facebook_Machine_Translation_Model_based_on_CNN/">

	
	<meta property="article:published_time" content="2019-03-21T19:03:00+08:00"> 
	<meta property="article:author" content="pastor">
	<meta property="article:published_first" content="Pastor Dean, /2019-03-21/nlp/8Machine_Translation/3.Facebook_Machine_Translation_Model_based_on_CNN/Facebook_Machine_Translation_Model_based_on_CNN/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Pastor Dean">
                    <img src="/images/favicon-32x32-next.png" alt="Pastor Dean">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/" title="home">home</a>
            </li>
            
            <li>
                <a href="/categories/" title="categories">categories</a>
            </li>
            
            <li>
                <a href="/archives/" title="archives">archives</a>
            </li>
            
            <li>
                <a href="/tools/" title="tools">tools</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/mrpastor" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2019-03-21T11:19:18.000Z">
                    2019-03-21
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/NLP/">NLP</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">NLP系列</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h1 id="facebook基于CNN的机器翻译模型"><a href="#facebook基于CNN的机器翻译模型" class="headerlink" title="facebook基于CNN的机器翻译模型"></a>facebook基于CNN的机器翻译模型</h1><h2 id="本章概述"><a href="#本章概述" class="headerlink" title="本章概述"></a>本章概述</h2><ul>
<li>基于CNN的翻译系统模型架构<ul>
<li>Pooling Encoder</li>
<li>Convolution Encoder</li>
<li>Convolution NMT</li>
<li>对比CNN与RNN去构建的 encoder-decoder模型，分析CNN的优缺点</li>
</ul>
</li>
<li>使用CNN完成神经翻译系统的Trick<ul>
<li>对模型某些部分做缩放（scaling）</li>
<li>对模型参数的初始化</li>
<li>对超参数的选择</li>
</ul>
</li>
<li>【实战】facebook CNN机器翻译系统代码解析<ul>
<li>举例训练，及测试 CNN翻译系统</li>
<li>分析 FconvModel, FconvEncoder, FconvDecoder</li>
<li>分析 main 函数中训练模型部分</li>
</ul>
</li>
</ul>
<h2 id="1-基于CNN的翻译系统模型结构"><a href="#1-基于CNN的翻译系统模型结构" class="headerlink" title="1.基于CNN的翻译系统模型结构"></a>1.基于CNN的翻译系统模型结构</h2><ul>
<li>在自然语言处理中，大部分流行的seq2seq模型都是基于RNN结构去构建encoder和decoder，但是RNN对于下一个状态的预测需要依赖前面的所有历史状态，使得并行化操作难以充分进行，难以发挥完全发挥GPU并行的效率。相反CNN通过在固定窗口内的计算，使得计算的并行化变得更加简单，而且通过多层CNN网络可以构建层级结构(hierarchical structure)，可以达到利用更短的路径去覆盖更长范围内的信息。</li>
<li>Facebook提出了基于CNN的机器翻译模型，并开源了CNN的机器翻译工具<a href="https://github.com/facebookresearch/fairseq" target="_blank" rel="noopener">Fairseq</a></li>
</ul>
<h3 id="1-1-Pooling-Encoder"><a href="#1-1-Pooling-Encoder" class="headerlink" title="1.1 Pooling Encoder"></a>1.1 Pooling Encoder</h3><ul>
<li>最简单的non-recurrent encoder就是把k个连续的单词的词向量求平均值，通过在句子左右两边都做添加额外的空单词(paddings)，可以使得encoder输出跟原来句子同等长度的hidden embeddings。<ul>
<li>假设原来的句子的词向量（word embedding）表示为 $w=[w_1,\cdots,w_m],~\forall~w_j\in R^f$</li>
<li>absolute position embeddings用于编码位置信息　$p=[p_1,\cdots,p_m],~\forall~p_j\in R^f$<br>$$e_j = w_j + p_j,~~ z_j = {1\over k} \sum_{t=-k/2}^{k/2}e_{j+t} $$</li>
<li>传统的attention 机制<br>$$ c_i = \sum_{j=1}^m a_{ij} e_j$$</li>
</ul>
</li>
</ul>
<h3 id="1-2-卷积编码器-Convolutional-Encoder-NMT-Gehring-et-al-2016"><a href="#1-2-卷积编码器-Convolutional-Encoder-NMT-Gehring-et-al-2016" class="headerlink" title="1.2 卷积编码器　Convolutional Encoder NMT Gehring et. al 2016"></a>1.2 卷积编码器　Convolutional Encoder NMT <a href="https://arxiv.org/pdf/1611.02344.pdf" target="_blank" rel="noopener">Gehring et. al 2016</a></h3><ul>
<li>卷积编码器在pooling encoder的基础上进行改进，使用一个CNN-a 卷积层来进一步编码源语言句子中的每个单词</li>
</ul>
<p>$$z_j = CNN-a(e)_j $$</p>
<ul>
<li>注意attention的时候，使用了另一个CNN-c　卷积层来编码源语言句子中的每个单词，并计算atttention weight，再进行加权求和<br>$$c_i = \sum_{j=1}^m a_{ij} CNN-c(e)_j$$</li>
</ul>
<h3 id="1-2-卷积编码器-Convolutional-Encoder-NMT-Gehring-et-al-2016-1"><a href="#1-2-卷积编码器-Convolutional-Encoder-NMT-Gehring-et-al-2016-1" class="headerlink" title="1.2 卷积编码器　Convolutional Encoder NMT Gehring et. al 2016"></a>1.2 卷积编码器　Convolutional Encoder NMT <a href="https://arxiv.org/pdf/1611.02344.pdf" target="_blank" rel="noopener">Gehring et. al 2016</a></h3><ul>
<li>该模型的encoder 采用的是CNN，但其decoder还是采用了传统的RNN模型</li>
</ul>
<p><img alt class="post-img b-lazy" data-img="./img/cnn-encoder.png" data-index="0" data-src="./img/cnn-encoder.png"></p>
<h3 id="1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017"><a href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017" class="headerlink" title="1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017"></a>1.３ 全卷积神经翻译模型　Convolutional NMT <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Gehring et. al 2017</a></h3><ul>
<li>该模型的encoder和decoder都采用的是卷积核CNN，动图演示<br><img alt class="post-img b-lazy" data-img="./img/fairseq.gif" data-index="1" data-src="./img/fairseq.gif"></li>
</ul>
<h3 id="1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-1"><a href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-1" class="headerlink" title="1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017"></a>1.３ 全卷积神经翻译模型　Convolutional NMT <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Gehring et. al 2017</a></h3><ul>
<li><p>卷积核结构</p>
<ul>
<li><p>假设有1D的卷积核的窗口大小是k(比如k=5)，每个卷积核都可以用一个权重矩阵$W\in \mathbb{R}^{2d\times kd}$和 bias $b_w\in \mathbb{R}^{2d}$。对于窗口内的词向量　$X\in \mathbb{R}^{k\times d}$把每个单词都拼接成一个长向量　$X’\in \mathbb{R}^{kd}$.<br>$$Y=WX’+b_w = [A B] \in \mathbb{R}^{2d} \ A,B\in \mathbb{R}^{d} $$</p>
</li>
<li><p>接下来我们采用Gated Linear Unites(GLU)的方式来进行编码, $\sigma()$是一个非线性的激活函数，　$\otimes$是element-wise mulitiplication，指的是对两个向量中的每个维度上的数值分别求乘积　<br>$$v([A B] = A \otimes \sigma(B) \in \mathbb{R}^d$$</p>
</li>
<li><p>残差连接　Residual Connection:　把上一层的输入也累加到下一层的输出<br>$$h_i^l = v(W^l [h_{(i-k)/2}^{l-1},\cdots,h_{(i+k)/2}^{l-1}]+b_w^l)+h_i^{l-1}　\in \mathbb{R}^d$$</p>
</li>
</ul>
</li>
</ul>
<h3 id="1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-2"><a href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-2" class="headerlink" title="1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017"></a>1.３ 全卷积神经翻译模型　Convolutional NMT <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Gehring et. al 2017</a></h3><ul>
<li><p>编码器　Encoder:</p>
<ul>
<li>假设原来的句子的词向量（word embedding）表示为 $w=[w_1,\cdots,w_m],~\forall~w_j\in \mathbb{R}^f$</li>
<li><p>absolute position embeddings用于编码位置信息　$p=[p_1,\cdots,p_m],~\forall~p_j\in \mathbb{R}^f$<br>$$e_j = w_j + p_j \ $$</p>
</li>
<li><p>encoder 先用一个线性函数$f:\mathbb{R}^f\rightarrow \mathbb{R}^d$，把词向量映射到d维空间中  </p>
</li>
<li>接下来encoder会将词向量通过一层层卷积核，得到每一层的单词的隐式表达（hidden state）, 其中　$z_j^u$　代表的是第u层CNN中第j个单词的表达</li>
</ul>
</li>
</ul>
<h3 id="1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-3"><a href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-3" class="headerlink" title="1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017"></a>1.３ 全卷积神经翻译模型　Convolutional NMT <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Gehring et. al 2017</a></h3><ul>
<li><p>Multi-step Attention机制</p>
<ul>
<li><p>假设已经翻译的单词的词表达是 $g=[g_1,\cdots, g_n]$，跟源语言的词表达一样，这里也是word embeddings加上positional embeddings<br>－假设decoder的卷积核的hidden state $h_i^l$, 可以进一步计算decoder已经生成的单词的每一层的单词表达<br>$$d_i^l = W_d^l h_i^l + b_d^l + g_i $$</p>
<p>－假设encoder 最顶层(假设是第u层)中，每个单词的表达是　$z_j^u$。我们可以计算decoder第l层中第i个已经生成的单词　$h_i^l$与源语言句子中最顶层（也即是第u层）的第j个单词 $z_j^u$的权重:<br>$$a_{ij}^l = {\exp(d_i^l \cdot z_j^u) \over \sum_{t=1}^m \exp(d_i^l \cdot z_t^u) } $$</p>
<p>－我们可以进一步计算在decoder第l层，在第i个时刻的上下文向量（也即是context vector）如以下公式，其中我们将encoder最顶层(第u层)的词向量$z_j^u$与最底层的词向量$e_j$相加。</p>
<p>$$c_i^l = \sum_{j=1}^m a_{ij}^l (z_j^u + e_j) $$<br>－一旦我们计算好$c_i^l$,我们将　$c_i^l$加到$h_i^l$中，作为decoder 的下一层的输入</p>
</li>
</ul>
</li>
</ul>
<h3 id="1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-4"><a href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-4" class="headerlink" title="1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017"></a>1.３ 全卷积神经翻译模型　Convolutional NMT <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Gehring et. al 2017</a></h3><ul>
<li>解码器　decoder<ul>
<li>把decoder最顶层的hidden state $h_i^L$　通过一个线性的函数映射到词表空间上$d\rightarrow |V|$，之后在通过一个softmax函数　归一化成一个条件概率向量：<br>$$p(y_{i+1}|y_1,\cdots, y_i, x)= softmax(W_o h_i^L + b_0) \in \mathbb{R}^{|V|} $$</li>
</ul>
</li>
</ul>
<h3 id="1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-5"><a href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-5" class="headerlink" title="1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017"></a>1.３ 全卷积神经翻译模型　Convolutional NMT <a href="https://arxiv.org/pdf/1705.03122.pdf" target="_blank" rel="noopener">Gehring et. al 2017</a></h3><ul>
<li>模型的结构图</li>
</ul>
<p><img alt="Drawing" style="width: 500px;" class="post-img b-lazy" data-img="./img/cnn-nmt.png" data-index="2" data-src="./img/cnn-nmt.png"></p>
<h3 id="1-4-全卷积神经翻译模型对比RNN神经翻译模型"><a href="#1-4-全卷积神经翻译模型对比RNN神经翻译模型" class="headerlink" title="1.4 全卷积神经翻译模型对比RNN神经翻译模型"></a>1.4 全卷积神经翻译模型对比RNN神经翻译模型</h3><ul>
<li>全卷积神经网络使用层级结构，可以充分地并行化</li>
<li>对于一个窗口大小为$k$的CNN，编码一个特征向量可以总结一个窗口为n个单词的信息，只需要做$O(n/k)$个卷积核操作。对比RNN，RNN编码一个窗口为n个单词的信息，需要做$O(n)$个操作，跟句子的长度成正比</li>
<li>对于一个CNN的输入，我们都进行了相同数量的卷积操作及非线性操作。对比RNN，第一个输入的单词进行了n词非线性操作，而最后一个输入的单词只进行了一次非线性操作。对于每个输入都进行相同数量的操作会有利于训练。</li>
<li>训练CNN NMT需要非常小心地设置参数及调整网络中某些层的缩放。</li>
</ul>
<h2 id="2-使用CNN完成神经机器翻译系统的tricks"><a href="#2-使用CNN完成神经机器翻译系统的tricks" class="headerlink" title="2 使用CNN完成神经机器翻译系统的tricks"></a>2 使用CNN完成神经机器翻译系统的tricks</h2><ul>
<li>训练过程中，我们需要将网络中某些部分进行缩放(scaling)</li>
<li>训练过程中，我们需要对权重初始化</li>
<li>训练过程中，我们需要对超参数进行设置</li>
</ul>
<h3 id="2-1-缩放操作（scaling）"><a href="#2-1-缩放操作（scaling）" class="headerlink" title="2.1 缩放操作（scaling）"></a>2.1 缩放操作（scaling）</h3><ul>
<li>我们将残差层的输出乘以　$\sqrt{0.5}$，　这样会减小一半的偏差variance</li>
<li>对于attention机制产生的上下文向量　$c_{ij}^l$　乘以一个系数　$m\sqrt{1/m}$, 其中m为源语言句子中单词个个数，这样做的好处也是能减小偏差。</li>
<li>对于CNN decoder有multiple atttention的情况，我们将encoder 每一层的gradient乘以一个系数，该系数是我们使用的attention的数量。注意的是，我们只对encoder中除了源语言单词的词向量矩阵以外的参数进行放大他们的gradient，源语言的词向量矩阵的gradient不进行放大。在实验中，我们发现这样的操作会使得训练能更加稳定。</li>
</ul>
<h3 id="2-2-参数初始化"><a href="#2-2-参数初始化" class="headerlink" title="2.2 参数初始化"></a>2.2 参数初始化</h3><ul>
<li>所有的词向量矩阵从一个以０为中心，标准差为0.1的高斯分布中随机初始化　$\mathcal{N}(0, \sqrt{n_l})$, 其中$n_l$为输入到这个神经元的输入个数，一般我们可以设置为0.1。这样能有助于保持一个正态分布的偏差。</li>
<li>我们还需要对每一层的激活函数输出进行正则化(normalization)，　比如残差连接中，每一层层的输出向量需要先做正则化，再把这一层的输入加到输出的向量上。</li>
<li>对于GLU，我们需要对其权重　$W$从一个正态分布$\mathcal{N}(0, \sqrt{4p\over n_l})$中随机抽样，而其bias设置成０</li>
<li>我们对每一层网络的输入向量都进行dropout处理</li>
</ul>
<h3 id="2-3-超参数设置"><a href="#2-3-超参数设置" class="headerlink" title="2.3 超参数设置"></a>2.3 超参数设置</h3><ul>
<li>encoder 和decoder都是用512维的hidden units，512维的word embeddings</li>
<li>训练的时候使用Nesterov’s accelerated gradient 的方法进行优化模型，momentum 设置成0.99</li>
<li>如果gradient的norm超过0.1就把gradient 重新归一化到0.1以内。</li>
<li>初始的learning rate设置成0.25，如果在每次进行valudation的时候dev数据集中的perplexity没有下降，我们就将learning rate乘以0.1,　一直持续到learning rate 降到$10^{-4}$以下我们停止训练</li>
<li>mini-batch　的大小设置成每次处理64句双语句子</li>
</ul>
<h2 id="3-Facebook-CNN-机器翻译系统代码解析"><a href="#3-Facebook-CNN-机器翻译系统代码解析" class="headerlink" title="3. Facebook CNN 机器翻译系统代码解析"></a>3. Facebook CNN 机器翻译系统代码解析</h2><ul>
<li>相应的代码可以在github上找到　<a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener">fairseq</a></li>
<li>安装<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/pytorch/fairseq.git</span><br><span class="line"><span class="built_in">cd</span> fairseq</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line">python setup.py build develop</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-1-实战例子"><a href="#3-1-实战例子" class="headerlink" title="3.1 实战例子"></a>3.1 实战例子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预处理数据</span></span><br><span class="line">$ bash prepare-wmt14en2de.sh --icml17</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> examples/translation/</span><br><span class="line">$ bash prepare-wmt14en2de.sh</span><br><span class="line">$ <span class="built_in">cd</span> ../..</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据处理成二进制形式，加速读写</span></span><br><span class="line">$ TEXT=examples/translation/wmt14_en_de</span><br><span class="line">$ python preprocess.py --<span class="built_in">source</span>-lang en --target-lang de \</span><br><span class="line">  --trainpref <span class="variable">$TEXT</span>/train --validpref <span class="variable">$TEXT</span>/valid --testpref <span class="variable">$TEXT</span>/<span class="built_in">test</span> \</span><br><span class="line">  --destdir data-bin/wmt14_en_de --thresholdtgt 0 --thresholdsrc 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="comment"># 如果显存不足，可以将--max-tokens设置成1500</span></span><br><span class="line">$ mkdir -p checkpoints/fconv_wmt_en_de</span><br><span class="line">$ python train.py data-bin/wmt14_en_de \</span><br><span class="line">  --lr 0.5 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \</span><br><span class="line">  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \</span><br><span class="line">  --lr-scheduler fixed --force-anneal 50 \</span><br><span class="line">  --arch fconv_wmt_en_de --save-dir checkpoints/fconv_wmt_en_de</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试，生成</span></span><br><span class="line">$ python generate.py data-bin/wmt14_en_de \</span><br><span class="line">  --path checkpoints/fconv_wmt_en_de/checkpoint_best.pt --beam 5 --remove-bpe</span><br></pre></td></tr></table></figure>
<h3 id="3-2-使用预训练好的模型"><a href="#3-2-使用预训练好的模型" class="headerlink" title="3.2 使用预训练好的模型"></a>3.2 使用预训练好的模型</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载模型及数据</span></span><br><span class="line">$ mkdir -p data-bin</span><br><span class="line">$ curl https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2 | tar xvjf - -C data-bin</span><br><span class="line">$ curl https://dl.fbaipublicfiles.com/fairseq/data/wmt14.v2.en-fr.newstest2014.tar.bz2 | tar xvjf - -C data-bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行翻译生成</span></span><br><span class="line">$ python generate.py data-bin/wmt14.en-fr.newstest2014  \</span><br><span class="line">  --path data-bin/wmt14.en-fr.fconv-py/model.pt \</span><br><span class="line">  --beam 5 --batch-size 128 --remove-bpe | tee /tmp/gen.out</span><br><span class="line">...</span><br><span class="line">| Translated 3003 sentences (96311 tokens) <span class="keyword">in</span> 166.0s (580.04 tokens/s)</span><br><span class="line">| Generate <span class="built_in">test</span> with beam=5: BLEU4 = 40.83, 67.5/46.9/34.4/25.5 (BP=1.000, ratio=1.006, syslen=83262, reflen=82787)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对翻译结果打分</span></span><br><span class="line">$ grep ^H /tmp/gen.out | cut -f3- &gt; /tmp/gen.out.sys</span><br><span class="line">$ grep ^T /tmp/gen.out | cut -f2- &gt; /tmp/gen.out.ref</span><br><span class="line">$ python score.py --sys /tmp/gen.out.sys --ref /tmp/gen.out.ref</span><br><span class="line">BLEU4 = 40.83, 67.5/46.9/34.4/25.5 (BP=1.000, ratio=1.006, syslen=83262, reflen=82787)</span><br></pre></td></tr></table></figure>
<h3 id="3-3-代码讲解"><a href="#3-3-代码讲解" class="headerlink" title="3.3 代码讲解"></a>3.3 代码讲解</h3><ul>
<li>CNN NMT类 FConvModel<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@register_model('fconv')</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FConvModel</span><span class="params">(FairseqModel)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        encoder (FConvEncoder): the encoder</span></span><br><span class="line"><span class="string">        decoder (FConvDecoder): the decoder</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_args</span><span class="params">(parser)</span>:</span></span><br><span class="line">        parser.add_argument(<span class="string">'--dropout'</span>, type=float, metavar=<span class="string">'D'</span>,</span><br><span class="line">                            help=<span class="string">'dropout probability'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--encoder-embed-dim'</span>, type=int, metavar=<span class="string">'N'</span>,</span><br><span class="line">                            help=<span class="string">'encoder embedding dimension'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--encoder-embed-path'</span>, type=str, metavar=<span class="string">'STR'</span>,</span><br><span class="line">                            help=<span class="string">'path to pre-trained encoder embedding'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--encoder-layers'</span>, type=str, metavar=<span class="string">'EXPR'</span>,</span><br><span class="line">                            help=<span class="string">'encoder layers [(dim, kernel_size), ...]'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--decoder-embed-dim'</span>, type=int, metavar=<span class="string">'N'</span>,</span><br><span class="line">                            help=<span class="string">'decoder embedding dimension'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--decoder-embed-path'</span>, type=str, metavar=<span class="string">'STR'</span>,</span><br><span class="line">                            help=<span class="string">'path to pre-trained decoder embedding'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--decoder-layers'</span>, type=str, metavar=<span class="string">'EXPR'</span>,</span><br><span class="line">                            help=<span class="string">'decoder layers [(dim, kernel_size), ...]'</span>)</span><br><span class="line">        parser.add_argument(<span class="string">'--decoder-out-embed-dim'</span>, type=int, metavar=<span class="string">'N'</span>,</span><br><span class="line">                            help=<span class="string">'decoder output embedding dimension'</span>)</span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">(cls, args, task)</span>:</span></span><br><span class="line">        base_architecture(args)</span><br><span class="line">        ...</span><br><span class="line">        encoder = FConvEncoder(</span><br><span class="line">            dictionary=task.source_dictionary,</span><br><span class="line">            embed_dim=args.encoder_embed_dim,</span><br><span class="line">            embed_dict=encoder_embed_dict,</span><br><span class="line">            convolutions=eval(args.encoder_layers),</span><br><span class="line">            dropout=args.dropout,</span><br><span class="line">            max_positions=args.max_source_positions,</span><br><span class="line">        )</span><br><span class="line">        decoder = FConvDecoder(</span><br><span class="line">            dictionary=task.target_dictionary,</span><br><span class="line">            embed_dim=args.decoder_embed_dim,</span><br><span class="line">            embed_dict=decoder_embed_dict,</span><br><span class="line">            convolutions=eval(args.decoder_layers),</span><br><span class="line">            out_embed_dim=args.decoder_out_embed_dim,</span><br><span class="line">            attention=eval(args.decoder_attention),</span><br><span class="line">            dropout=args.dropout,</span><br><span class="line">            max_positions=args.max_target_positions,</span><br><span class="line">            share_embed=args.share_input_output_embed,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> FConvModel(encoder, decoder)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-3-代码讲解-1"><a href="#3-3-代码讲解-1" class="headerlink" title="3.3 代码讲解"></a>3.3 代码讲解</h3><ul>
<li>CNN encoder类 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FConvEncoder</span><span class="params">(FairseqEncoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            self, dictionary, embed_dim=<span class="number">512</span>, embed_dict=None, max_positions=<span class="number">1024</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">            convolutions=<span class="params">(<span class="params">(<span class="number">512</span>, <span class="number">3</span>)</span>,)</span> * <span class="number">20</span>, dropout=<span class="number">0.1</span>, left_pad=True,</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span>:</span></span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 定义词向量矩阵及位置矩阵</span></span><br><span class="line">        self.embed_tokens = Embedding(num_embeddings, embed_dim, self.padding_idx)</span><br><span class="line">        self.embed_positions = PositionalEmbedding(</span><br><span class="line">            max_positions,</span><br><span class="line">            embed_dim,</span><br><span class="line">            self.padding_idx,</span><br><span class="line">            left_pad=self.left_pad,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        convolutions = extend_conv_spec(convolutions)</span><br><span class="line">        in_channels = convolutions[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        self.fc1 = Linear(embed_dim, in_channels, dropout=dropout)</span><br><span class="line">        self.projections = nn.ModuleList()</span><br><span class="line">        self.convolutions = nn.ModuleList()</span><br><span class="line">        self.residuals = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义CNN层及残差层</span></span><br><span class="line">        layer_in_channels = [in_channels]</span><br><span class="line">        <span class="keyword">for</span> _, (out_channels, kernel_size, residual) <span class="keyword">in</span> enumerate(convolutions):</span><br><span class="line">            <span class="keyword">if</span> residual == <span class="number">0</span>:</span><br><span class="line">                residual_dim = out_channels</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                residual_dim = layer_in_channels[-residual]</span><br><span class="line">            self.projections.append(Linear(residual_dim, out_channels)</span><br><span class="line">                                    <span class="keyword">if</span> residual_dim != out_channels <span class="keyword">else</span> <span class="keyword">None</span>)</span><br><span class="line">            <span class="keyword">if</span> kernel_size % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                padding = kernel_size // <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                padding = <span class="number">0</span></span><br><span class="line">            self.convolutions.append(</span><br><span class="line">                ConvTBC(in_channels, out_channels * <span class="number">2</span>, kernel_size,</span><br><span class="line">                        dropout=dropout, padding=padding)</span><br><span class="line">            )</span><br><span class="line">            self.residuals.append(residual)</span><br><span class="line">            in_channels = out_channels</span><br><span class="line">            layer_in_channels.append(out_channels)</span><br><span class="line">        self.fc2 = Linear(in_channels, embed_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src_tokens, src_lengths)</span>:</span></span><br><span class="line">        <span class="comment"># 查找词向量及位置向量</span></span><br><span class="line">        x = self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)</span><br><span class="line">        x = F.dropout(x, p=self.dropout, training=self.training)</span><br><span class="line">        input_embedding = x</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将词的表达映射到CNN的输入空间 fc1: R^f -&gt;R^d</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在句子左右两边添加padding</span></span><br><span class="line">        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()  <span class="comment"># -&gt; T x B</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> encoder_padding_mask.any():</span><br><span class="line">            encoder_padding_mask = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转置：B x T x C -&gt; T x B x C</span></span><br><span class="line">        x = x.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        residuals = [x]</span><br><span class="line">        <span class="comment"># 多层的CNN 层叠起来</span></span><br><span class="line">        <span class="keyword">for</span> proj, conv, res_layer <span class="keyword">in</span> zip(self.projections, self.convolutions, self.residuals):</span><br><span class="line">            <span class="keyword">if</span> res_layer &gt; <span class="number">0</span>:</span><br><span class="line">                residual = residuals[-res_layer]</span><br><span class="line">                residual = residual <span class="keyword">if</span> proj <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">else</span> proj(residual)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                residual = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> encoder_padding_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                x = x.masked_fill(encoder_padding_mask.unsqueeze(<span class="number">-1</span>), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            x = F.dropout(x, p=self.dropout, training=self.training)</span><br><span class="line">            <span class="keyword">if</span> conv.kernel_size[<span class="number">0</span>] % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># padding is implicit in the conv</span></span><br><span class="line">                x = conv(x)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                padding_l = (conv.kernel_size[<span class="number">0</span>] - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">                padding_r = conv.kernel_size[<span class="number">0</span>] // <span class="number">2</span></span><br><span class="line">                x = F.pad(x, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, padding_l, padding_r))</span><br><span class="line">                x = conv(x)</span><br><span class="line">            <span class="comment"># GLU 层</span></span><br><span class="line">            x = F.glu(x, dim=<span class="number">2</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 残差层</span></span><br><span class="line">            <span class="keyword">if</span> residual <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                x = (x + residual) * math.sqrt(<span class="number">0.5</span>)</span><br><span class="line">            residuals.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># T x B x C -&gt; B x T x C</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将x映射回词向量空间 R^d -&gt; R^f</span></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> encoder_padding_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            encoder_padding_mask = encoder_padding_mask.t()  <span class="comment"># -&gt; B x T</span></span><br><span class="line">            x = x.masked_fill(encoder_padding_mask.unsqueeze(<span class="number">-1</span>), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将gradient放大</span></span><br><span class="line">        x = GradMultiply.apply(x, <span class="number">1.0</span> / (<span class="number">2.0</span> * self.num_attention_layers))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 把input embedding加到output中</span></span><br><span class="line">        y = (x + input_embedding) * math.sqrt(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">'encoder_out'</span>: (x, y),</span><br><span class="line">            <span class="string">'encoder_padding_mask'</span>: encoder_padding_mask,  <span class="comment"># B x T</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-3-代码讲解-2"><a href="#3-3-代码讲解-2" class="headerlink" title="3.3 代码讲解"></a>3.3 代码讲解</h3><ul>
<li>解码器decoder</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FConvDecoder</span><span class="params">(FairseqIncrementalDecoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,...)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义词向量矩阵及位置向量矩阵</span></span><br><span class="line">        self.embed_tokens = Embedding(num_embeddings, embed_dim, padding_idx)</span><br><span class="line">        self.embed_positions = PositionalEmbedding(</span><br><span class="line">            max_positions,</span><br><span class="line">            embed_dim,</span><br><span class="line">            padding_idx,</span><br><span class="line">            left_pad=self.left_pad,</span><br><span class="line">        ) <span class="keyword">if</span> positional_embeddings <span class="keyword">else</span> <span class="keyword">None</span></span><br><span class="line">        </span><br><span class="line">        convolutions = extend_conv_spec(convolutions)</span><br><span class="line">        in_channels = convolutions[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        self.fc1 = Linear(embed_dim, in_channels, dropout=dropout)</span><br><span class="line">        self.projections = nn.ModuleList()</span><br><span class="line">        self.convolutions = nn.ModuleList()</span><br><span class="line">        self.attention = nn.ModuleList()</span><br><span class="line">        self.residuals = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义多层CNN</span></span><br><span class="line">        layer_in_channels = [in_channels]</span><br><span class="line">        <span class="keyword">for</span> i, (out_channels, kernel_size, residual) <span class="keyword">in</span> enumerate(convolutions):</span><br><span class="line">            <span class="keyword">if</span> residual == <span class="number">0</span>:</span><br><span class="line">                residual_dim = out_channels</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                residual_dim = layer_in_channels[-residual]</span><br><span class="line">            self.projections.append(Linear(residual_dim, out_channels)</span><br><span class="line">                                    <span class="keyword">if</span> residual_dim != out_channels <span class="keyword">else</span> <span class="keyword">None</span>)</span><br><span class="line">            self.convolutions.append(</span><br><span class="line">                LinearizedConv1d(in_channels, out_channels * <span class="number">2</span>, kernel_size,</span><br><span class="line">                                 padding=(kernel_size - <span class="number">1</span>), dropout=dropout)</span><br><span class="line">            )</span><br><span class="line">            self.attention.append(AttentionLayer(out_channels, embed_dim)</span><br><span class="line">                                  <span class="keyword">if</span> attention[i] <span class="keyword">else</span> <span class="keyword">None</span>)</span><br><span class="line">            self.residuals.append(residual)</span><br><span class="line">            in_channels = out_channels</span><br><span class="line">            layer_in_channels.append(out_channels)</span><br><span class="line"></span><br><span class="line">        self.adaptive_softmax = <span class="keyword">None</span></span><br><span class="line">        self.fc2 = self.fc3 = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, prev_output_tokens, encoder_out_dict=None, incremental_state=None)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 获得位置向量</span></span><br><span class="line">        <span class="keyword">if</span> self.embed_positions <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            pos_embed = self.embed_positions(prev_output_tokens, incremental_state)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pos_embed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获得上一个生成的单词的词向量</span></span><br><span class="line">        x = self._embed_tokens(prev_output_tokens, incremental_state)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将词向量加上位置向量作为当前时刻的输入</span></span><br><span class="line">        x += pos_embed</span><br><span class="line">        x = F.dropout(x, p=self.dropout, training=self.training)</span><br><span class="line">        target_embedding = x</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将输入从词向量空间映射到CNN输入空间</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转置：B x T x C -&gt; T x B x C</span></span><br><span class="line">        x = self._transpose_if_training(x, incremental_state)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 多层的CNN 堆叠</span></span><br><span class="line">        avg_attn_scores = <span class="keyword">None</span></span><br><span class="line">        num_attn_layers = len(self.attention)</span><br><span class="line">        residuals = [x]</span><br><span class="line">        <span class="keyword">for</span> proj, conv, attention, res_layer <span class="keyword">in</span> zip(self.projections, self.convolutions, self.attention,</span><br><span class="line">                                                    self.residuals):</span><br><span class="line">            <span class="keyword">if</span> res_layer &gt; <span class="number">0</span>:</span><br><span class="line">                residual = residuals[-res_layer]</span><br><span class="line">                residual = residual <span class="keyword">if</span> proj <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">else</span> proj(residual)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                residual = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">            x = F.dropout(x, p=self.dropout, training=self.training)</span><br><span class="line">            x = conv(x, incremental_state)</span><br><span class="line">            x = F.glu(x, dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 注意力机制</span></span><br><span class="line">            <span class="keyword">if</span> attention <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                x = self._transpose_if_training(x, incremental_state)</span><br><span class="line"></span><br><span class="line">                x, attn_scores = attention(x, target_embedding, (encoder_a, encoder_b), encoder_padding_mask)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> self.training <span class="keyword">and</span> self.need_attn:</span><br><span class="line">                    attn_scores = attn_scores / num_attn_layers</span><br><span class="line">                    <span class="keyword">if</span> avg_attn_scores <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                        avg_attn_scores = attn_scores</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        avg_attn_scores.add_(attn_scores)</span><br><span class="line"></span><br><span class="line">                x = self._transpose_if_training(x, incremental_state)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 残差连接</span></span><br><span class="line">            <span class="keyword">if</span> residual <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                x = (x + residual) * math.sqrt(<span class="number">0.5</span>)</span><br><span class="line">            residuals.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转置：T x B x C -&gt; B x T x C</span></span><br><span class="line">        x = self._transpose_if_training(x, incremental_state)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># fc2:将输入映射到词表大小空间，可进行预测</span></span><br><span class="line">        <span class="keyword">if</span> self.fc2 <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">and</span> self.fc3 <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            x = self.fc2(x)</span><br><span class="line">            x = F.dropout(x, p=self.dropout, training=self.training)</span><br><span class="line">            x = self.fc3(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, avg_attn_scores</span><br></pre></td></tr></table></figure>
<h3 id="3-3-代码讲解-3"><a href="#3-3-代码讲解-3" class="headerlink" title="3.3 代码讲解"></a>3.3 代码讲解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(args, init_distributed=False)</span>:</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 载入数据</span></span><br><span class="line">    load_dataset_splits(task, [<span class="string">'train'</span>, <span class="string">'valid'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建模型及优化函数</span></span><br><span class="line">    model = task.build_model(args)</span><br><span class="line">    criterion = task.build_criterion(args)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建训练器 trainer</span></span><br><span class="line">    trainer = Trainer(args, task, model, criterion, dummy_batch, oom_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化dataloader</span></span><br><span class="line">    epoch_itr = task.get_batch_iterator(...)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练一直到learning rate太小就停止</span></span><br><span class="line">    max_epoch = args.max_epoch <span class="keyword">or</span> math.inf</span><br><span class="line">    max_update = args.max_update <span class="keyword">or</span> math.inf</span><br><span class="line">    lr = trainer.get_lr()</span><br><span class="line">    train_meter = StopwatchMeter()</span><br><span class="line">    train_meter.start()</span><br><span class="line">    <span class="keyword">while</span> lr &gt; args.min_lr <span class="keyword">and</span> epoch_itr.epoch &lt; max_epoch <span class="keyword">and</span> trainer.get_num_updates() &lt; max_update:</span><br><span class="line">        <span class="comment"># 训练一个epoch</span></span><br><span class="line">        train(args, trainer, task, epoch_itr)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch_itr.epoch % args.validate_interval == <span class="number">0</span>:</span><br><span class="line">            valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 只用第一个validation loss去更新learning rate</span></span><br><span class="line">        lr = trainer.lr_step(epoch_itr.epoch, valid_losses[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="keyword">if</span> epoch_itr.epoch % args.save_interval == <span class="number">0</span>:</span><br><span class="line">            save_checkpoint(args, trainer, epoch_itr, valid_losses[<span class="number">0</span>])</span><br><span class="line">    train_meter.stop()</span><br></pre></td></tr></table></figure>
<h2 id="本节小结"><a href="#本节小结" class="headerlink" title="本节小结"></a>本节小结</h2><ul>
<li>基于CNN的翻译系统模型架构<ul>
<li>Pooling Encoder</li>
<li>Convolution Encoder</li>
<li>Convolution NMT</li>
<li>对比CNN与RNN去构建的 encoder-decoder模型，分析CNN的优缺点</li>
</ul>
</li>
<li>使用CNN完成神经翻译系统的Trick<ul>
<li>对模型某些部分做缩放（scaling）</li>
<li>对模型参数的初始化</li>
<li>对超参数的选择</li>
</ul>
</li>
<li>【实战】facebook CNN机器翻译系统代码解析<ul>
<li>举例训练，及测试 CNN翻译系统</li>
<li>分析了 FconvModel, FconvEncoder, FconvDecoder</li>
<li>分析了 main 函数中训练模型部分</li>
</ul>
</li>
</ul>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/nlp/" rel="tag"># nlp</a>
                    </li>
                    
                    <li>
                        <a href="/tags/自然语言处理/" rel="tag"># 自然语言处理</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="NLP系列" href="/2019-03-21/nlp/4Text_Classification/Chapter2_Chapter1_Text_Classification_based_on_Deep_Learning/2.News_Classification_based_on_CNN/">
            ← NLP系列
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="NLP系列" href="/2019-03-21/nlp/2NLP_Basics2/lesson2/3.Emotion Detection/">
            NLP系列 →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#facebook基于CNN的机器翻译模型"><span class="toc-text">facebook基于CNN的机器翻译模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#本章概述"><span class="toc-text">本章概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-基于CNN的翻译系统模型结构"><span class="toc-text">1.基于CNN的翻译系统模型结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Pooling-Encoder"><span class="toc-text">1.1 Pooling Encoder</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-卷积编码器-Convolutional-Encoder-NMT-Gehring-et-al-2016"><span class="toc-text">1.2 卷积编码器　Convolutional Encoder NMT Gehring et. al 2016</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-卷积编码器-Convolutional-Encoder-NMT-Gehring-et-al-2016-1"><span class="toc-text">1.2 卷积编码器　Convolutional Encoder NMT Gehring et. al 2016</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017"><span class="toc-text">1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-1"><span class="toc-text">1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-2"><span class="toc-text">1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-3"><span class="toc-text">1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-4"><span class="toc-text">1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-３-全卷积神经翻译模型-Convolutional-NMT-Gehring-et-al-2017-5"><span class="toc-text">1.３ 全卷积神经翻译模型　Convolutional NMT Gehring et. al 2017</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-全卷积神经翻译模型对比RNN神经翻译模型"><span class="toc-text">1.4 全卷积神经翻译模型对比RNN神经翻译模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-使用CNN完成神经机器翻译系统的tricks"><span class="toc-text">2 使用CNN完成神经机器翻译系统的tricks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-缩放操作（scaling）"><span class="toc-text">2.1 缩放操作（scaling）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-参数初始化"><span class="toc-text">2.2 参数初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-超参数设置"><span class="toc-text">2.3 超参数设置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Facebook-CNN-机器翻译系统代码解析"><span class="toc-text">3. Facebook CNN 机器翻译系统代码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-实战例子"><span class="toc-text">3.1 实战例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-使用预训练好的模型"><span class="toc-text">3.2 使用预训练好的模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-代码讲解"><span class="toc-text">3.3 代码讲解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-代码讲解-1"><span class="toc-text">3.3 代码讲解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-代码讲解-2"><span class="toc-text">3.3 代码讲解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-代码讲解-3"><span class="toc-text">3.3 代码讲解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#本节小结"><span class="toc-text">本节小结</span></a></li></ol></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Pastor Dean &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020-01-16/thinking/Thinking modelBiological thinking Biological thinking looking at the business world from an evolutionary perspective/">Thinking modelBiological thinking Biological thinking: looking at the business world from an evolutionary perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-13/thinking/Modern Darwin Integrated Model  Biological Thinking Mode Opening God Perspective/">Modern Darwin Integrated Model Biological Thinking Mode Opening God is Perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-11/thinking/Metacognition Changing the stubborn thinking of the brain/">Metacognition Changing the stubborn thinking of the brain</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/images/favicon-16x16-next.png" alt="Pastor Dean">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Pastor Dean">Pastor Dean &copy; 2020</a>
			
				
			        <span hidden="true" id="/2019-03-21/nlp/8Machine_Translation/3.Facebook_Machine_Translation_Model_based_on_CNN/Facebook_Machine_Translation_Model_based_on_CNN/" class="leancloud-visitors" data-flag-title="NLP系列">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>


<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>



<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





</body>
</html>
