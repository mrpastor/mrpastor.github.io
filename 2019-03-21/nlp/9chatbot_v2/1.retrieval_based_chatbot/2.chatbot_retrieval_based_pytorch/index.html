<!DOCTYPE html>
<html lang="en">







<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>NLPç³»åˆ— | Pastor Dean</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="pastor">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/images/favicon-16x16-next.png">
	<link rel="apple-touch-icon" href="/images/favicon-16x16-next.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Pastor Dean">
	<meta property="og:type" content="article">
	<meta property="og:title" content="NLPç³»åˆ— | Pastor Dean">
	<meta property="og:description" content>
	<meta property="og:url" content="https://mrpastor.github.io/2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/2.chatbot_retrieval_based_pytorch/">

	
	<meta property="article:published_time" content="2019-03-21T19:03:00+08:00"> 
	<meta property="article:author" content="pastor">
	<meta property="article:published_first" content="Pastor Dean, /2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/2.chatbot_retrieval_based_pytorch/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Pastor Dean">
                    <img src="/images/favicon-32x32-next.png" alt="Pastor Dean">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/" title="home">home</a>
            </li>
            
            <li>
                <a href="/categories/" title="categories">categories</a>
            </li>
            
            <li>
                <a href="/archives/" title="archives">archives</a>
            </li>
            
            <li>
                <a href="/tools/" title="tools">tools</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/mrpastor" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2019-03-21T11:19:18.000Z">
                    2019-03-21
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/NLP/">NLP</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">NLPç³»åˆ—</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h1 id="æ„å»ºäºUbuntuå¯¹è¯æ•°æ®é›†ä¸Šçš„åŸºäºæ£€ç´¢çš„èŠå¤©æœºå™¨äºº"><a href="#æ„å»ºäºUbuntuå¯¹è¯æ•°æ®é›†ä¸Šçš„åŸºäºæ£€ç´¢çš„èŠå¤©æœºå™¨äºº" class="headerlink" title="æ„å»ºäºUbuntuå¯¹è¯æ•°æ®é›†ä¸Šçš„åŸºäºæ£€ç´¢çš„èŠå¤©æœºå™¨äºº"></a>æ„å»ºäºUbuntuå¯¹è¯æ•°æ®é›†ä¸Šçš„åŸºäºæ£€ç´¢çš„èŠå¤©æœºå™¨äºº</h1><p><strong>æç¤ºï¼šå¦‚æœå¤§å®¶è§‰å¾—è®¡ç®—èµ„æºæœ‰é™ï¼Œæ¬¢è¿å¤§å®¶åœ¨â€ç§‘å­¦ä¸Šç½‘â€œåå…è´¹è¯•ç”¨<a href="https://colab.research.google.com" target="_blank" rel="noopener">googleçš„colab</a>ï¼Œæœ‰å…è´¹çš„K80 GPUä¾›å¤§å®¶ä½¿ç”¨ï¼Œå¤§å®¶åªéœ€è¦æŠŠè¯¾ç¨‹çš„notebookä¸Šä¼ å³å¯è¿è¡Œ</strong></p>
<p>å’Œä¸Šä¸€ä¸ªnotebookä¸€æ ·ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢çš„å¯¹è¯ç³»ç»Ÿï¼Œæˆ‘ä»¬ä¼šå¯¹å€™é€‰é›†ä¸­çš„å›ç­”å’Œé—®é¢˜è¿›è¡ŒåŒ¹é…æ‰“åˆ†ï¼Œæ ¹æ®åˆ†æ•°çš„é«˜ä½è¿›è¡Œæ’åºå¹¶ç»™å‡ºæˆ‘ä»¬é€‰æ‹©çš„æœ€ä½³å›å¤ã€‚</p>
<p>å®Œæ•´çš„æ•°æ®å¯ä»¥åœ¨Google Driveæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ï¼š<a href="https://drive.google.com/open?id=1RIIbsS-vxR7Dlo2_v6FWHDFE7q1XPPgj" target="_blank" rel="noopener">https://drive.google.com/open?id=1RIIbsS-vxR7Dlo2_v6FWHDFE7q1XPPgj</a></p>
<p> <strong>è¦å¤ç°æ–‡æ¡£ä¸­çš„ä»£ç ï¼Œéœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</strong></p>
<p>1) <strong>ä¸‹è½½</strong> ä»¥ä¸‹æ–‡ä»¶:</p>
<pre><code>- glove.6B.50d.txt (Subfolder GloVe)
- training_10000.csv (Subfolder MAIN FILES)
- validation_1000.csv (Subfolder MAIN FILES)
- testing_same_structure_1000.csv (Subfolder MAIN FILES)
- testing_different_structure_100.csv (Subfolder MAIN FILES)
- saved_model_10000_gpu.pt (Subfolder SAVED MODELS)
</code></pre><p>2) <strong>è°ƒæ•´å˜é‡å¤§å°</strong> ï¼šå¯¹äºä»£ç ä¸­å‡ºç°çš„ <em>num_training_examples</em>, <em>num_validation_examples</em>, <em>embedding_dim</em>, <em>test_dataframe_same_structure</em>, <em>test_dataframe_different_structure</em> å’Œ<em>saved model file name</em> å¯ä»¥æ ¹æ®æ•°æ®é‡çš„å¤§å°è¿›è¡Œè°ƒæ•´</p>
<p>3) <strong>è°ƒæ•´è¶…å‚æ•°è®¾ç½®</strong>ï¼šå…·ä½“æ¨¡å‹çš„å‚æ•°å¤§å®¶å¯ä»¥è‡ªå·±è°ƒæ•´ï¼Œä¹Ÿå¯ä»¥å‚è€ƒSAVED MODELSæ–‡ä»¶å¤¹ä¸‹çš„å†…å®¹ï¼Œä½ å¯ä»¥æ‰¾åˆ°<strong>æ¨¡å‹æˆªå›¾</strong>ï¼Œåšå’Œå®ƒä¸€æ ·çš„è®¾å®šï¼Œå¤§å®¶ä¹Ÿå¯ä»¥å¤ç°æœ¬notebookçš„ç»“æœã€‚</p>
<p>==========================================================================================================</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive</span><br><span class="line">drive.mount(<span class="string">'/content/gdrive'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&amp;response_type=code

Enter your authorization code:
Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·
Mounted at /content/gdrive
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!ls /content/gdrive/My\ Drive/Dialogue\ Files\</span><br></pre></td></tr></table></figure>
<pre><code>GloVe    &apos;MAIN FILES&apos;  &apos;Original Files&apos;    &apos;SAVED MODELS&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install torch torchvision</span><br></pre></td></tr></table></figure>
<pre><code>Collecting torch
[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)
[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 591.8MB 24kB/s 
tcmalloc: large alloc 1073750016 bytes == 0x6211c000 @  0x7effd0bd42a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641
[?25hCollecting torchvision
[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)
[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 26.8MB/s 
[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)
Collecting pillow&gt;=4.1.1 (from torchvision)
[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)
[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0MB 7.2MB/s 
[?25hInstalling collected packages: torch, pillow, torchvision
  Found existing installation: Pillow 4.0.0
    Uninstalling Pillow-4.0.0:
      Successfully uninstalled Pillow-4.0.0
Successfully installed pillow-5.4.1 torch-1.0.0 torchvision-0.2.1
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.autograd <span class="keyword">as</span> autograd</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> torch.nn.utils.rnn </span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="å®šä¹‰helperå‡½æ•°ä»¥æ„å»ºè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­çš„å˜é‡"><a href="#å®šä¹‰helperå‡½æ•°ä»¥æ„å»ºè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­çš„å˜é‡" class="headerlink" title="å®šä¹‰helperå‡½æ•°ä»¥æ„å»ºè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­çš„å˜é‡"></a>å®šä¹‰helperå‡½æ•°ä»¥æ„å»ºè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­çš„å˜é‡</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataframe</span><span class="params">(csvfile)</span>:</span></span><br><span class="line">    dataframe = pd.read_csv(csvfile)</span><br><span class="line">    <span class="keyword">return</span> dataframe</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffle_dataframe</span><span class="params">(dataframe)</span>:</span></span><br><span class="line">    dataframe.reindex(np.random.permutation(dataframe.index))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_vocab</span><span class="params">(dataframe)</span>:</span></span><br><span class="line">    vocab = []</span><br><span class="line">    word_freq = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> dataframe.iterrows():</span><br><span class="line">        </span><br><span class="line">        context_cell = row[<span class="string">"Context"</span>]</span><br><span class="line">        response_cell = row[<span class="string">"Utterance"</span>]</span><br><span class="line">        </span><br><span class="line">        train_words = str(context_cell).split() + str(response_cell).split()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> train_words:</span><br><span class="line">          </span><br><span class="line">            <span class="keyword">if</span> word.lower() <span class="keyword">not</span> <span class="keyword">in</span> vocab:</span><br><span class="line">                vocab.append(word.lower())         </span><br><span class="line">                       </span><br><span class="line">            <span class="keyword">if</span> word.lower() <span class="keyword">not</span> <span class="keyword">in</span> word_freq:</span><br><span class="line">                word_freq[word.lower()] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                word_freq[word] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    word_freq_sorted = sorted(word_freq.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line">    vocab = [<span class="string">"&lt;UNK&gt;"</span>] + [pair[<span class="number">0</span>] <span class="keyword">for</span> pair <span class="keyword">in</span> word_freq_sorted]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> vocab</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_word_to_id</span><span class="params">(vocab)</span>:</span>             </span><br><span class="line">    word_to_id = &#123;word: id <span class="keyword">for</span> id, word <span class="keyword">in</span> enumerate(vocab)&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> word_to_id</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_id_to_vec</span><span class="params">(word_to_id, glovefile)</span>:</span> </span><br><span class="line">    lines = open(glovefile, <span class="string">'r'</span>).readlines()</span><br><span class="line">    id_to_vec = &#123;&#125;</span><br><span class="line">    vector = <span class="keyword">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        word = line.split()[<span class="number">0</span>]</span><br><span class="line">        vector = np.array(line.split()[<span class="number">1</span>:], dtype=<span class="string">'float32'</span>) <span class="comment">#32</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> word_to_id:</span><br><span class="line">            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(vector))</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">for</span> word, id <span class="keyword">in</span> word_to_id.items(): </span><br><span class="line">        <span class="keyword">if</span> word_to_id[word] <span class="keyword">not</span> <span class="keyword">in</span> id_to_vec:</span><br><span class="line">            v = np.zeros(*vector.shape, dtype=<span class="string">'float32'</span>)</span><br><span class="line">            v[:] = np.random.randn(*v.shape)*<span class="number">0.01</span></span><br><span class="line">            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(v))</span><br><span class="line">            </span><br><span class="line">    embedding_dim = id_to_vec[<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> id_to_vec, embedding_dim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_ids_and_labels</span><span class="params">(row, word_to_id)</span>:</span></span><br><span class="line">    context_ids = []</span><br><span class="line">    response_ids = []</span><br><span class="line"></span><br><span class="line">    context_cell = row[<span class="string">'Context'</span>]</span><br><span class="line">    response_cell = row[<span class="string">'Utterance'</span>]</span><br><span class="line">    label_cell = row[<span class="string">'Label'</span>]</span><br><span class="line"></span><br><span class="line">    max_context_len = <span class="number">160</span></span><br><span class="line">    </span><br><span class="line">    context_words = context_cell.split()</span><br><span class="line">    <span class="keyword">if</span> len(context_words) &gt; max_context_len:</span><br><span class="line">        context_words = context_words[:max_context_len]</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> context_words:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> word_to_id:</span><br><span class="line">            context_ids.append(word_to_id[word])</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            context_ids.append(<span class="number">0</span>) <span class="comment">#UNK</span></span><br><span class="line">    </span><br><span class="line">    response_words = response_cell.split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> response_words:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> word_to_id:</span><br><span class="line">            response_ids.append(word_to_id[word])</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            response_ids.append(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    label = np.array(label_cell).astype(np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> context_ids, response_ids, label</span><br></pre></td></tr></table></figure>
<h2 id="æ¨¡å‹å®šä¹‰"><a href="#æ¨¡å‹å®šä¹‰" class="headerlink" title="æ¨¡å‹å®šä¹‰"></a>æ¨¡å‹å®šä¹‰</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, </span></span></span><br><span class="line"><span class="function"><span class="params">            emb_size, </span></span></span><br><span class="line"><span class="function"><span class="params">            hidden_size, </span></span></span><br><span class="line"><span class="function"><span class="params">            vocab_size, </span></span></span><br><span class="line"><span class="function"><span class="params">            p_dropout)</span>:</span> </span><br><span class="line">    </span><br><span class="line">            super(Encoder, self).__init__()</span><br><span class="line">             </span><br><span class="line">            self.emb_size = emb_size</span><br><span class="line">            self.hidden_size = hidden_size</span><br><span class="line">            self.vocab_size = vocab_size</span><br><span class="line">            self.p_dropout = p_dropout</span><br><span class="line">       </span><br><span class="line">            self.embedding = nn.Embedding(self.vocab_size, self.emb_size)</span><br><span class="line">            self.lstm = nn.LSTM(self.emb_size, self.hidden_size)</span><br><span class="line">            self.dropout_layer = nn.Dropout(self.p_dropout) </span><br><span class="line"></span><br><span class="line">            self.init_weights()</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">(self)</span>:</span></span><br><span class="line">        init.uniform(self.lstm.weight_ih_l0, a = <span class="number">-0.01</span>, b = <span class="number">0.01</span>)</span><br><span class="line">        init.orthogonal(self.lstm.weight_hh_l0)</span><br><span class="line">        self.lstm.weight_ih_l0.requires_grad = <span class="keyword">True</span></span><br><span class="line">        self.lstm.weight_hh_l0.requires_grad = <span class="keyword">True</span></span><br><span class="line">        </span><br><span class="line">        embedding_weights = torch.FloatTensor(self.vocab_size, self.emb_size)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> id, vec <span class="keyword">in</span> id_to_vec.items():</span><br><span class="line">            embedding_weights[id] = vec</span><br><span class="line">        </span><br><span class="line">        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad = <span class="keyword">True</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        embeddings = self.embedding(inputs)</span><br><span class="line">        _, (last_hidden, _) = self.lstm(embeddings) <span class="comment">#dimensions: (num_layers * num_directions x batch_size x hidden_size)</span></span><br><span class="line">        last_hidden = self.dropout_layer(last_hidden[<span class="number">-1</span>])<span class="comment">#access last lstm layer, dimensions: (batch_size x hidden_size)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> last_hidden</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DualEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">     </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder)</span>:</span></span><br><span class="line">        super(DualEncoder, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.hidden_size = self.encoder.hidden_size</span><br><span class="line">        M = torch.FloatTensor(self.hidden_size, self.hidden_size)     </span><br><span class="line">        init.xavier_normal(M)</span><br><span class="line">        self.M = nn.Parameter(M, requires_grad = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, context_tensor, response_tensor)</span>:</span></span><br><span class="line">        </span><br><span class="line">        context_last_hidden = self.encoder(context_tensor) <span class="comment">#dimensions: (batch_size x hidden_size)</span></span><br><span class="line">        response_last_hidden = self.encoder(response_tensor) <span class="comment">#dimensions: (batch_size x hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#context = context_last_hidden.mm(self.M).cuda()</span></span><br><span class="line">        context = context_last_hidden.mm(self.M) <span class="comment">#dimensions: (batch_size x hidden_size)</span></span><br><span class="line">        context = context.view(<span class="number">-1</span>, <span class="number">1</span>, self.hidden_size) <span class="comment">#dimensions: (batch_size x 1 x hidden_size)</span></span><br><span class="line">        </span><br><span class="line">        response = response_last_hidden.view(<span class="number">-1</span>, self.hidden_size, <span class="number">1</span>) <span class="comment">#dimensions: (batch_size x hidden_size x 1)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#score = torch.bmm(context, response).view(-1, 1).cuda()</span></span><br><span class="line">        score = torch.bmm(context, response).view(<span class="number">-1</span>, <span class="number">1</span>) <span class="comment">#dimensions: (batch_size x 1 x 1) and lastly --&gt; (batch_size x 1)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>
<h2 id="æ•°æ®ä¸å˜é‡æ„å»º"><a href="#æ•°æ®ä¸å˜é‡æ„å»º" class="headerlink" title="æ•°æ®ä¸å˜é‡æ„å»º"></a>æ•°æ®ä¸å˜é‡æ„å»º</h2><p><strong>å®šä¹‰å‡½æ•°å»è°ƒç”¨æ‰€æœ‰çš„helperå‡½æ•°ï¼Œä»¥ä¾¿å®Œæˆå„ç§æ•°æ®å’Œå˜é‡åˆå§‹åŒ–ï¼Œä»¥åŠéƒ¨åˆ†çš„é¢„è®­ç»ƒè¯å‘é‡åŠ è½½ç­‰</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creating_variables</span><span class="params">(num_training_examples, num_validation_examples, embedding_dim)</span>:</span></span><br><span class="line"></span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Creating variables for training and validation..."</span>)</span><br><span class="line"></span><br><span class="line">    training_dataframe = create_dataframe(<span class="string">'training_%d.csv'</span> %num_training_examples)</span><br><span class="line">    vocab = create_vocab(training_dataframe)</span><br><span class="line">    word_to_id = create_word_to_id(vocab)</span><br><span class="line">    id_to_vec, emb_dim = create_id_to_vec(word_to_id, <span class="string">'glove.6B.%dd.txt'</span> %embedding_dim)</span><br><span class="line"></span><br><span class="line">    validation_dataframe = create_dataframe(<span class="string">'validation_%d.csv'</span> %num_validation_examples)</span><br><span class="line"></span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Variables created.\n"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> training_dataframe, vocab, word_to_id, id_to_vec, emb_dim, validation_dataframe</span><br></pre></td></tr></table></figure>
<h2 id="æ¨¡å‹æ„å»º"><a href="#æ¨¡å‹æ„å»º" class="headerlink" title="æ¨¡å‹æ„å»º"></a>æ¨¡å‹æ„å»º</h2><p><strong>è°ƒç”¨Encoderå’ŒDualEncoderå»æ„å»ºæ¨¡å‹</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creating_model</span><span class="params">(hidden_size, p_dropout)</span>:</span></span><br><span class="line"></span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Calling model..."</span>)</span><br><span class="line"></span><br><span class="line">    encoder = Encoder(</span><br><span class="line">            emb_size = emb_dim,</span><br><span class="line">            hidden_size = hidden_size,</span><br><span class="line">            vocab_size = len(vocab),</span><br><span class="line">            p_dropout = p_dropout)</span><br><span class="line"></span><br><span class="line">    dual_encoder = DualEncoder(encoder)</span><br><span class="line"></span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Model created.\n"</span>)</span><br><span class="line">    print(dual_encoder)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> encoder, dual_encoder</span><br></pre></td></tr></table></figure>
<p><strong>è®­ç»ƒé›†å’ŒéªŒè¯é›†å‡†ç¡®ç‡è®¡ç®—</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increase_count</span><span class="params">(correct_count, score, label)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> ((score.data[<span class="number">0</span>][<span class="number">0</span>] &gt;= <span class="number">0.5</span>) <span class="keyword">and</span> (label.data[<span class="number">0</span>][<span class="number">0</span>] == <span class="number">1.0</span>)) <span class="keyword">or</span> ((score.data[<span class="number">0</span>][<span class="number">0</span>] &lt; <span class="number">0.5</span>) <span class="keyword">and</span> (label.data[<span class="number">0</span>][<span class="number">0</span>]  == <span class="number">0.0</span>)):</span><br><span class="line">       correct_count +=<span class="number">1</span>  </span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span> correct_count</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_accuracy</span><span class="params">(correct_count, dataframe)</span>:</span></span><br><span class="line">    accuracy = correct_count/(len(dataframe))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br></pre></td></tr></table></figure>
<h2 id="æ¨¡å‹è®­ç»ƒ"><a href="#æ¨¡å‹è®­ç»ƒ" class="headerlink" title="æ¨¡å‹è®­ç»ƒ"></a>æ¨¡å‹è®­ç»ƒ</h2><p>æ„å»ºæ¨¡å‹è®­ç»ƒå‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span><span class="params">(learning_rate, l2_penalty, epochs)</span>:</span> </span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Starting training and validation...\n"</span>)</span><br><span class="line">    print(<span class="string">"====================Data and Hyperparameter Overview====================\n"</span>)</span><br><span class="line">    print(<span class="string">"Number of training examples: %d, Number of validation examples: %d"</span> %(len(training_dataframe), len(validation_dataframe)))</span><br><span class="line">    print(<span class="string">"Learning rate: %.5f, Embedding Dimension: %d, Hidden Size: %d, Dropout: %.2f, L2:%.10f\n"</span> %(learning_rate, emb_dim, encoder.hidden_size, encoder.p_dropout, l2_penalty))</span><br><span class="line">    print(<span class="string">"================================Results...==============================\n"</span>)</span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(dual_encoder.parameters(), lr = learning_rate, weight_decay = l2_penalty)</span><br><span class="line">       </span><br><span class="line">    loss_func = torch.nn.BCEWithLogitsLoss()</span><br><span class="line">    <span class="comment">#loss_func.cuda()</span></span><br><span class="line">     </span><br><span class="line">    best_validation_accuracy = <span class="number">0.0</span></span><br><span class="line">     </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">                     </span><br><span class="line">            shuffle_dataframe(training_dataframe)</span><br><span class="line">                        </span><br><span class="line">            sum_loss_training = <span class="number">0.0</span></span><br><span class="line">            </span><br><span class="line">            training_correct_count = <span class="number">0</span></span><br><span class="line">            </span><br><span class="line">            dual_encoder.train()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> index, row <span class="keyword">in</span> training_dataframe.iterrows():            </span><br><span class="line">            </span><br><span class="line">                context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)</span><br><span class="line">                </span><br><span class="line">                context = autograd.Variable(torch.LongTensor(context_ids).view(<span class="number">-1</span>,<span class="number">1</span>), requires_grad = <span class="keyword">False</span>) <span class="comment">#.cuda()</span></span><br><span class="line">                </span><br><span class="line">                response = autograd.Variable(torch.LongTensor(response_ids).view(<span class="number">-1</span>, <span class="number">1</span>), requires_grad = <span class="keyword">False</span>) <span class="comment">#.cuda()</span></span><br><span class="line">                                </span><br><span class="line">                label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(<span class="number">1</span>,<span class="number">1</span>))), requires_grad = <span class="keyword">False</span>) <span class="comment">#.cuda()</span></span><br><span class="line">                             </span><br><span class="line">                score = dual_encoder(context, response)</span><br><span class="line">        </span><br><span class="line">                loss = loss_func(score, label)</span><br><span class="line">                </span><br><span class="line">                sum_loss_training += loss.data[<span class="number">0</span>]</span><br><span class="line">                </span><br><span class="line">                loss.backward()</span><br><span class="line">        </span><br><span class="line">                optimizer.step()</span><br><span class="line">               </span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                </span><br><span class="line">                training_correct_count = increase_count(training_correct_count, score, label)</span><br><span class="line">                                                    </span><br><span class="line">            training_accuracy = get_accuracy(training_correct_count, training_dataframe)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#plt.plot(epoch, training_accuracy)</span></span><br><span class="line">                </span><br><span class="line">            shuffle_dataframe(validation_dataframe)</span><br><span class="line">            </span><br><span class="line">            validation_correct_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            sum_loss_validation = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">            dual_encoder.eval()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> index, row <span class="keyword">in</span> validation_dataframe.iterrows():</span><br><span class="line">                </span><br><span class="line">                context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)</span><br><span class="line">                </span><br><span class="line">                context = autograd.Variable(torch.LongTensor(context_ids).view(<span class="number">-1</span>,<span class="number">1</span>)) <span class="comment">#.cuda()</span></span><br><span class="line">                </span><br><span class="line">                response = autograd.Variable(torch.LongTensor(response_ids).view(<span class="number">-1</span>, <span class="number">1</span>)) <span class="comment">#.cuda()</span></span><br><span class="line">                                </span><br><span class="line">                label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(<span class="number">1</span>,<span class="number">1</span>)))) <span class="comment">#.cuda()</span></span><br><span class="line">                </span><br><span class="line">                score = dual_encoder(context, response)</span><br><span class="line">                </span><br><span class="line">                loss = loss_func(score, label)</span><br><span class="line">                </span><br><span class="line">                sum_loss_validation += loss.data[<span class="number">0</span>]</span><br><span class="line">                </span><br><span class="line">                validation_correct_count = increase_count(validation_correct_count, score, label)</span><br><span class="line">                    </span><br><span class="line">            validation_accuracy = get_accuracy(validation_correct_count, validation_dataframe)</span><br><span class="line">                        </span><br><span class="line">            print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], </span><br><span class="line">                  <span class="string">"Epoch: %d/%d"</span> %(epoch,epochs),  </span><br><span class="line">                  <span class="string">"TrainLoss: %.3f"</span> %(sum_loss_training/len(training_dataframe)), </span><br><span class="line">                  <span class="string">"TrainAccuracy: %.3f"</span> %(training_accuracy), </span><br><span class="line">                  <span class="string">"ValLoss: %.3f"</span> %(sum_loss_validation/len(validation_dataframe)), </span><br><span class="line">                  <span class="string">"ValAccuracy: %.3f"</span> %(validation_accuracy))</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> validation_accuracy &gt; best_validation_accuracy:</span><br><span class="line">                best_validation_accuracy = validation_accuracy</span><br><span class="line">                torch.save(dual_encoder.state_dict(), <span class="string">'saved_model_%d_examples.pt'</span> %(len(training_dataframe)))</span><br><span class="line">                print(<span class="string">"New best found and saved."</span>)</span><br><span class="line">                </span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Training and validation epochs finished."</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">training_dataframe, vocab, word_to_id, id_to_vec, emb_dim, validation_dataframe = creating_variables(num_training_examples = <span class="number">10000</span>, </span><br><span class="line">                                                                                                     embedding_dim = <span class="number">50</span>, </span><br><span class="line">                                                                                                     num_validation_examples = <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<p><strong>è®¾å®šhidden sizeå’Œdropoutæ¦‚ç‡ï¼Œæ„å»ºæ¨¡å‹</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">encoder, dual_encoder = creating_model(hidden_size = <span class="number">50</span>, </span><br><span class="line">                                       p_dropout = <span class="number">0.85</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#encoder.cuda()</span></span><br><span class="line"><span class="comment">#dual_encoder.cuda</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> dual_encoder.named_parameters():</span><br><span class="line">    <span class="keyword">if</span> param.requires_grad:</span><br><span class="line">        print(name)</span><br></pre></td></tr></table></figure>
<p><strong>è®¾å®šå­¦ä¹ ç‡ï¼Œè¿­ä»£è½®æ•°ï¼Œl2æ­£åˆ™åŒ–å¼ºåº¦ï¼Œå¼€å§‹è®­ç»ƒ</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_model(learning_rate = <span class="number">0.0001</span>, </span><br><span class="line">            l2_penalty = <span class="number">0.0001</span>,</span><br><span class="line">            epochs = <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p><strong>åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dual_encoder.load_state_dict(torch.load(<span class="string">'saved_model_10000_examples.pt'</span>))</span><br><span class="line"></span><br><span class="line">dual_encoder.eval()</span><br></pre></td></tr></table></figure>
<p><strong>ç¬¬1ç§æµ‹è¯•æ–¹å¼:</strong></p>
<p><em>æµ‹è¯•æ•°æ®é›†å’Œè®­ç»ƒè¿˜æœ‰éªŒè¯æ•°æ®é›†æœ‰ç€ä¸€æ ·çš„æ•°æ®ç»„ç»‡æ ¼å¼ (context, response, label)</em></p>
<p><em>æµ‹è¯•è¯„åˆ¤æŒ‡æ ‡ï¼šå‡†ç¡®ç‡</em></p>
<p>Loading data:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_dataframe_same_structure = pd.read_csv(<span class="string">'testing_same_structure_1000.csv'</span>)</span><br></pre></td></tr></table></figure>
<p>æ„å»ºæµ‹è¯•å‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testing_same_structure</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    test_correct_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> test_dataframe_same_structure.iterrows():</span><br><span class="line"></span><br><span class="line">        context_ids, response_ids, label = load_ids_and_labels(row, word_to_id)</span><br><span class="line"></span><br><span class="line">        context = autograd.Variable(torch.LongTensor(context_ids).view(<span class="number">-1</span>,<span class="number">1</span>)) <span class="comment">#.cuda()</span></span><br><span class="line"></span><br><span class="line">        response = autograd.Variable(torch.LongTensor(response_ids).view(<span class="number">-1</span>, <span class="number">1</span>)) <span class="comment">#.cuda()</span></span><br><span class="line"></span><br><span class="line">        label = autograd.Variable(torch.FloatTensor(torch.from_numpy(np.array(label).reshape(<span class="number">1</span>,<span class="number">1</span>)))) <span class="comment">#.cuda()</span></span><br><span class="line"></span><br><span class="line">        score = dual_encoder(context, response)</span><br><span class="line"></span><br><span class="line">        test_correct_count = increase_count(test_correct_count, score, label)</span><br><span class="line"></span><br><span class="line">    test_accuracy = get_accuracy(test_correct_count, test_dataframe_same_structure)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> test_accuracy</span><br></pre></td></tr></table></figure>
<p>å‡†ç¡®ç‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_accuracy = testing_same_structure()</span><br><span class="line">print(<span class="string">"Test accuracy for %d training examples and %d test examples: %.2f"</span> %(len(training_dataframe),len(test_dataframe_same_structure),test_accuracy))</span><br></pre></td></tr></table></figure>
<p><strong>ç¬¬2ç§æµ‹è¯•æ–¹å¼</strong></p>
<p><em>æµ‹è¯•æ•°æ®é›†å’Œè®­ç»ƒ/éªŒè¯é›†æ ¼å¼ä¸ä¸€æ · (1ä¸ªé—®é¢˜ï¼Œ1ä¸ªæ ‡å‡†ç­”æ¡ˆï¼Œ9ä¸ªå¹²æ‰°é¡¹é”™è¯¯ç­”æ¡ˆ)</em></p>
<p><em>æµ‹è¯•è¯„ä¼°æŒ‡æ ‡ï¼šrecall(å¬å›)</em></p>
<p>åŠ è½½æ•°æ®</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_dataframe_different_structure = pd.read_csv(<span class="string">'testing_different_structure_100.csv'</span>)</span><br></pre></td></tr></table></figure>
<p>ä»¥å­—å…¸å½¢æ€å­˜å‚¨å¯¹è¯word ids</p>
<p><em>Outer dictionary â€œids_per_example_and_candidateâ€: keys = examples, values = inner dictionaries</em></p>
<p><em>Inner dictionaries â€œids_per_candidateâ€: keys = candidate names, values = list of word IDs</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_ids</span><span class="params">(test_dataframe_different_structure, word_to_id)</span>:</span></span><br><span class="line">    </span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Loading test IDs..."</span>)</span><br><span class="line"></span><br><span class="line">    max_context_len = <span class="number">160</span></span><br><span class="line">    </span><br><span class="line">    ids_per_example_and_candidate = &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, example <span class="keyword">in</span> test_dataframe_different_structure.iterrows():</span><br><span class="line">        </span><br><span class="line">        ids_per_candidate = &#123;&#125;</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">for</span> column_name, cell <span class="keyword">in</span>  example.iteritems():</span><br><span class="line">            </span><br><span class="line">                id_list = []</span><br><span class="line">            </span><br><span class="line">                words = str(cell).split()</span><br><span class="line">                <span class="keyword">if</span> len(words) &gt; max_context_len:</span><br><span class="line">                    words = words[:max_context_len]</span><br><span class="line">    </span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                    <span class="keyword">if</span> word <span class="keyword">in</span> word_to_id:</span><br><span class="line">                        id_list.append(word_to_id[word])</span><br><span class="line">                    <span class="keyword">else</span>: </span><br><span class="line">                        id_list.append(<span class="number">0</span>) <span class="comment">#UNK  </span></span><br><span class="line">                    </span><br><span class="line">                ids_per_candidate[column_name] = id_list</span><br><span class="line">    </span><br><span class="line">        ids_per_example_and_candidate[i] = ids_per_candidate</span><br><span class="line">    </span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Test IDs loaded."</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ids_per_example_and_candidate</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ids_per_example_and_candidate = load_ids(test_dataframe_different_structure, word_to_id)</span><br></pre></td></tr></table></figure>
<p>ä»¥å­—å…¸å½¢æ€å­˜å‚¨å¾—åˆ†score</p>
<p><em>Outer dictionary â€œscores_per_example_and_candidateâ€: keys = examples, values = inner dictionaries</em></p>
<p><em>Inner dictionaries â€œscores_per_candidateâ€: keys = candidate names, values = score</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_scores</span><span class="params">()</span>:</span> </span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Computing test scores..."</span>)</span><br><span class="line">    </span><br><span class="line">    scores_per_example_and_candidate = &#123;&#125;</span><br><span class="line">                 </span><br><span class="line">    <span class="keyword">for</span> example, utterance_ids_dict <span class="keyword">in</span> sorted(ids_per_example_and_candidate.items()): </span><br><span class="line">        </span><br><span class="line">        score_per_candidate = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> utterance_name, ids_list <span class="keyword">in</span> sorted(utterance_ids_dict.items()):</span><br><span class="line">        </span><br><span class="line">            context = autograd.Variable(torch.LongTensor(utterance_ids_dict[<span class="string">'Context'</span>]).view(<span class="number">-1</span>,<span class="number">1</span>))<span class="comment">#.cuda()</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> utterance_name != <span class="string">'Context'</span>:</span><br><span class="line"></span><br><span class="line">                candidate_response = autograd.Variable(torch.LongTensor(utterance_ids_dict[utterance_name]).view(<span class="number">-1</span>, <span class="number">1</span>))<span class="comment">#.cuda()</span></span><br><span class="line">                        </span><br><span class="line">                score = torch.sigmoid(dual_encoder(context, candidate_response))</span><br><span class="line">                </span><br><span class="line">                score_per_candidate[<span class="string">"Score with "</span> + utterance_name] = score.data[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">        scores_per_example_and_candidate[example] = score_per_candidate</span><br><span class="line"></span><br><span class="line">    print(str(datetime.datetime.now()).split(<span class="string">'.'</span>)[<span class="number">0</span>], <span class="string">"Test scores computed."</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> scores_per_example_and_candidate</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores_per_example_and_candidate = load_scores()</span><br></pre></td></tr></table></figure>
<p>å®šä¹‰è®¡ç®—å¬å›ç»“æœçš„æ–¹æ³•ï¼š </p>
<p>è¿™é‡Œè®¡ç®—çš„æ˜¯recall@kè¿™ä¸ªè¯„ä¼°æŒ‡æ ‡ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_recall_at_k</span><span class="params">(k)</span>:</span></span><br><span class="line">    count_true_hits = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> example, score_per_candidate_dict <span class="keyword">in</span> sorted(scores_per_example_and_candidate.items()): </span><br><span class="line">    </span><br><span class="line">        top_k = dict(sorted(score_per_candidate_dict.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)[:k])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">'Score with Ground Truth Utterance'</span> <span class="keyword">in</span> top_k:</span><br><span class="line">            count_true_hits += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    number_of_examples = len(scores_per_example_and_candidate)</span><br><span class="line">    </span><br><span class="line">    recall_at_k = count_true_hits/number_of_examples</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> recall_at_k</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"recall_at_5 ="</span>,get_recall_at_k(k = <span class="number">5</span>)) <span class="comment">#Baseline expectation: 5/10 = 0.5 for random guess</span></span><br><span class="line">print(<span class="string">"recall_at_2 ="</span>,get_recall_at_k(k = <span class="number">2</span>)) <span class="comment">#Baseline expectation: 2/10 = 0.2 for random guess</span></span><br><span class="line">print(<span class="string">"recall_at_1 ="</span>,get_recall_at_k(k = <span class="number">1</span>)) <span class="comment">#Baseline expectation: 1/10 = 0.1 for random guess</span></span><br></pre></td></tr></table></figure>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/nlp/" rel="tag"># nlp</a>
                    </li>
                    
                    <li>
                        <a href="/tags/è‡ªç„¶è¯­è¨€å¤„ç†/" rel="tag"># è‡ªç„¶è¯­è¨€å¤„ç†</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="NLPç³»åˆ—" href="/2019-03-21/nlp/8Machine_Translation/1.Statistical_machine_translation/Statistical_machine_translation/">
            â† NLPç³»åˆ—
        </a>
        
        <span class="prev-next-post">Â·</span>
        
        <a class="next-post" title="NLPç³»åˆ—" href="/2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/1.chatbot_retrieval_based_tensorflow/">
            NLPç³»åˆ— â†’
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#æ„å»ºäºUbuntuå¯¹è¯æ•°æ®é›†ä¸Šçš„åŸºäºæ£€ç´¢çš„èŠå¤©æœºå™¨äºº"><span class="toc-text">æ„å»ºäºUbuntuå¯¹è¯æ•°æ®é›†ä¸Šçš„åŸºäºæ£€ç´¢çš„èŠå¤©æœºå™¨äºº</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#å®šä¹‰helperå‡½æ•°ä»¥æ„å»ºè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­çš„å˜é‡"><span class="toc-text">å®šä¹‰helperå‡½æ•°ä»¥æ„å»ºè®­ç»ƒå’ŒéªŒè¯è¿‡ç¨‹ä¸­çš„å˜é‡</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#æ¨¡å‹å®šä¹‰"><span class="toc-text">æ¨¡å‹å®šä¹‰</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#æ•°æ®ä¸å˜é‡æ„å»º"><span class="toc-text">æ•°æ®ä¸å˜é‡æ„å»º</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#æ¨¡å‹æ„å»º"><span class="toc-text">æ¨¡å‹æ„å»º</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#æ¨¡å‹è®­ç»ƒ"><span class="toc-text">æ¨¡å‹è®­ç»ƒ</span></a></li></ol></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Pastor Dean &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020-01-16/thinking/Thinking modelBiological thinking Biological thinking looking at the business world from an evolutionary perspective/">Thinking modelBiological thinking Biological thinking: looking at the business world from an evolutionary perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-13/thinking/Modern Darwin Integrated Model  Biological Thinking Mode Opening God Perspective/">Modern Darwin Integrated Model Biological Thinking Mode Opening God is Perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-11/thinking/Metacognition Changing the stubborn thinking of the brain/">Metacognition Changing the stubborn thinking of the brain</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  â†’ </a>
  </footer>
</article>

            
            
            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/images/favicon-16x16-next.png" alt="Pastor Dean">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Pastor Dean">Pastor Dean &copy; 2020</a>
			
				
			        <span hidden="true" id="/2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/2.chatbot_retrieval_based_pytorch/" class="leancloud-visitors" data-flag-title="NLPç³»åˆ—">
			            <span>é˜…è¯»é‡ </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>


<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>



<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





</body>
</html>
