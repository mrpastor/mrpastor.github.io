<!DOCTYPE html>
<html lang="en">







<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>NLP系列 | Pastor Dean</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="pastor">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/images/favicon-16x16-next.png">
	<link rel="apple-touch-icon" href="/images/favicon-16x16-next.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Pastor Dean">
	<meta property="og:type" content="article">
	<meta property="og:title" content="NLP系列 | Pastor Dean">
	<meta property="og:description" content>
	<meta property="og:url" content="https://mrpastor.github.io/2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/1.chatbot_retrieval_based_tensorflow/">

	
	<meta property="article:published_time" content="2019-03-21T19:03:00+08:00"> 
	<meta property="article:author" content="pastor">
	<meta property="article:published_first" content="Pastor Dean, /2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/1.chatbot_retrieval_based_tensorflow/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Pastor Dean">
                    <img src="/images/favicon-32x32-next.png" alt="Pastor Dean">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/ || home" title="home">home</a>
            </li>
            
            <li>
                <a href="/categories/ || th" title="categories">categories</a>
            </li>
            
            <li>
                <a href="/archives/ || archive" title="archives">archives</a>
            </li>
            
            <li>
                <a href="/tools/ || tools" title="tools">tools</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/mrpastor" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2019-03-21T11:19:18.000Z">
                    2019-03-21
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/NLP/">NLP</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">NLP系列</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h1 id="基于内容检索式的聊天机器人"><a href="#基于内容检索式的聊天机器人" class="headerlink" title="基于内容检索式的聊天机器人"></a>基于内容检索式的聊天机器人</h1><p><strong>提示：如果大家觉得计算资源有限，欢迎大家在”科学上网“后免费试用<a href="https://colab.research.google.com" target="_blank" rel="noopener">google的colab</a>，有免费的K80 GPU供大家使用，大家只需要把课程的notebook上传即可运行</strong></p>
<p><img alt class="post-img b-lazy" data-img="./img/retrieval_chatbot.png" data-index="0" data-src="./img/retrieval_chatbot.png"></p>
<p>以下内容会介绍到基于检索的聊天机器人原理，并实现一个基于检索的模型，使用了双层Decoder的LSTM模型，通过这个模型可以实现聊天机器人。</p>
<p>本部分英文原文见<a href="http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/" target="_blank" rel="noopener">deep-learning-for-chatbots-2-retrieval-based-model-tensorflow</a>，本文涉及到的数据和代码见<a href="https://github.com/dennybritz/chatbot-retrieval/" target="_blank" rel="noopener">Github仓库地址</a>。</p>
<hr>
<h2 id="基于检索模型的聊天机器人"><a href="#基于检索模型的聊天机器人" class="headerlink" title="基于检索模型的聊天机器人"></a>基于检索模型的聊天机器人</h2><p>本文我们将介绍和实现一个基于检索模型的聊天机器人。检索模型所使用的回复数据通常是<strong>预先存储且知道（或定义）的数据</strong>，而不像生成式模型那样可以创造出崭新的、未知的回复内容（模型没有见过）。准确来讲，检索式模型的输入是<strong>一段上下文内容 C (会话到目前未知的内容信息)</strong> 和<strong>一个可能作为回复的候选答案</strong>；模型的输出是对这个候选答案的打分。寻找最合适的回复内容的过程是：先对一堆候选答案进行打分及排序，最后选出分值最高的那个最为回复。</p>
<p>也许你会质疑为什么不直接使用生成式模型，生成式模型不需要预先存储且定义好的数据，比起检索模型更加的灵活多变。原因在于目前生成式模型的效果并不佳，由于生成式模型的约束条件少，过于多变的模型导致生成的response中出现一些语法错误和语义无关的内容。生成式模型需要海量的训练数据，且难以优化。目前工业界常用的模型还是基于检索的模型，或者以生成式模型作为补充的两者结合，谷歌的<a href="http://arxiv.org/abs/1606.04870" target="_blank" rel="noopener">Smart Reply</a>就是一个例子。尽管目前生成式模型是学术界的研究热点，但在实践中使用检索式模型是更加合适的选择。</p>
<h2 id="Ubuntu对话数据集"><a href="#Ubuntu对话数据集" class="headerlink" title="Ubuntu对话数据集"></a>Ubuntu对话数据集</h2><p>这篇博客我们将使用Ubuntu对话数据集（<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">论文来源</a> <a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="noopener">github地址</a>）。这个数据集（Ubuntu Dialog Corpus, UDC）是目前最大的公开对话数据集之一，它是来自Ubuntu的IRC网络上的对话日志。<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">这篇论文</a>介绍了该数据集生成的具体细节。下面简单介绍一下数据的格式。</p>
<p>训练数据有1,000,000条实例，其中一半是正例（label为1），一半是负例（label为0，负例为随机生成）。每条实例包括一段上下文信息（context），即Query；和一段可能的回复内容，即Response；Label为1表示该Response确实是Query的回复，Label为0则表示不是。下面是数据示例：</p>
<p><a href="http://i.imgur.com/tlKSbnT.png" target="_blank" rel="noopener"><img alt="img" class="post-img b-lazy" data-img="http://i.imgur.com/tlKSbnT.png" data-index="1" data-src="http://i.imgur.com/tlKSbnT.png"></a></p>
<p>数据集的生成使用了<a href="http://www.nltk.org/" target="_blank" rel="noopener">NLTK工具</a>，包括分词、stemmed、lemmatized等文本预处理步骤；同时还使用了NER技术，将文本中的实体，如姓名、地点、组织、URL等替换成特殊字符。这些文本预处理并不是必须的，但是能够提升一些模型的性能。据统计，query的平均长度为86个word，而response的平均长度为17个word，更多的数据统计信息见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/notebooks/Data%20Exploration.ipynb" target="_blank" rel="noopener">Jupyter notebook</a>。</p>
<p>数据集也包括了测试和验证集，但这两部分的数据和训练数据在格式上不太一样。在测试集和验证集中，对于每一条实例，有一个正例和九个负例数据（也称为干扰数据）。模型的目标在于给正例的得分尽可能的高，而给负例的得分尽可能的低。下面是数据示例：</p>
<p><a href="http://i.imgur.com/EoEK6vy.png" target="_blank" rel="noopener"><img alt="img" class="post-img b-lazy" data-img="http://i.imgur.com/EoEK6vy.png" data-index="2" data-src="http://i.imgur.com/EoEK6vy.png"></a></p>
<p>模型的评测方式有很多种。其中最常用到的是<strong>recall@k</strong>，即经模型对候选的response排序后，前k个候选中存在正例数据（正确的那个）的占比；显然k值越大，该指标会越高，因为这对模型性能的要求越松。</p>
<p>在Ubuntu数据集中，负例数据都是随机生成的；然而在现实中，想要从全部的数据中随机生成负例是不可能的。谷歌的Smart Reply则使用了<a href="http://arxiv.org/abs/1606.04870" target="_blank" rel="noopener">聚类技术</a>，然后将每个类的中取一些作为负例，这样生成负例的方式显得更加合理（考虑了负例数据的多样性，同时减少时间开销）。</p>
<h2 id="BASELINE"><a href="#BASELINE" class="headerlink" title="BASELINE"></a>BASELINE</h2><p>在使用NN模型之前，先设立一些简单的baseline模型，以方便后续的效果对比。使用如下的函数来计算<strong>recall@k</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_recall</span><span class="params">(y, y_test, k=<span class="number">1</span>)</span>:</span></span><br><span class="line">    num_examples = float(len(y))</span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> predictions, label <span class="keyword">in</span> zip(y, y_test):</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">in</span> predictions[:k]:</span><br><span class="line">            num_correct += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> num_correct/num_examples</span><br></pre></td></tr></table></figure>
<p>其中，<code>y</code>是所预测的以降序排列的模型预测分值，<code>y_test</code>是实际的label值。举个例子，假设<code>y</code>的值为[0,3,1,2,5,6,4,7,8,9]，这说明第0号的候选的预测分值最高、作为回复的可能性最高，而9号则最低。这里的第0号同时也是正确的那个，即正例数据，标号为1-9的为随机生成的负例数据。</p>
<p>理论上，最base的随机模型（Random Predictor）的recall@1的值为10%，recall@2的值为20%。相应的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Random Predictor</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_random</span><span class="params">(context, utterances)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.random.choice(len(utterances), <span class="number">10</span>, replace=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate Random predictor</span></span><br><span class="line">y_random = [predict_random(test_df.Context[x], test_df.iloc[x,<span class="number">1</span>:].values) <span class="keyword">for</span> x <span class="keyword">in</span> range(len(test_df))]</span><br><span class="line">y_test = np.zeros(len(y_random))</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:</span><br><span class="line">    print(<span class="string">"Recall @ (&#123;&#125;, 10): &#123;:g&#125;"</span>.format(n, evaluate_recall(y_random, y_test, n)))</span><br></pre></td></tr></table></figure>
<p>实际的模型结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Recall @ (<span class="number">1</span>, <span class="number">10</span>): <span class="number">0.0937632</span></span><br><span class="line">Recall @ (<span class="number">2</span>, <span class="number">10</span>): <span class="number">0.194503</span></span><br><span class="line">Recall @ (<span class="number">5</span>, <span class="number">10</span>): <span class="number">0.49297</span></span><br><span class="line">Recall @ (<span class="number">10</span>, <span class="number">10</span>): <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这与理论预期相符，但这不是我们所追求的结果。</p>
<p>另外一个baseline的模型为<strong>tfidf predictor</strong>。tfidf表示词频（term frequency）和逆文档词频（inverse document frequency），它衡量了一个词在一篇文档中的重要程度（基于整个语料库）。直观上，两篇文档对应的tfidf向量越接近，两篇文章的内容也越相似。同样的，对于一个QR pair，它们语义上接近的词共现的越多，也将越可能是一个正确的QR pair（<strong>这句话存疑，原因在于QR之间也有可能不存在语义上的相似，一个Q对应的R是多样的。</strong>）。tfidf predictor对应的代码如下（利用<a href="http://scikit-learn.org/" target="_blank" rel="noopener">scikit-learn工具</a>能够轻易实现）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TFIDFPredictor</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.vectorizer = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.vectorizer.fit(np.append(data.Context.values,data.Utterance.values))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, context, utterances)</span>:</span></span><br><span class="line">        <span class="comment"># Convert context and utterances into tfidf vector</span></span><br><span class="line">        vector_context = self.vectorizer.transform([context])</span><br><span class="line">        vector_doc = self.vectorizer.transform(utterances)</span><br><span class="line">        <span class="comment"># The dot product measures the similarity of the resulting vectors</span></span><br><span class="line">        result = np.dot(vector_doc, vector_context.T).todense()</span><br><span class="line">        result = np.asarray(result).flatten()</span><br><span class="line">        <span class="comment"># Sort by top results and return the indices in descending order</span></span><br><span class="line">        <span class="keyword">return</span> np.argsort(result, axis=<span class="number">0</span>)[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate TFIDF predictor</span></span><br><span class="line">pred = TFIDFPredictor()</span><br><span class="line">pred.train(train_df)</span><br><span class="line">y = [pred.predict(test_df.Context[x], test_df.iloc[x,<span class="number">1</span>:].values) <span class="keyword">for</span> x <span class="keyword">in</span> range(len(test_df))]</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:</span><br><span class="line">    print(<span class="string">"Recall @ (&#123;&#125;, 10): &#123;:g&#125;"</span>.format(n, evaluate_recall(y, y_test, n)))</span><br></pre></td></tr></table></figure>
<p>模型结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Recall @ (1, 10): 0.495032</span><br><span class="line">Recall @ (2, 10): 0.596882</span><br><span class="line">Recall @ (5, 10): 0.766121</span><br><span class="line">Recall @ (10, 10): 1</span><br></pre></td></tr></table></figure>
<p>显然这比Random的模型要好得多，但这还不够。之前的假设并不完美，首先query和response之间并不一定要是语义上的相近；其次tfidf模型忽略了词序这一重要的信息。使用NN模型我们能做得更好一些。</p>
<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>这篇博文将建立的NN模型为两层Encoder的LSTM模型（Dual Encoder LSTM Network），这种形式的网络被广泛应用在chatbot中（尽管可能效果并不是最佳的那个，你可以尽可能地尝试其他的NN模型）。<a href="https://www.tensorflow.org/versions/r0.9/tutorials/seq2seq/index.html" target="_blank" rel="noopener">seq2seq模型</a>常用于机器翻译领域，并取得了较大的效果。使用Dual LSTM模型的原因在于这个模型被证明在这个数据集有较好的效果（<a href="http://arxiv.org/abs/1510.03753" target="_blank" rel="noopener">详情见这里</a>）,这可以作为我们后续模型效果的验证。</p>
<p>两层Encoder的LSTM模型的结构图如下（<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="noopener">论文来源</a>）：</p>
<p><a href="http://i.imgur.com/qpFDJWM.png" target="_blank" rel="noopener"><img alt="img" class="post-img b-lazy" data-img="http://i.imgur.com/qpFDJWM.png" data-index="3" data-src="http://i.imgur.com/qpFDJWM.png"></a></p>
<p>大致的流程如下：</p>
<p>(1) Query和Response都是经过分词的，分词后每个词embedded为向量形式。初始的词向量使用<a href="http://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">GloVe vectors</a>，之后词向量随着模型的训练会进行fine-tuned（实验发现，初始的词向量使用GloVe并没有在性能上带来显著的提升）。</p>
<p>(2) 分词且向量化的Query和Response经过相同的RNN（word by word）。RNN最终生成一个向量表示，捕捉了Query和Response之间的[语义联系]（图中的c和r）；这个向量的维度是可以指定的，这里指定为256维。</p>
<p>(3) 将向量c与一个矩阵M相乘，来预测一个可能的回复r’。如果c为一个256维的向量，M维256*256的矩阵，两者相乘的结果为另一个256维的向量，我们可以将其解释为[一个生成式的回复向量]。矩阵M是需要训练的参数。</p>
<p>(4) 通过点乘的方式来预测生成的回复r’和候选的回复r之间的相似程度，点乘结果越大表示候选回复作为回复的可信度越高；之后通过sigmoid函数归一化，转成概率形式。图中把第(3)步和第(4)步结合在一起了。</p>
<p>为了训练模型，我们还需要一个损失函数（loss function）。这里使用二元的交叉熵（binary cross-entropy）作为损失函数。我们已知实例的真实label <code>y</code>，值为0或1；通过上面的第(4)步可以得到一个概率值 <code>y&#39;</code>；因此，交叉熵损失值为<code>L = -y * ln(y&#39;) - (1 - y) * ln(1 - y&#39;)</code>。这个公式的意义是直观的，即当<code>y=1</code>时，<code>L = -ln(y&#39;)</code>，我们期望<code>y&#39;</code>尽量地接近1使得损失函数的值越小；反之亦然。</p>
<p>实现过程中使用了<a href="http://www.numpy.org/" target="_blank" rel="noopener">numpy</a>、<a href="http://pandas.pydata.org/" target="_blank" rel="noopener">pandas</a>、<a href="http://www.tensorflow.org/" target="_blank" rel="noopener">TensorFlow</a>和<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn" target="_blank" rel="noopener">TF Learn</a>等工具。</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p><a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="noopener">数据集</a>的原始格式为csv格式，我们需要先将其转为<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto" target="_blank" rel="noopener">TensorFlow专有的格式</a>，这种格式的好处在于能够直接从输入文件中load tensors，并让TensorFlow来处理洗牌(shuffling)、批量(batching)和队列化(queuing)等操作。预处理中还包括创建一个字典库，将词进行标号，TFRecord文件将直接存储这些词的标号。</p>
<p>每个实例包括如下几个字段：</p>
<ul>
<li>Query：表示为一串词标号的序列，如[231, 2190, 737, 0, 912]；</li>
<li>Query的长度；</li>
<li>Response：同样是一串词标号的序列；</li>
<li>Response的长度；</li>
<li>Label；</li>
<li>Distractor_[N]：表示负例干扰数据，仅在验证集和测试集中有，N的取值为0-8；</li>
<li>Distractor_[N]的长度；</li>
</ul>
<p>数据预处理的Python脚本见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/scripts/prepare_data.py" target="_blank" rel="noopener">这里</a>，生成了3个文件：train.tfrecords, validation.tfrecords 和 test.tfrecords。你可以尝试自己运行程序，或者直接下载和使用<a href="https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM" target="_blank" rel="noopener">预处理后的数据</a>。</p>
<h3 id="创建输入函数"><a href="#创建输入函数" class="headerlink" title="创建输入函数"></a>创建输入函数</h3><p>为了使用TensoFlow内置的训练和评测模块，我们需要创建一个输入函数：这个函数返回输入数据的batch。因为训练数据和测试数据的格式不同，我们需要创建不同的输入函数。输入函数需要返回批量(batch)的特征和标签值(如果有的话)。类似于如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># TODO Load and preprocess data here</span></span><br><span class="line">  <span class="keyword">return</span> batched_features, labels</span><br></pre></td></tr></table></figure>
<p>因为我们需要在模型训练和评测过程中使用不同的输入函数，为了防止重复书写代码，我们创建一个包装器(wrapper)，名称为<code>create_input_fn</code>，针对不同的mode使用相应的code，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_input_fn</span><span class="params">(mode, input_files, batch_size, num_epochs=None)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># TODO Load and preprocess data here</span></span><br><span class="line">    <span class="keyword">return</span> batched_features, labels</span><br><span class="line">  <span class="keyword">return</span> input_fn</span><br></pre></td></tr></table></figure>
<p>完整的code见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_inputs.py" target="_blank" rel="noopener">udc_inputs.py</a>。整体上，这个函数做了如下的事情：</p>
<p>(1) 定义了示例文件中的feature字段；<br>(2) 使用<code>tf.TFRecordReader</code>来读取<code>input_files</code>中的数据；<br>(3) 根据feature字段的定义对数据进行解析；<br>(4) 提取训练数据的标签；<br>(5) 产生批量化的训练数据；<br>(6) 返回批量的特征数据及对应标签；</p>
<h3 id="定义评测指标"><a href="#定义评测指标" class="headerlink" title="定义评测指标"></a>定义评测指标</h3><p>之前已经提到用<code>recall@k</code>这个指标来评测模型，TensorFlow中已经实现了许多标准指标（包括<code>recall@k</code>）。为了使用这些指标，需要创建一个字典，key为指标名称，value为对应的计算函数。如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_evaluation_metrics</span><span class="params">()</span>:</span></span><br><span class="line">  eval_metrics = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:</span><br><span class="line">    eval_metrics[<span class="string">"recall_at_%d"</span> % k] = functools.partial(</span><br><span class="line">        tf.contrib.metrics.streaming_sparse_recall_at_k,</span><br><span class="line">        k=k)</span><br><span class="line">  <span class="keyword">return</span> eval_metrics</span><br></pre></td></tr></table></figure>
<p>如上，我们使用了<a href="https://docs.python.org/2/library/functools.html#functools.partial" target="_blank" rel="noopener">functools.partial</a>函数，这个函数的输入参数有两个。不要被<code>streaming_sparse_recall_at_k</code>所困惑，其中的<code>streaming</code>的含义是表示指标的计算是增量式的。</p>
<p>训练和测试所使用的评测方式是不一样的，训练过程中我们对每个case可能作为正确回复的概率进行预测，而测试过程中我们对每组数据（包含10个case，其中1个是正确的，另外9个是生成的负例/噪音数据）中的case进行逐条概率预测，得到例如<code>[0.34, 0.11, 0.22, 0.45, 0.01, 0.02, 0.03, 0.08, 0.33, 0.11]</code>这样格式的输出，这些输出值的和并不要求为1（因为是逐条预测的，有单独的预测概率值，在0到1之间）；而对于这组数据而言，因为<code>数据index=0</code>对应的为正确答案，这里<code>recall@1</code>为0，因为<code>0.34</code>是其中第二大的值，所以<code>recall@2</code>是1（表示这组数据中预测概率值在前二的中有一个是正确的）。</p>
<h3 id="训练程序样例"><a href="#训练程序样例" class="headerlink" title="训练程序样例"></a>训练程序样例</h3><p>首先，给一个模型训练和测试的程序样例，这之后你可以参照程序中所用到的标准函数，来快速切换和使用其他的网络模型。假设我们有一个函数<code>model_fn</code>，函数的输入参数有<code>batched features</code>，<code>label</code>和<code>mode(train/evaluation)</code>，函数的输出为预测值。程序样例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">estimator = tf.contrib.learn.Estimator(</span><br><span class="line">model_fn=model_fn,</span><br><span class="line">model_dir=MODEL_DIR,</span><br><span class="line">config=tf.contrib.learn.RunConfig())</span><br><span class="line"></span><br><span class="line">input_fn_train = udc_inputs.create_input_fn(</span><br><span class="line">mode=tf.contrib.learn.ModeKeys.TRAIN,</span><br><span class="line">input_files=[TRAIN_FILE],</span><br><span class="line">batch_size=hparams.batch_size)</span><br><span class="line"></span><br><span class="line">input_fn_eval = udc_inputs.create_input_fn(</span><br><span class="line">mode=tf.contrib.learn.ModeKeys.EVAL,</span><br><span class="line">input_files=[VALIDATION_FILE],</span><br><span class="line">batch_size=hparams.eval_batch_size,</span><br><span class="line">num_epochs=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">eval_metrics = udc_metrics.create_evaluation_metrics()</span><br><span class="line"></span><br><span class="line"><span class="comment"># We need to subclass theis manually for now. The next TF version will</span></span><br><span class="line"><span class="comment"># have support ValidationMonitors with metrics built-in.</span></span><br><span class="line"><span class="comment"># It's already on the master branch.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EvaluationMonitor</span><span class="params">(tf.contrib.learn.monitors.EveryN)</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">every_n_step_end</span><span class="params">(self, step, outputs)</span>:</span></span><br><span class="line">  self._estimator.evaluate(</span><br><span class="line">    input_fn=input_fn_eval,</span><br><span class="line">    metrics=eval_metrics,</span><br><span class="line">    steps=<span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">eval_monitor = EvaluationMonitor(every_n_steps=FLAGS.eval_every)</span><br><span class="line">estimator.fit(input_fn=input_fn_train, steps=<span class="keyword">None</span>, monitors=[eval_monitor])</span><br></pre></td></tr></table></figure>
<p>这里创建了一个<code>model_fn</code>的<code>estimator</code>(评估函数)；两个输入函数，<code>input_fn_train</code>和<code>input_fn_eval</code>，以及计算评测指标的函数；</p>
<h3 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h3><p>到目前为止，我们创建了模型的输入、解析、评测和训练的样例程序。现在我们来写LSTM的程序，<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_model.py" target="_blank" rel="noopener">create_model_fn</a>函数用以处理不同格式的训练和测试数据；它的输入参数为<code>model_impl</code>，这个函数表示实际作出预测的模型，这里就是用的LSTM，当然你可以替换成任意的其他模型。程序如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dual_encoder_model</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    hparams,</span></span></span><br><span class="line"><span class="function"><span class="params">    mode,</span></span></span><br><span class="line"><span class="function"><span class="params">    context,</span></span></span><br><span class="line"><span class="function"><span class="params">    context_len,</span></span></span><br><span class="line"><span class="function"><span class="params">    utterance,</span></span></span><br><span class="line"><span class="function"><span class="params">    utterance_len,</span></span></span><br><span class="line"><span class="function"><span class="params">    targets)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Initialize embedidngs randomly or with pre-trained vectors if available</span></span><br><span class="line">  embeddings_W = get_embeddings(hparams)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Embed the context and the utterance</span></span><br><span class="line">  context_embedded = tf.nn.embedding_lookup(</span><br><span class="line">      embeddings_W, context, name=<span class="string">"embed_context"</span>)</span><br><span class="line">  utterance_embedded = tf.nn.embedding_lookup(</span><br><span class="line">      embeddings_W, utterance, name=<span class="string">"embed_utterance"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Build the RNN</span></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">"rnn"</span>) <span class="keyword">as</span> vs:</span><br><span class="line">    <span class="comment"># We use an LSTM Cell</span></span><br><span class="line">    cell = tf.nn.rnn_cell.LSTMCell(</span><br><span class="line">        hparams.rnn_dim,</span><br><span class="line">        forget_bias=<span class="number">2.0</span>,</span><br><span class="line">        use_peepholes=<span class="keyword">True</span>,</span><br><span class="line">        state_is_tuple=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run the utterance and context through the RNN</span></span><br><span class="line">    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(</span><br><span class="line">        cell,</span><br><span class="line">        tf.concat(<span class="number">0</span>, [context_embedded, utterance_embedded]),</span><br><span class="line">        sequence_length=tf.concat(<span class="number">0</span>, [context_len, utterance_len]),</span><br><span class="line">        dtype=tf.float32)</span><br><span class="line">    encoding_context, encoding_utterance = tf.split(<span class="number">0</span>, <span class="number">2</span>, rnn_states.h)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> tf.variable_scope(<span class="string">"prediction"</span>) <span class="keyword">as</span> vs:</span><br><span class="line">    M = tf.get_variable(<span class="string">"M"</span>,</span><br><span class="line">      shape=[hparams.rnn_dim, hparams.rnn_dim],</span><br><span class="line">      initializer=tf.truncated_normal_initializer())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># "Predict" a  response: c * M</span></span><br><span class="line">    generated_response = tf.matmul(encoding_context, M)</span><br><span class="line">    generated_response = tf.expand_dims(generated_response, <span class="number">2</span>)</span><br><span class="line">    encoding_utterance = tf.expand_dims(encoding_utterance, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dot product between generated response and actual response</span></span><br><span class="line">    <span class="comment"># (c * M) * r</span></span><br><span class="line">    logits = tf.batch_matmul(generated_response, encoding_utterance, <span class="keyword">True</span>)</span><br><span class="line">    logits = tf.squeeze(logits, [<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Apply sigmoid to convert logits to probabilities</span></span><br><span class="line">    probs = tf.sigmoid(logits)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate the binary cross-entropy loss</span></span><br><span class="line">    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits, tf.to_float(targets))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Mean loss across the batch of examples</span></span><br><span class="line">  mean_loss = tf.reduce_mean(losses, name=<span class="string">"mean_loss"</span>)</span><br><span class="line">  <span class="keyword">return</span> probs, mean_loss</span><br></pre></td></tr></table></figure>
<p>完整的程序见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/models/dual_encoder.py" target="_blank" rel="noopener">dual_encoder.py</a>。基于这个，我们能够实例化model函数在我们之前定义的<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_train.py" target="_blank" rel="noopener">udc_train.py</a>，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_fn = udc_model.create_model_fn(</span><br><span class="line">  hparams=hparams,</span><br><span class="line">  model_impl=dual_encoder_model)</span><br></pre></td></tr></table></figure>
<p>这样我们就可以直接运行<code>udc_train.py</code>文件，来开始模型的训练和评测了，你可以设定<code>--eval_every</code>参数来控制模型在验证集上的评测频率。更多的命令行参数信息可见<code>tf.flags</code>和<code>hparams</code>，你也可以运行<code>python udc_train.py --help</code>来查看。</p>
<p>运行程序的效果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INFO:tensorflow:training step 20200, loss = 0.36895 (0.330 sec/batch).</span><br><span class="line">INFO:tensorflow:Step 20201: mean_loss:0 = 0.385877</span><br><span class="line">INFO:tensorflow:training step 20300, loss = 0.25251 (0.338 sec/batch).</span><br><span class="line">INFO:tensorflow:Step 20301: mean_loss:0 = 0.405653</span><br><span class="line">...</span><br><span class="line">INFO:tensorflow:Results after 270 steps (0.248 sec/batch): recall_at_1 = 0.507581018519, recall_at_2 = 0.689699074074, recall_at_5 = 0.913020833333, recall_at_10 = 1.0, loss = 0.5383</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h3 id="模型的评测"><a href="#模型的评测" class="headerlink" title="模型的评测"></a>模型的评测</h3><p>在训练完模型后，你可以将其应用在测试集上，使用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python udc_test.py --model_dir=$MODEL_DIR_FROM_TRAINING</span><br></pre></td></tr></table></figure>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python udc_test.py --model_dir=~/github/chatbot-retrieval/runs/1467389151</span><br></pre></td></tr></table></figure>
<p>这将得到模型在测试集上的<code>recall@k</code>的结果，注意在使用<code>udc_test.py</code>文件时，需要使用与训练时相同的参数。</p>
<p>在训练模型的次数大约2w次时(在GPU上大约花费1小时)，模型在测试集上得到如下的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">recall_at_1 = 0.507581018519</span><br><span class="line">recall_at_2 = 0.689699074074</span><br><span class="line">recall_at_5 = 0.913020833333</span><br></pre></td></tr></table></figure>
<p>其中，<code>recall@1</code>的值与tfidf模型的差不多，但是<code>recall@2</code>和<code>recall@5</code>的值则比tfidf模型的结果好太多。原论文中的结果依次是0.55,0.72和0.92，可能通过模型调参或者预处理能够达到这个结果。</p>
<h3 id="使用模型进行预测"><a href="#使用模型进行预测" class="headerlink" title="使用模型进行预测"></a>使用模型进行预测</h3><p>对于新的数据，你可以使用<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_predict.py" target="_blank" rel="noopener">udc_predict.py</a>来进行预测；例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python udc_predict.py --model_dir=./runs/1467576365/</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Context: Example context</span><br><span class="line">Response 1: 0.44806</span><br><span class="line">Response 2: 0.481638</span><br></pre></td></tr></table></figure>
<p>你可以从候选的回复中，选择预测分值最高的那个作为回复。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上，我们实现了一个基于检索的NN模型，它能够对候选的回复进行预测和打分，通过输出分值最高（或者满足一定阈值）的候选回复已完成聊天的过程。后续可以尝试其他更好的模型，或者通过调参来取得更好的实验结果。</p>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/nlp/" rel="tag"># nlp</a>
                    </li>
                    
                    <li>
                        <a href="/tags/自然语言处理/" rel="tag"># 自然语言处理</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="NLP系列" href="/2019-03-21/nlp/6seq2seq_v2/3.seq2seq_application_step_by_step/">
            ← NLP系列
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="NLP系列" href="/2019-03-21/nlp/8Machine_Translation/3.Facebook_Machine_Translation_Model_based_on_CNN/Facebook_Machine_Translation_Model_based_on_CNN/">
            NLP系列 →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#基于内容检索式的聊天机器人"><span class="toc-text">基于内容检索式的聊天机器人</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#基于检索模型的聊天机器人"><span class="toc-text">基于检索模型的聊天机器人</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ubuntu对话数据集"><span class="toc-text">Ubuntu对话数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BASELINE"><span class="toc-text">BASELINE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM"><span class="toc-text">LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据预处理"><span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#创建输入函数"><span class="toc-text">创建输入函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#定义评测指标"><span class="toc-text">定义评测指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练程序样例"><span class="toc-text">训练程序样例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#创建模型"><span class="toc-text">创建模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型的评测"><span class="toc-text">模型的评测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用模型进行预测"><span class="toc-text">使用模型进行预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol></li></ol></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Pastor Dean &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020-01-16/thinking/Thinking modelBiological thinking Biological thinking looking at the business world from an evolutionary perspective/">Thinking modelBiological thinking Biological thinking: looking at the business world from an evolutionary perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-13/thinking/Modern Darwin Integrated Model  Biological Thinking Mode Opening God Perspective/">Modern Darwin Integrated Model Biological Thinking Mode Opening God is Perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-11/thinking/Metacognition Changing the stubborn thinking of the brain/">Metacognition Changing the stubborn thinking of the brain</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">Categories</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Biological-Thinking/">Biological Thinking</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cognitive-Neuroscience/">Cognitive Neuroscience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FFmpeg/">FFmpeg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MacOS/">MacOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PM/">PM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/RPC/">RPC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ubuntu/">Ubuntu</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Vim/">Vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/WebRTC/">WebRTC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deeplearn/">deeplearn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/http/">http</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machineLearning/">machineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/文摘/">文摘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构师/">架构师</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/知识图谱/">知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/">职业规划</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/个人提升/">个人提升</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机基础/">计算机基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机相关技术资料整理/">计算机相关技术资料整理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/认知升级/">认知升级</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财务自由/">财务自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财富自由/">财富自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">Tag Cloud</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/AI/" style="font-size: 14px;">AI</a> <a href="/tags/Android/" style="font-size: 14px;">Android</a> <a href="/tags/Biological/" style="font-size: 17.75px;">Biological</a> <a href="/tags/Browser/" style="font-size: 14px;">Browser</a> <a href="/tags/Business/" style="font-size: 16.5px;">Business</a> <a href="/tags/Cognitive/" style="font-size: 17.75px;">Cognitive</a> <a href="/tags/DeepLearning/" style="font-size: 15.25px;">DeepLearning</a> <a href="/tags/Docker/" style="font-size: 14px;">Docker</a> <a href="/tags/FFmpeg/" style="font-size: 21.5px;">FFmpeg</a> <a href="/tags/FastCGI/" style="font-size: 14px;">FastCGI</a> <a href="/tags/IP划分/" style="font-size: 14px;">IP划分</a> <a href="/tags/IP地址/" style="font-size: 14px;">IP地址</a> <a href="/tags/Knowledge-Graph/" style="font-size: 16.5px;">Knowledge Graph</a> <a href="/tags/Linux-Shell/" style="font-size: 14px;">Linux Shell</a> <a href="/tags/MacOS/" style="font-size: 15.25px;">MacOS</a> <a href="/tags/Neuroscience/" style="font-size: 17.75px;">Neuroscience</a> <a href="/tags/RPC/" style="font-size: 14px;">RPC</a> <a href="/tags/Thinking/" style="font-size: 17.75px;">Thinking</a> <a href="/tags/Tutorial/" style="font-size: 20.25px;">Tutorial</a> <a href="/tags/WebRTC/" style="font-size: 21.5px;">WebRTC</a> <a href="/tags/WebSocket/" style="font-size: 14px;">WebSocket</a> <a href="/tags/algorithm/" style="font-size: 15.25px;">algorithm</a> <a href="/tags/config/" style="font-size: 14px;">config</a> <a href="/tags/decisionTree/" style="font-size: 14px;">decisionTree</a> <a href="/tags/git/" style="font-size: 17.75px;">git</a> <a href="/tags/google-adsense/" style="font-size: 14px;">google adsense</a> <a href="/tags/hexo/" style="font-size: 17.75px;">hexo</a> <a href="/tags/http/" style="font-size: 17.75px;">http</a> <a href="/tags/knn/" style="font-size: 14px;">knn</a> <a href="/tags/lighttpd/" style="font-size: 15.25px;">lighttpd</a> <a href="/tags/mxnet/" style="font-size: 14px;">mxnet</a> <a href="/tags/mysql/" style="font-size: 22.75px;">mysql</a> <a href="/tags/nlp/" style="font-size: 24px;">nlp</a> <a href="/tags/nodejs/" style="font-size: 14px;">nodejs</a> <a href="/tags/openvpn/" style="font-size: 14px;">openvpn</a> <a href="/tags/other/" style="font-size: 15.25px;">other</a> <a href="/tags/paddle/" style="font-size: 14px;">paddle</a> <a href="/tags/planning/" style="font-size: 20.25px;">planning</a> <a href="/tags/pracitce/" style="font-size: 15.25px;">pracitce</a> <a href="/tags/rich/" style="font-size: 14px;">rich</a> <a href="/tags/shell/" style="font-size: 14px;">shell</a> <a href="/tags/svn/" style="font-size: 14px;">svn</a> <a href="/tags/ubuntu/" style="font-size: 14px;">ubuntu</a> <a href="/tags/vim/" style="font-size: 16.5px;">vim</a> <a href="/tags/webpack/" style="font-size: 14px;">webpack</a> <a href="/tags/webrtc/" style="font-size: 19px;">webrtc</a> <a href="/tags/个人发展/" style="font-size: 14px;">个人发展</a> <a href="/tags/互联网实事/" style="font-size: 14px;">互联网实事</a> <a href="/tags/外链/" style="font-size: 14px;">外链</a> <a href="/tags/提升个人思维/" style="font-size: 14px;">提升个人思维</a> <a href="/tags/文摘/" style="font-size: 15.25px;">文摘</a> <a href="/tags/斜杠青年/" style="font-size: 14px;">斜杠青年</a> <a href="/tags/机器学习/" style="font-size: 16.5px;">机器学习</a> <a href="/tags/架构师/" style="font-size: 14px;">架构师</a> <a href="/tags/测试工具/" style="font-size: 14px;">测试工具</a> <a href="/tags/睡后成长/" style="font-size: 14px;">睡后成长</a> <a href="/tags/睡后收入/" style="font-size: 14px;">睡后收入</a> <a href="/tags/税后收入/" style="font-size: 14px;">税后收入</a> <a href="/tags/笔记/" style="font-size: 14px;">笔记</a> <a href="/tags/自然语言处理/" style="font-size: 24px;">自然语言处理</a> <a href="/tags/视频流/" style="font-size: 15.25px;">视频流</a> <a href="/tags/计算机相关技术资料整理/" style="font-size: 14px;">计算机相关技术资料整理</a> <a href="/tags/认知升级/" style="font-size: 14px;">认知升级</a> <a href="/tags/限速/" style="font-size: 14px;">限速</a> <a href="/tags/面试/" style="font-size: 14px;">面试</a> <a href="/tags/项目管理/" style="font-size: 14px;">项目管理</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/images/favicon-16x16-next.png" alt="Pastor Dean">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Pastor Dean">Pastor Dean &copy; 2020</a>
			
				
			        <span hidden="true" id="/2019-03-21/nlp/9chatbot_v2/1.retrieval_based_chatbot/1.chatbot_retrieval_based_tensorflow/" class="leancloud-visitors" data-flag-title="NLP系列">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>


<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>



<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





</body>
</html>
