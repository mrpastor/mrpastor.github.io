<!DOCTYPE html>
<html lang="en">







<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>NLP系列 | Pastor Dean</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="pastor">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="/images/favicon-16x16-next.png">
	<link rel="apple-touch-icon" href="/images/favicon-16x16-next.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	

	<meta property="og:site_name" content="Pastor Dean">
	<meta property="og:type" content="article">
	<meta property="og:title" content="NLP系列 | Pastor Dean">
	<meta property="og:description" content>
	<meta property="og:url" content="https://mrpastor.github.io/2019-03-21/nlp/1NLP_intro/1.language_model_calculation/">

	
	<meta property="article:published_time" content="2019-03-21T19:03:00+08:00"> 
	<meta property="article:author" content="pastor">
	<meta property="article:published_first" content="Pastor Dean, /2019-03-21/nlp/1NLP_intro/1.language_model_calculation/">
	

	
	
	<link rel="stylesheet" href="/css/allinonecss.min.css">

	
	
	
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                
                <a class="site-nav-logo" href="/" title="Pastor Dean">
                    <img src="/images/favicon-32x32-next.png" alt="Pastor Dean">
                </a>
                
                
            </li>
            
            
            <li>
                <a href="/ || home" title="home">home</a>
            </li>
            
            <li>
                <a href="/categories/ || th" title="categories">categories</a>
            </li>
            
            <li>
                <a href="/archives/ || archive" title="archives">archives</a>
            </li>
            
            <li>
                <a href="/tools/ || tools" title="tools">tools</a>
            </li>
            
            
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/mrpastor" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    <a class="social-link" title="facebook" href="https://facebook" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

    </a>
    
    
    <a class="social-link" title="twitter" href="https://twitter.com" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

    </a>
    
    
    
    
</div>
    </div>
</nav>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2019-03-21T11:19:18.000Z">
                    2019-03-21
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/NLP/">NLP</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">NLP系列</h1>
        </header>
        <div class="post-full no-image">
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h2 id="统计语言模型"><a href="#统计语言模型" class="headerlink" title="统计语言模型"></a>统计语言模型</h2><blockquote>
<p>以下内容摘自和修改自吴军《数学之美》</p>
</blockquote>
<p>自然语言从它产生开始，逐渐演变成一种上下文相关的信息表达和传递方式。因此让计算机处理自然语言，一个基本问题就是<strong>为自然语言这种上下文相关的特性建立数学模型</strong>，这个数学模型就是在自然语言处理中常说的<strong>统计语言模型(Statistical Language Model)</strong>。它是今天所有自然语言处理的基础，并且广泛应用于机器翻译、语音识别、印刷体或手写体识别、拼写纠错、汉字输入和文献查询。</p>
<h3 id="1-用数学的方法描述语言规律"><a href="#1-用数学的方法描述语言规律" class="headerlink" title="1. 用数学的方法描述语言规律"></a>1. 用数学的方法描述语言规律</h3><p>统计语言模型产生的初衷是为了解决语音识别问题。在语音识别中，计算机需要知道一个文字序列是否能构成一个大家理解并且有意义的句子，然后显示或打印给使用者。</p>
<p>比如：</p>
<blockquote>
<p>美联储主席本·伯南克昨天告诉媒体 7000 亿美元的救助资金将借给上百家银行、保险公司和汽车公司。</p>
</blockquote>
<p>这句话就很通顺，意义也很明白。</p>
<p>如果改变一些词的顺序，或者替换掉一些词，将这句话变成：</p>
<blockquote>
<p>本·伯南克美联储主席昨天 7000 亿美元的救助资金告诉媒体将借给银行、保险公司和汽车公司上百家。</p>
</blockquote>
<p>意思就含混了，虽然多少还能猜到一点。</p>
<p>但如果再换成：</p>
<blockquote>
<p>联主美储席本·伯诉体南将借天的救克告媒昨助资金 70 元亿 00 美给上百百百家银保行、汽车险公司公司和。</p>
</blockquote>
<p>基本上读者就不知所云了。</p>
<p>第一个句子合乎语法，词义清晰。第二个句子虽不合乎语法，但是词义还算清晰。而第三个句子则连词义都不清晰了。上世纪 70 年代以前，科学家们也是这样想的，他们试图判断这个文字序列是否合乎文法、含义是否正确等。但是语言的结构千变万化，要通过制定规则来覆盖所有的文法根本是不可能的。而弗里德里克·贾里尼克(Frederick Jelinek)换了一个角度，用一个简单的统计模型就很漂亮地搞定了这个问题。</p>
<h4 id="贾里尼克的想法"><a href="#贾里尼克的想法" class="headerlink" title="贾里尼克的想法"></a>贾里尼克的想法</h4><p>贾里尼克的出发点很简单：<strong>一个句子是否合理，就看它的可能性大小如何。</strong>上面的例子中，第一个句子出现的概率大致是$10^{−20}$，第二个句子出现的概率是 $10^{−25}$，第三个句子出现的概率是 $10^{−70}$。因此第一个句子出现的可能性最大，是第二个句子的 10万倍，是第三个句子的一百亿亿亿亿亿亿倍。</p>
<p>用更普遍而严格的描述是：</p>
<p>假定 SS 是一个有意义的句子，由一连串特定顺序排列的词 $w_1,w_2,⋯,w_n$组成，n为句子的长度。那么 S 在文本中出现的可能性就是 S 的概率 P(S)。于是可以把 P(S) 展开表示为：</p>
<p>$P(S)=P(w_1,w_2,⋯,w_n)$</p>
<p>利用条件概率公式，SS 这个序列出现的概率等于每一个词出现的条件概率相乘，于是：</p>
<p>$P(w_{1},w_{2},⋯,w_{n})=P(w_{1})⋅P(w_{2}∣w_{1})⋅P(w_{3}∣w_{1},w_{2})⋯P(w_{n}∣w_{1},w_{2},⋯,w_{n−1})P(w_{1},w_{2},⋯,w_{n})=P(w_{1})⋅P(w_{2}∣w_{1})⋅P(w_{3}∣w_{1},w_{2})⋯P(w_{n}∣w_{1},w_{2},⋯,w_{n−1})$</p>
<p>其中 $P(w_{1})$ 表示句子第一个词为 $w_1$ 的概率；$P(w_{2}∣w_{1})$ 是在已知第一个词的前提下，第二个词出现的概率；以此类推。不难看出，词 $w_n$ 的出现概率取决于它前面所有的词。</p>
<blockquote>
<p>$P(w_{1})$ 更准确的描述是 $P(w_{1}∣BOS)$ 即这个词在句子开头出现的概率。</p>
</blockquote>
<p>从计算上来看，第一个词的条件概率 $P(w_{1})$ 很容易算，第二个词的条件概率 $P(w_{2}∣w_{1})$ 也还不太麻烦，但是从第三个词的条件概率 $P(w_{3}∣w_{1},w_{2})$ 开始就非常难算了，因为它涉及到三个变量 $w_{1},w_{2},w_3$，而每个变量的可能性都是一种语言字典的大小。到了最后一个词 $w_n$，条件概率 $P(w_{n}∣w_{1},w_{2},⋯,w_{n−1})$ 的可能性太多，根本无法估算。</p>
<h4 id="二元模型与-N-元模型"><a href="#二元模型与-N-元模型" class="headerlink" title="二元模型与 N 元模型"></a>二元模型与 N 元模型</h4><p>从 19 世纪到 20 世纪初，俄国有个数学家叫马尔可夫(Andrey Markov)，他提出了一种偷懒但还颇为有效的方法：假设任意一个词语 wiwi 出现的概率只同它前面的词 wi−1 有关。于是问题就变得很简单了，这种假设在数学上称为马尔可夫假设。</p>
<blockquote>
<p>马尔可夫在 1906 年首先做出了这类过程，而将此一般化到可数无限状态空间是由柯尔莫果洛夫在 1936 年给出的。</p>
</blockquote>
<p>现在，S 出现的概率就变得简单了：</p>
<p>$P(S)=P(w_{1})⋅P(w_{2}∣w_{1})⋅P(w_{3}∣w_{2})⋯P(w_{i}∣w_{i−1})⋯P(w_{n}∣w_{n−1})$</p>
<p>上面的公式对应的统计语言模型是二元模型(Bigram Model)。当然，也可以假设一个词由前面的 N−1 个词决定，对应的模型稍微复杂些，被称为 N 元模型。</p>
<p>接下来的问题就是如何估计条件概率 $P(w_{i}∣w_{i−1})$。根据它的定义：</p>
<p>$P(w_{i}∣w_{i−1})=P(w_{i−1},w_{i})P(w_{i−1})P(w_{i}∣w_{i−1})=P(w_{i−1},w_{i})P(w_{i−1})$</p>
<p>而估计联合概率 $P(w_{i−1},w_{i})$ 和边缘概率 $P(w_{i−1})$ 是很简单的。根据大数定理，只要统计量足够，相对频度就等于概率，因而只需在语料库(Corpus)的文本中统计一下 $w_{i−1},w_i$ 这对词前后相邻出现了多少次 $N(w_{i−1},w_{i})$，以及 $w_{i−1}$ 出现了多少次 $N(w_{i−1})$，然后用两个数分别处以语料库的大小 N，即可得到这些词或者二元组的概率：</p>
<p>$$P(w_{i-1},w_i)=f(w_{i-1},w_i)=\frac{N(w_{i-1},w_i)}{N} \ P(w_{i-1})=f(w_{i-1})=\frac{N(w_{i-1})}{N}$$<br>$$P(w_{i-1},w_i)=f(w_{i-1},w_i)=\frac{N(w_{i-1},w_i)}{N} \ P(w_{i-1})=f(w_{i-1})=\frac{N(w_{i-1})}{N}$$</p>
<p>于是，</p>
<p>$$P(w_i\mid w_{i-1})\approx\frac{N(w_{i-1},w_i)}{N(w_{i-1})}$$</p>
<p>这似乎有点难以置信，用这么简单的数学模型就能解决复杂的语音识别、机器翻译等问题，而用很复杂的文法规则和人工智能却做不到。其实很多语言学家都曾质疑过这种方法的有效性，但事实证明，统计语言模型比任何已知的借助某种规则的解决方法更有效。</p>
<h3 id="2-高阶语言模型"><a href="#2-高阶语言模型" class="headerlink" title="2. 高阶语言模型"></a>2. 高阶语言模型</h3><p>在基于一阶马尔可夫假设的二元模型中，句子中每个词只和前面一个词有关，这似乎过于简化了，或者说近似地过头了。比如说在句子“美丽的花朵”中，“花朵”其实是和“美丽”有关，也就是说是与前面的第二个词有关。因此，更普遍的假设是某个词和前面的若干个词有关。</p>
<p>正如之前介绍的那样，N 元模型假设每个词 $w_i$ 和前面的 N−1 个词有关，而与更前面的词无关，这样词 $w_i$ 的概率只取决于前面的 N−1 个词 $w_{i−N+1},w_{i−N+2},⋯,w_{i−1}$。因此：</p>
<p>$$P(w_i\mid w_1,w_2,\cdots,w_{i-1})=P(w_i\mid w_{i-N+1},w_{i-N+2},\cdots,w_{i-1})$$</p>
<p>这种假设被称为 N−1 阶马尔可夫假设，对应的语言模型称为 N 元模型(N-Gram Model)。N=2时就是之前介绍的二元模型，而 N=1 的一元模型实际上是一个上下文无关模型，即假定当前词的出现概率与前面的词无关。在实际中应用最多的就是 N=3 的三元模型，更高阶的模型就很少使用了。</p>
<blockquote>
<p><strong>为什么 N 取值这么小？</strong></p>
<p>首先，N 元模型的大小（空间复杂度）几乎是 N 的指数函数，即 $O(|V|^N)$，这里 |V|是一种语言词典的词汇量，一般在几万到几十万个。其次，使用 N 元模型的速度（时间复杂度）也几乎是一个指数函数，即 $O(|V|^{N−1})$。因此，N 不能很大。</p>
<p>当 N 从 1 到 2，再从 2 到 3 时，模型的效果上升显著。而当模型从 3 到 4 时，效果的提升就不是很显著了，而资源的耗费却增加地非常快。所以，除非是为了做到极致不惜资源，很少有人会使用四元以上的模型。</p>
</blockquote>
<p>还有一个问题，三元、四元或更高阶的模型也并不能覆盖所有的语言现象。在自然语言处理中，上下文之间的相关性可能跨度非常大，甚至可以从一个段落跨到另一个段落。因此，即便再怎么提高模型的阶数，对这种情况也无可奈何，这就是马尔可夫模型的局限性，这是就需要采用其他一些长程的依赖性(Long Distance Dependency)来解决这个问题了。</p>
<h4 id="3-模型的训练、零概率问题和平滑方法"><a href="#3-模型的训练、零概率问题和平滑方法" class="headerlink" title="3. 模型的训练、零概率问题和平滑方法"></a>3. 模型的训练、零概率问题和平滑方法</h4><p>语言模型中所有的条件概率称为模型的参数，通过对语料的统计，得到这些参数的过程称为模型的训练。前面提到的二元模型训练方法似乎非常简单，只需计算一下 $w_{i−1},w_i$ 前后相邻出现的次数 $N(w_{i−1},w_{i})$ 和 $w_{i−1}$ 单独出现的次数 $N(w_{i−1})$ 的比值即可。但是如果同现的次数 $N(w_{i−1},w_{i})=0$ 怎么办，是否意味着条件概率 $P(w_{i}∣w_{i−1})=0$？反之，如果 $N(w_{i−1},w_{i})$ 和 $N(w_{i−1})$ 都只出现一次，能否得出 $P(w_{i}∣w_{i−1})=1$ 这样非常绝对的结论？</p>
<p>这就涉及到统计的可靠性问题了。在数理统计中，我们之所以敢用对采样数据进行观察的结果来预测概率，是因为有大数定理(Law of Large Number)在背后做支持，它的要求是有足够的观察值。但是在估计语言模型的概率时，很多人恰恰忘了这个道理，因此训练出来的语言模型“不管用”，然后回过头来怀疑这个方法是否有效。那么如何正确地训练一个语言模型呢？</p>
<p>一个直接的办法就是增加数据量，但是即使如此，仍会遇到零概率或者统计量不足的问题。假定要训练一个汉语的语言模型，汉语的词汇量大致是 20 万这个数量级，训练一个三元模型就有 $200,000^3=8×10^{15} $个不同参数。假设抓取 100 亿个有意义的中文网页，每个网页平均 1000 词，全部用作训练也依然只有 $10^{13}$。因此，如果用直接的比值计算概率，大部分条件概率依然是零，这种模型我们称之为“不平滑”。</p>
<p>训练统计语言模型的艺术就在于解决好统计样本不足时的概率估计问题。</p>
<h4 id="古德-图灵估计"><a href="#古德-图灵估计" class="headerlink" title="古德-图灵估计"></a>古德-图灵估计</h4><p>1953 年古德(I.J.Good)在他的老板图灵(Alan Turing)的指导下，提出了在统计中相信可靠的统计数据，而对不可信的统计数据打折扣的一种概率估计方法，同时将折扣出的那一小部分概率给予未看见的事件(Unseen Events)。古德和图灵还给出了一个很漂亮的重新估算概率的公式，这个公式后来被称为古德-图灵估计(Good-Turing Estimate)。</p>
<p>古德-图灵估计的原理是：对于没看见的事件，我们不能认为它发生的概率就是零，因此我们从概率的总量(Probability Mass)中，分配一个很小的比例给这些没有看见的事件。这样一来，看见了的事件的概率总和就小于 1了。因此，需要将所有看见了的事件概率调小一点，并且按照“越是不可信的统计折扣越多”的方法进行。</p>
<p>以统计词典中每个词的概率为例：假定在语料库中出现 r 次的词有 $N_r$ 个，特别地，未出现的词数量为 $N_0$。语料库的大小为 N。那么，很显然</p>
<p>$$N=\sum_{r=1}^{\infty}rN_r$$</p>
<p>出现 r 次的词在整个语料库中的相对频度(Relative Frequency)则是 $r/N$，如果不做任何优化处理，就以这个相对频度作为这些词的概率估计。现在假定当 r 比较小时，它的统计可能不可靠，因此在计算那些出现 r 次的词的概率时，要使用一个更小一点的次数，是 $d_r$（而不直接使用r），古德-图灵估计按照下面的公式计算$d_r$：</p>
<p>$$d_r = (r+1)\cdot N_{r+1}/N_r$$</p>
<p>显然</p>
<p>$$\sum_rd_r\cdot N_r=N$$</p>
<p>根据 $Zipf$ 定律，一般情况下 $N_{r+1}&lt;N_r$，因而 $d_r&lt;r$，而 $d_0&gt;0$。这样就给未出现的词赋予了一个很小的非零值，从而解决了零概率的问题。同时下调了出现频率很低的词的概率。实际运用中，一般只对出现次数低于某个阈值的词下调频率，然后把下调得到的频率总和给未出现的词。</p>
<blockquote>
<p>一般来说，出现一次的词的数量比出现两次的多，出现两次的比出现三次的多，这种规律称为 Zipf定律(Zipf’s Law)，即 r 越大，词的数量 $N_r$ 越小。</p>
</blockquote>
<p>这样出现 r 次的词的概率估计为$d_r/N$。于是，对于频率超过一定阈值的词，它们的概率估计就是它们在语料库中的相对频度，对于频率小于阈值的词，它们的概率估计就小于它们的相对频度，并且出现次数越少，折扣越多。对于未看见的词，也给与了一个比较小的概率。这样所有词的概率估计都很平滑了。</p>
<h4 id="卡茨退避法"><a href="#卡茨退避法" class="headerlink" title="卡茨退避法"></a>卡茨退避法</h4><p>对于二元组 $(w_{i−1},w_{i})(w_{i−1},w_{i})$ 的条件概率估计 $P(w_{i}∣w_{i−1})$也可以做同样的处理。我们知道，通过前一个词 $w_{i−1}$ 预测后一个词 $w_i$ 时，所有的可能情况的条件概率总和应该为 1，即</p>
<p>$$\sum_{w_i\in V}P(w_i\mid w_{i-1})=1$$</p>
<p>对于出现次数非常少的二元组 $(w_{i−1},w_{i})(w_{i−1},w_{i})$，需要按照古德-图灵的方法打折扣，这样 $\sum_{w_{i-1},w_i\text{ seen}}P(w_i\mid w_{i-1})\lt 1$，这意味着有一部分概率量没有分配出去，留给了没有看到的二元组 $(w_{i−1},w_{i})(w_{i−1},w_{i})$。基于这种思想，估计二元模型概率的公式为：</p>
<p>$$P(w_i\mid w_{i-1})=\begin{cases}f(w_i\mid w_{i-1})\quad\text{if }N(w_{i-1},w_i) \ge T \f_{gt}(w_i\mid w_{i-1})\quad\text{if }0\lt N(w_{i-1},w_i)\lt T \ Q(w_{i-1})\cdot f(w_i)\quad\text{otherwise}\end{cases}$$</p>
<p>其中 T 是阈值，一般在 8−10 左右，函数 $f_{gt}()$ 表示经过古德-图灵估计后的相对频度，而</p>
<p>$$Q(w_{i-1})=\frac{1-\sum_{w_i \text{ seen}}P(w_i\mid w_{i-1})}{\sum_{w_i\text{ unseen}}f(w_i)}$$</p>
<p>这样可以保证所有的可能情况的条件概率总和为 11。</p>
<p>这种平滑方法最早由前 IBM 科学家卡茨(S.M.Katz)提出，故称为卡茨退避法(Katz backoff)。类似地，对于三元模型，概率估计的公式如下：</p>
<p>$$P(w_i\mid w_{i-2},w_{i-1})=\begin{cases}f(w_i\mid w_{i-2},w_{i-1})\quad\text{if }N(w_{i-2,}w_{i-1},w_i) \ge T \f_{gt}(w_i\mid w_{i-2,}w_{i-1})\quad\text{if }0\lt N(w_{i-2},w_{i-1},w_i)\lt T \ Q(w_{i-2},w_{i-1})\cdot P(w_i\mid w_{i-1})\quad\text{otherwise}\end{cases}$$</p>
<p>对于一般情况的 N 元模型概率估计公式，以此类推。</p>
<blockquote>
<p>内伊(Herman Ney)等人在此基础上优化了卡茨退避法，原理大同小异。</p>
</blockquote>
<h4 id="线性插值"><a href="#线性插值" class="headerlink" title="线性插值"></a>线性插值</h4><p>因为一元组 $(w_{i})$ 出现的次数平均比二元组 $(w_{i−1},w_{i})$ 出现的次数要多很多，根据大数定律，它的相对频度更接近概率分布。类似地，二元组平均出现的次数比三元组要高，二元组的相对频度比三元组更接近概率分布。同时，低阶模型的零概率问题也比高阶模型轻微。因此，用低阶语言模型和高阶模型进行线性插值来达到平滑的目的，也是过去行业中经常使用的一种方法，这种方法称为删除插值(Deleted Interpolation)，详见下面的公式：</p>
<p>$$P(w_i\mid w_{i-2},w_{i-1})=\lambda(w_{i-2},w_{i-1})\cdot f(w_i\mid w_{i-2},w_{i-1}) +\lambda(w_{i-1})\cdot f(w_i\mid w_{i-1})+\lambda f(w_i)$$</p>
<p>其中，三个 λ 为插值权重，均为正数且和为 1。</p>
<p>线性插值法的效果比卡茨退避法略差，故现在已经较少使用了。</p>
<p><img alt class="post-img b-lazy" data-img="../img/xiniu_neteasy.png" data-index="0" data-src="../img/xiniu_neteasy.png"></p>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/nlp/" rel="tag"># nlp</a>
                    </li>
                    
                    <li>
                        <a href="/tags/自然语言处理/" rel="tag"># 自然语言处理</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="NLP系列" href="/2019-03-21/nlp/10Visual_Text_Task_Image_Caption_and_VQA/Chapter1_Image_Caption/Image_Caption/">
            ← NLP系列
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="NLP系列" href="/2019-03-21/nlp/5Text_topic_extraction_and_representation_v2/2_LDA/">
            NLP系列 →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#统计语言模型"><span class="toc-text">统计语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-用数学的方法描述语言规律"><span class="toc-text">1. 用数学的方法描述语言规律</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#贾里尼克的想法"><span class="toc-text">贾里尼克的想法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#二元模型与-N-元模型"><span class="toc-text">二元模型与 N 元模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-高阶语言模型"><span class="toc-text">2. 高阶语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-模型的训练、零概率问题和平滑方法"><span class="toc-text">3. 模型的训练、零概率问题和平滑方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#古德-图灵估计"><span class="toc-text">古德-图灵估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#卡茨退避法"><span class="toc-text">卡茨退避法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#线性插值"><span class="toc-text">线性插值</span></a></li></ol></li></ol></li></ol>
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Pastor Dean &mdash;</small>
    <h3 class="read-next-card-header-title">Recent Posts</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2020-01-16/thinking/Thinking modelBiological thinking Biological thinking looking at the business world from an evolutionary perspective/">Thinking modelBiological thinking Biological thinking: looking at the business world from an evolutionary perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-13/thinking/Modern Darwin Integrated Model  Biological Thinking Mode Opening God Perspective/">Modern Darwin Integrated Model Biological Thinking Mode Opening God is Perspective</a>
      </li>
      
      
      
      <li>
        <a href="/2020-01-11/thinking/Metacognition Changing the stubborn thinking of the brain/">Metacognition Changing the stubborn thinking of the brain</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">Categories</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Biological-Thinking/">Biological Thinking</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Cognitive-Neuroscience/">Cognitive Neuroscience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FFmpeg/">FFmpeg</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MacOS/">MacOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Network/">Network</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PM/">PM</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/RPC/">RPC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ubuntu/">Ubuntu</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Vim/">Vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/WebRTC/">WebRTC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithm/">algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/deeplearn/">deeplearn</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/http/">http</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machineLearning/">machineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/前端/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/文摘/">文摘</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/架构师/">架构师</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/知识图谱/">知识图谱</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/">职业规划</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/职业规划/个人提升/">个人提升</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机基础/">计算机基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/计算机相关技术资料整理/">计算机相关技术资料整理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/认知升级/">认知升级</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财务自由/">财务自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/财富自由/">财富自由</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(/images/favicon-32x32-next.png)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">Tag Cloud</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/AI/" style="font-size: 14px;">AI</a> <a href="/tags/Android/" style="font-size: 14px;">Android</a> <a href="/tags/Biological/" style="font-size: 17.75px;">Biological</a> <a href="/tags/Browser/" style="font-size: 14px;">Browser</a> <a href="/tags/Business/" style="font-size: 16.5px;">Business</a> <a href="/tags/Cognitive/" style="font-size: 17.75px;">Cognitive</a> <a href="/tags/DeepLearning/" style="font-size: 15.25px;">DeepLearning</a> <a href="/tags/Docker/" style="font-size: 14px;">Docker</a> <a href="/tags/FFmpeg/" style="font-size: 21.5px;">FFmpeg</a> <a href="/tags/FastCGI/" style="font-size: 14px;">FastCGI</a> <a href="/tags/IP划分/" style="font-size: 14px;">IP划分</a> <a href="/tags/IP地址/" style="font-size: 14px;">IP地址</a> <a href="/tags/Knowledge-Graph/" style="font-size: 16.5px;">Knowledge Graph</a> <a href="/tags/Linux-Shell/" style="font-size: 14px;">Linux Shell</a> <a href="/tags/MacOS/" style="font-size: 15.25px;">MacOS</a> <a href="/tags/Neuroscience/" style="font-size: 17.75px;">Neuroscience</a> <a href="/tags/RPC/" style="font-size: 14px;">RPC</a> <a href="/tags/Thinking/" style="font-size: 17.75px;">Thinking</a> <a href="/tags/Tutorial/" style="font-size: 20.25px;">Tutorial</a> <a href="/tags/WebRTC/" style="font-size: 21.5px;">WebRTC</a> <a href="/tags/WebSocket/" style="font-size: 14px;">WebSocket</a> <a href="/tags/algorithm/" style="font-size: 15.25px;">algorithm</a> <a href="/tags/config/" style="font-size: 14px;">config</a> <a href="/tags/decisionTree/" style="font-size: 14px;">decisionTree</a> <a href="/tags/git/" style="font-size: 17.75px;">git</a> <a href="/tags/google-adsense/" style="font-size: 14px;">google adsense</a> <a href="/tags/hexo/" style="font-size: 17.75px;">hexo</a> <a href="/tags/http/" style="font-size: 17.75px;">http</a> <a href="/tags/knn/" style="font-size: 14px;">knn</a> <a href="/tags/lighttpd/" style="font-size: 15.25px;">lighttpd</a> <a href="/tags/mxnet/" style="font-size: 14px;">mxnet</a> <a href="/tags/mysql/" style="font-size: 22.75px;">mysql</a> <a href="/tags/nlp/" style="font-size: 24px;">nlp</a> <a href="/tags/nodejs/" style="font-size: 14px;">nodejs</a> <a href="/tags/openvpn/" style="font-size: 14px;">openvpn</a> <a href="/tags/other/" style="font-size: 15.25px;">other</a> <a href="/tags/paddle/" style="font-size: 14px;">paddle</a> <a href="/tags/planning/" style="font-size: 20.25px;">planning</a> <a href="/tags/pracitce/" style="font-size: 15.25px;">pracitce</a> <a href="/tags/rich/" style="font-size: 14px;">rich</a> <a href="/tags/shell/" style="font-size: 14px;">shell</a> <a href="/tags/svn/" style="font-size: 14px;">svn</a> <a href="/tags/ubuntu/" style="font-size: 14px;">ubuntu</a> <a href="/tags/vim/" style="font-size: 16.5px;">vim</a> <a href="/tags/webpack/" style="font-size: 14px;">webpack</a> <a href="/tags/webrtc/" style="font-size: 19px;">webrtc</a> <a href="/tags/个人发展/" style="font-size: 14px;">个人发展</a> <a href="/tags/互联网实事/" style="font-size: 14px;">互联网实事</a> <a href="/tags/外链/" style="font-size: 14px;">外链</a> <a href="/tags/提升个人思维/" style="font-size: 14px;">提升个人思维</a> <a href="/tags/文摘/" style="font-size: 15.25px;">文摘</a> <a href="/tags/斜杠青年/" style="font-size: 14px;">斜杠青年</a> <a href="/tags/机器学习/" style="font-size: 16.5px;">机器学习</a> <a href="/tags/架构师/" style="font-size: 14px;">架构师</a> <a href="/tags/测试工具/" style="font-size: 14px;">测试工具</a> <a href="/tags/睡后成长/" style="font-size: 14px;">睡后成长</a> <a href="/tags/睡后收入/" style="font-size: 14px;">睡后收入</a> <a href="/tags/税后收入/" style="font-size: 14px;">税后收入</a> <a href="/tags/笔记/" style="font-size: 14px;">笔记</a> <a href="/tags/自然语言处理/" style="font-size: 24px;">自然语言处理</a> <a href="/tags/视频流/" style="font-size: 15.25px;">视频流</a> <a href="/tags/计算机相关技术资料整理/" style="font-size: 14px;">计算机相关技术资料整理</a> <a href="/tags/认知升级/" style="font-size: 14px;">认知升级</a> <a href="/tags/限速/" style="font-size: 14px;">限速</a> <a href="/tags/面试/" style="font-size: 14px;">面试</a> <a href="/tags/项目管理/" style="font-size: 14px;">项目管理</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="/images/favicon-16x16-next.png" alt="Pastor Dean">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="Search ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Pastor Dean">Pastor Dean &copy; 2020</a>
			
				
			        <span hidden="true" id="/2019-03-21/nlp/1NLP_intro/1.language_model_calculation/" class="leancloud-visitors" data-flag-title="NLP系列">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="https://hexo.io" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>


<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>



<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>




<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: '',
            appKey: '',
            placeholder: 'Just go go',
            pageSize: 10,
            avatar: 'mm',
            visitor: true
        })
    });
</script>





</body>
</html>
